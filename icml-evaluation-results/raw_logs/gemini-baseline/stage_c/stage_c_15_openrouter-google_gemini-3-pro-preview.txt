This research plan focuses on the **Human-Computer Interaction (HCI) of Legal AI**, moving beyond "can the model pass the Bar?" to "does the model actually make lawyers safer and more efficient?" This area is critical as firms integrate tools like CoCounsel, Harvey, and Lexis+ AI.

### 1. Problem Framing and Goals

**The Problem:**
While Large Language Models (LLMs) demonstrate high proficiency on legal benchmarks (e.g., LegalBench, UBE), their impact on the *workflow* of legal professionals is unproven. There is a high risk of **"Automation Bias"**â€”where lawyers, pressed for time, accept plausible-sounding but legally inaccurate AI outputs (hallucinations). Furthermore, the cognitive load of "verifying" AI output may negate the time saved in "drafting."

**Research Goal:**
Conduct a **Mixed-Methods User Study** to quantify the impact of AI assistance on legal task performance (Speed vs. Quality) and measure the prevalence of automation bias among legal professionals.

**Core Objectives:**
1.  **Efficiency vs. Accuracy:** Determine if AI assistance statistically significantly reduces time-on-task without lowering the grade of the legal work product.
2.  **Hallucination Blindness:** Measure how often qualified lawyers fail to catch "seeded" legal errors in AI-generated drafts.
3.  **User Trust Dynamics:** Correlate the user's level of legal experience (Junior vs. Senior) with their trust in the model's output.

---

### 2. Experiments

#### Experiment 1: The "Copilot" Performance Audit (A/B Test)
**Hypothesis:** AI assistance reduces drafting time by >30% but results in a lower "Legal Reasoning" score compared to human-only drafting due to generic argumentation.
*   **Setup:**
    *   **Participants:** 40 Legal professionals (20 Law Students, 20 Practicing Attorneys).
    *   **Task:** Draft a logical legal memo based on a provided "case file" (fact pattern + 3 relevant cases). Use a standard **Multistate Performance Test (MPT)** prompt to ensure a ground truth exists.
    *   **Condition A (Control):** Standard word processor + PDF case files.
    *   **Condition B (Treatment):** Access to a custom AI interface (GPT-4o backend) pre-loaded with the case files (RAG) and a chat window.
*   **Baselines:** Average time/score of Condition A.
*   **Evaluation Metrics:**
    *   **Time-on-Task:** (Minutes).
    *   **Quality Score:** Blind grading by 2 senior partners using a standardized rubric (1-5 scale on Issue Spotting, Rule Application, Conclusion).
*   **Expected Outcome:** Condition B is 40% faster but scores 0.5 points lower on "Nuance/Application," proving efficiency comes at a quality cost.

#### Experiment 2: The "Trojan Horse" Safety Test
**Hypothesis:** Lawyers are likely to overlook "citation hallucinations" if the surrounding text is high-quality, exhibiting automation bias.
*   **Setup:**
    *   **Task:** Review a pre-generated legal brief for a Motion to Dismiss.
    *   **Manipulation:** The brief contains one **hallucinated case citation** (real-sounding name, fake holding) and one **subtle logic error** (misinterpreting a statute).
    *   **Instruction:** "Review this draft for errors as if a junior associate wrote it. Annotate all mistakes."
*   **Evaluation Metrics:** **Detection Rate** (% of participants who flag the error).
*   **Expected Outcome:** Detection rate will be disturbingly low (<60%), particularly for the hallucinated citation, indicating over-reliance on the tool's perceived authority.

#### Experiment 3: Cognitive Load & Trust (Qualitative)
**Hypothesis:** Use of AI shifts cognitive load from "Generation" to "Verification," which users find subjectively more taxing despite being faster.
*   **Setup:**
    *   **Method:** Post-task survey using **NASA-TLX** (Task Load Index) and semi-structured interviews.
    *   **Questions:** "How much did you trust the AI?" "Did you verify every citation?"
*   **Evaluation Metrics:** Self-reported Mental Demand vs. Temporal Demand.
*   **Expected Outcome:** Participants will report lower Temporal Demand but higher Frustration/Mental Demand in the AI condition due to the "verification tax."

---

### 3. Timeline (6 Months)

| Month | Milestone | Key Deliverables |
| :--- | :--- | :--- |
| **Month 1** | **IRB & Protocol** | **CRITICAL:** Submit IRB application (Human Subjects). Define "Deception" protocol for Exp 2. Draft MPT case materials. |
| **Month 2** | **Recruitment & Pilot** | Recruit 5 participants for a "Dry Run" to fix UI bugs. Begin recruiting valid lawyers (offer CLE credit or honorarium). |
| **Month 3** | **Data Collection (Phase 1)** | Execute Exp 1 and 2 with the first cohort (Law Students). Monitor for technical failures. |
| **Month 4** | **Data Collection (Phase 2)** | Execute Exp 1 and 2 with the second cohort (Practicing Attorneys). Conduct Exp 3 interviews. |
| **Month 5** | **Grading & Analysis** | **Blind Grading:** Hired experts grade the anonymized memos. Run statistical significance tests (t-tests, ANOVA). |
| **Month 6** | **Writing & Submission** | Draft paper. Target venues: **CHI (HCI)**, **FAccT**, or a Law Review (e.g., *Stanford Technology Law Review*). |

---

### 4. Resources

**Compute & Tools:**
*   **Interface:** A simple web wrapper (Streamlit/Gradio) around the OpenAI API to log all keystrokes and interaction timestamps. *Do not use ChatGPT directly; you need logs.*
*   **Survey Tool:** Qualtrics (for NASA-TLX and consent forms).
*   **Budget:** Honorariums for participants. Lawyers are expensive. Budget \$50-\$100/hr or partner with a Bar Association to offer CLE (Continuing Legal Education) credits instead of cash.

**Datasets:**
*   **NCBE Multistate Performance Test (MPT):** Use past exam questions (publicly available). They are perfect because they are "closed universe" (all necessary laws are provided), removing the variable of "search skill."
*   **LegalBench:** Use for inspiration on specific reasoning tasks.

**Evidence/References:**
*   *Reference:* "Better Call GPT, Comparing Large Language Models Against Lawyers" (Choi et al., 2023).
*   *Reference:* "Hallucination is Inevitable" (check papers on legal hallucination rates).

---

### 5. Risks and Mitigations

| Risk | Impact | Mitigation Strategy |
| :--- | :--- | :--- |
| **IRB Delays** | Experiment 2 involves "deception" (giving users bad AI outputs intentionally). | **Debriefing:** Include a robust debriefing form explaining *why* the errors were seeded. Submit as "Exempt" or "Expedited" if possible, arguing minimal harm. |
| **Recruitment Failure** | Lawyers are too busy to participate. | **Law Clinics:** Partner with Law School Clinics. They are "real" lawyers (supervised students) and easier to recruit. |
| **Skill Variance** | A senior partner writes better than a student regardless of AI. | **Within-Subjects Design:** If possible, have the *same* person do Task A (Manual) and Task B (AI) to control for individual skill. |
| **Data Privacy** | Lawyers fear uploading data. | **Synthetic Data:** explicitly state in the recruitment that *no real client data* will be used. Use the MPT mock cases. |

---

### 6. Stretch Ideas & Follow-up Directions

*   **Prompt Engineering Education:** Add a third condition: Lawyers who are *trained* on how to prompt the AI vs. those who are thrown in blind. Does "AI Literacy" mitigate automation bias?
*   **RAG vs. Context Window:** Compare feeding the case files into the context window (Long Context) vs. using a Retrieval (RAG) system. Which leads to fewer hallucinations?
*   **Longitudinal Study:** Give the tool to a firm for a month. Does trust increase or decrease over time? (Harder to control, but higher ecological validity).

**Optional next step:**
Download a sample **Multistate Performance Test (MPT)** packet from the NCBE website. This will be your "Ground Truth" dataset. Read the "File" and "Library" sections to understand the closed-universe constraints you will be simulating.