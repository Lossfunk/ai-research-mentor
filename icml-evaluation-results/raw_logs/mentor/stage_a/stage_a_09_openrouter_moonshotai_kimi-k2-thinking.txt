<thinking>
Beginner, torn between two fields. Need a decisive recommendation, not a comparison list. Honest assessment: robotics safety is not beginner‑friendly without hardware/control background. Lead with verdict, justify, give path forward, ask one clarifying question. 150–200 words.
</thinking>

I’ll be blunt: **for a beginner, AI ethics is far more accessible than robotics safety**. Robotics safety is a bad starting point unless you already have hands‑on robotics, controls, or hardware experience.

Why:
- **Robotics safety is technically unforgiving**. You need control theory, dynamics, simulators, often hardware. Beginners get stuck debugging physics, not doing research.
- **AI ethics can be entered through analysis, evaluation, and critique**, not just math or hardware. You can make real contributions by carefully examining claims, datasets, or evaluation practices.

That said, most people do AI ethics *badly*. If you choose it, avoid vague philosophy. A beginner‑friendly, legitimate entry is:
- Pick one deployed AI system or benchmark
- Examine one concrete ethical claim (bias, robustness, misuse)
- Test whether the evidence actually supports that claim

What you should *not* do:
- Opinion essays
- Broad “ethical implications of AI” surveys
- Policy recommendations without technical grounding

If you later want robotics safety, you can transition once you’ve built technical confidence.

One key question before I lock this in:
**Do you enjoy careful reading and argumentation, or do you strongly want to build and test systems?**