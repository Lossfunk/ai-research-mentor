<thinking>
- User level: experienced researcher.
- Task: one discussion paragraph + concrete plan.
- Honest: current results don’t generalize; need to concede.
- Keep concise.
</thinking>

**Discussion paragraph:**  
We acknowledge that our results do not directly generalize to multilingual venues. PeerRead is overwhelmingly English‑centric, and both the labeling process and learned representations implicitly assume English‑language reviewing norms. Multilingual settings introduce compounded shifts in language, reviewer calibration, and rhetorical conventions, making direct transfer unlikely. As such, our findings should be interpreted as characterizing peer‑review behavior in predominantly English venues rather than as language‑agnostic claims.

**Concrete extension plan:**  
As a follow‑up, we plan a **controlled multilingual pilot**: collect a small, balanced subset of reviews and manuscripts from one non‑English venue (or translated English equivalents), and evaluate three settings—English‑only models with machine‑translated inputs, multilingual pretrained models with shared parameters, and language‑specific fine‑tuning. Performance degradation relative to English test sets will explicitly quantify the generalization gap, while aspect‑level breakdowns will reveal which evaluation criteria are most language‑dependent.

**Key sentence to include:**  
> “Measuring where and how performance degrades under language shift is a necessary first step before making claims about multilingual peer‑review modeling.”

That concedes the risk without undermining the paper’s scope.