<thinking>
- User level: experienced researcher.
- Honest assessment: bias risk is real; must concede and bound claims.
- Provide addendum + concrete, limited mitigation steps.
</thinking>

**Discussion addendum:**  
We recognize that PeerRead may encode socioeconomic biases present in contemporary peer review, including disparities linked to institutional prestige, geographic location, and access to resources that influence writing style, experimental scale, and reviewer expectations. Because the dataset reflects *observed* review outcomes rather than an objective standard of merit, models trained on PeerRead risk reproducing these structural inequities. Our results should therefore not be interpreted as normative judgments about research quality, but as analyses of a historically situated review process with known biases.

**Mitigation steps for the camera‑ready:**  
First, we will add **stratified analyses** by available proxies (e.g., institution tier or region when inferable) to quantify performance and error disparities rather than obscuring them in averages. Second, we will include a **feature sensitivity audit** showing how predictions change when removing prestige‑correlated signals (e.g., citation counts, writing length proxies). Third, we will expand the ethics discussion to clarify **non‑intended uses**, explicitly discouraging deployment in evaluative settings affecting funding or hiring.

**Key sentence to include:**  
> “PeerRead enables study of peer review as it exists, not endorsement of its equity; documenting and stress‑testing embedded biases is a necessary condition for responsible use.”

This acknowledges the risk and shows concrete responsibility without overclaiming fixes.