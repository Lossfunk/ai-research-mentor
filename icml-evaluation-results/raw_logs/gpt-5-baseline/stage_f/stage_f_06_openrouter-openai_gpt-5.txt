Below is a ready-to-use set of double-blind compliance notes tailored for a human-centered AI evaluation paper, plus an artifact release plan, anonymized appendices blueprint, and a six-week timeline with checkpoints. Adapt phrasing to your venue’s author kit (ICLR/ICML/NeurIPS/ACL/CHI).

A) Double-blind compliance notes to include in the paper

Anonymity and self-references
- We follow double‑blind review. All identifying details (author names, affiliations, grants, lab names, institutional IRB identifiers, repository owners, URLs that reveal identities) are removed from the submission and supplementary materials.
- Self‑citations are anonymized (e.g., “Anonymous, 2024”) and written in third person without language that reveals authorship (avoid “our prior work introduced…”). Full self‑citations will be restored at camera‑ready.
- Preprints and prior artifacts: We do not link to non‑anonymous repositories or personal webpages. If a preprint exists, we cite it neutrally without naming authors when the venue permits, and avoid pointing to identity‑revealing resources.

Human subjects, ethics, and IRB
- Human subjects: This study involved human participants. We obtained ethics approval from an institutional review board; to preserve anonymity we do not name the institution or protocol number in the submission. Details will be provided at camera‑ready.
- Consent and compensation: All participants provided informed consent. Compensation and recruitment procedures are described without institution‑specific identifiers.
- Privacy: We minimized collection of personal data. Free‑text fields were scrubbed for PII prior to analysis. We report only aggregate statistics and redact rare categories that risk re‑identification.

Recruitment and demographics
- Recruitment is described at a level that supports replication without deanonymizing the authors (e.g., “commercial panel provider,” “university subject pool”) rather than naming local labs or organizations uniquely tied to the authors.
- Demographics are reported in aggregate; small cells are merged or suppressed to reduce re‑identification risk.

Materials and stimuli
- All task materials, prompts, and UI screenshots are included in anonymized form. Any logos, system names, or institution‑branded elements are redacted or blurred. File metadata and image EXIF have been cleared.

Computing environment and systems
- We describe hardware/software at a generic level sufficient for reproduction (e.g., “consumer laptop,” “NVIDIA A100 40GB”) without mentioning institution‑specific clusters or internal systems that could reveal identity.

Acknowledgments and funding
- Acknowledgments and grant numbers are omitted for review and will be restored at camera‑ready.

B) Artifact release plan (double‑blind friendly)

Anonymized repository
- We provide an anonymized artifact for reviewers with:
  - Code for data processing, analysis, and figure generation.
  - Synthetic or de‑identified example data sufficient to execute the pipeline end‑to‑end.
  - Scripts to reproduce each table/figure with a single command.
  - Environment specification (Conda/Poetry lockfile) and optional Docker image.
- Hosting: Anonymous Git hosting (no owner profile) or a private, blinded link (e.g., OpenReview supplementary, OSF/Zenodo private link with embargo) that does not display author names. Commit history is squashed to avoid identity in logs.

Data handling
- Raw human data are not redistributed. We include:
  - Aggregated results tables; de‑identified sample records where safe; and a data dictionary.
  - A data‑access statement with instructions for obtaining the original datasets (if public) or a contact form to request controlled access after acceptance (if restricted).
  - A redaction policy describing how we removed PII from free‑text responses and logs.

Experiment seeds and configs
- All configs (YAML/TOML) include fixed random seeds and parameter settings for reproducibility.
- We provide a manifest mapping each main result to its config and command.

Licensing and policies
- For submission: a permissive license file without author names (or a placeholder “To be finalized at camera‑ready”), and an acceptable‑use policy for any released models or scripts interacting with sensitive data.
- Post‑acceptance: replace placeholders with final license and citation files.

Artifact statement to paste in paper
- “An anonymized artifact containing code, configs, and de‑identified materials is provided in the supplementary link. No raw participant data are shared; we release aggregated results and synthetic examples sufficient to reproduce analyses. Full, non‑anonymous artifacts will be published upon acceptance.”

C) Anonymized appendices blueprint

Include the following, ensuring no identity leakage:
- Extended methods: Recruitment criteria, screening, task design, counterbalancing, attention checks, timing. Avoid institution names; use generic provider descriptions.
- Instruments and prompts: Full survey/interview instruments, task instructions, prompts, UI screenshots with branding/logos redacted.
- Qualitative codebook: Coding scheme, examples with identifying details masked; coder training protocol without coder names.
- Reliability and stats: Inter‑rater reliability (κ/α) computation details; power analysis; analysis plan; exact model specifications; multiple‑comparison controls.
- Additional results: Full tables, ablations, confidence intervals, subgroup analyses with small cells merged to protect participants.
- Ethics details: Consent script (generic), risk/benefit assessment, data retention policy, and takedown procedure. IRB named generically for review; full details added at camera‑ready.
- Provenance and licenses: Third‑party datasets/tools with licenses and URLs; no mirrored proprietary assets.
- Reproducibility pack: Exact commands for each figure/table; environment hashes; container digest; anonymized artifact link.

D) Blinding do/don’t quick checks

Do
- Use neutral phrasing for institution‑specific resources (“commercial panel,” “institutional participant pool”).
- Remove names from file paths, notebook authorship, EXIF, Git config (user.name/user.email), and document properties.
- Replace lab/institutional logos in figures; check alt‑text and PDF properties.
- Cite your prior work as “Anonymous (Year)” and write about it in third person.

Don’t
- Link to GitHub or datasets under personal or lab accounts.
- Include acknowledgments, grants, or IRB institution names/numbers in the submission.
- Quote participant free‑text that contains names, locations, or unique events; paraphrase or mask as needed.

E) Six‑week timeline with double‑blind checkpoints

Week 6: Scope and blinding plan
- Lock venue template and anonymization requirements.
- Draft ethics/IRB text with generic wording; decide what is deferred to camera‑ready.
- Set up an anonymous repo and storage; squash history; disable identity‑revealing metadata.
- Gate: Confirm that all planned materials (instruments, screenshots, quotes) can be anonymized without harming validity.

Week 5: Artifact scaffold and materials scrub
- Implement one‑command runners; add configs, seeds, environment files, container.
- Scrub materials: redact logos, clear EXIF/metadata, sanitize logs and free‑text.
- Build appendix shells: methods, instruments, codebook, stats, ethics details.
- Gate: External spot‑check for identity leaks in text, figures, file metadata.

Week 4: Results stabilization and appendices
- Finalize main analyses; generate CIs; complete subgroup and ablations.
- Populate appendices with full details; merge small demographic cells.
- Draft artifact statement and data‑access statement for the paper.

Week 3: Compliance and reproducibility dry‑run
- Fresh‑machine reproduction of at least one end‑to‑end run using the anonymized artifact.
- Complete venue reproducibility and ethics checklists.
- Internal red‑team read for deanonymization risks (self‑references, institution hints, unique resources).

Week 2: Paper freeze v1 and artifact hardening
- Freeze main text within page limits; move overflow to anonymized appendices.
- Lock anonymized artifact; tag a reviewer build; verify deterministic runs with fixed seeds.
- Prepare rebuttal templates (if OpenReview) and a plan for clarifying anonymity questions.

Week 1: Final polish and verification
- Final pass on anonymization (PDF properties, alt‑text, figure watermarks).
- Proof ethics/IRB text; ensure no institutional identifiers remain.
- Validate all supplementary links function without revealing identity.

Submission week
- Submit paper + anonymized appendices + artifact link.
- Archive commit/tag hashes, environment lockfiles, and a list of all anonymization steps (for later de‑anonymization at camera‑ready).

F) Ready-to-paste boilerplate snippets

Ethics and anonymity
- “This submission follows double‑blind review. We removed identifying information from the manuscript and supplementary materials. We obtained ethics approval from an institutional review board; to preserve anonymity we omit the institution name and protocol number and will include them in the camera‑ready version.”

Artifact availability
- “We provide an anonymized artifact with code, analysis scripts, and de‑identified materials sufficient to reproduce all results. Due to participant privacy, raw human data are not shared; we include aggregated results and synthetic examples. Access details are in the supplementary material. Full artifacts will be released upon acceptance.”

Data and privacy
- “All free‑text responses were screened to remove personal identifiers. Demographic reporting merges small categories to reduce re‑identification risk. A takedown procedure is described in Appendix X.”

If you share your target venue, I can tailor these notes to that author kit (e.g., specific wording for ICLR limitations and OpenReview artifacts, ACL ethics checklist items, or CHI anonymized supplementary materials) and draft a venue-ready anonymized artifact README template.