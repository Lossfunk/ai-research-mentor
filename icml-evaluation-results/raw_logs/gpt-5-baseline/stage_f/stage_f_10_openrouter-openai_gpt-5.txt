Below is a concise, venue-focused compliance map for a “language-model-for-law” paper. It lists the ethics/compliance sections you should include, then maps them to major AI venues’ disclosure checklists and artifact expectations. Use this as your final pre‑submission checklist.

Core ethics/compliance sections to include in the paper and supplement
- Ethics statement (law‑specific)
  - Scope and non‑advice disclaimer; unauthorized practice of law (UPL) guardrails; human‑in‑the‑loop requirement.
  - Dual‑use/misuse risks (fraudulent filings, fake citations, harassment, evasion of court orders) and mitigations (citation verification, refusal policies).
  - Jurisdictional and temporal scope: which legal systems/time windows your results apply to; concept drift as law changes.
- Data provenance and licensing
  - Per‑asset table: corpus name (e.g., CourtListener/RECAP, Caselaw Access Project, EUR‑Lex, legislation.gov.uk), URL, license, permitted uses (research/commercial), redistribution allowed (Y/N), special terms/TOS, and any DUAs.
  - Explicitly state exclusion of proprietary databases (e.g., Westlaw/Lexis) unless you have rights; do not redistribute restricted texts.
  - Web/TOS compliance and robots.txt status (if applicable); takedown process.
- Human subjects and annotation
  - Whether you used legal experts or crowd workers; IRB/ethics determination (approved/exempt/Not Human Subjects Research), consent, pay rates, demographics handling, inter‑annotator agreement.
- Privacy and confidentiality
  - PII/privileged information screening and redaction; residual risk discussion; policy for rectification/takedown.
  - No release of raw filings containing PII; only sanitized/aggregated artifacts.
- Safety, fairness, and bias
  - Group‑wise and jurisdiction‑wise performance; impacts on access to justice and error asymmetries.
  - Jailbreak/unsafe prompt evaluation; hallucinated citation rates and mitigation.
- Reproducibility and artifacts
  - Exact preprocessing/tokenization; prompts, seeds, splits; eval scripts; versioning; container.
  - Release plan: code, configs, evaluation data fetch scripts; weights vs deltas vs evaluation‑only API consistent with upstream licenses.
- Compute and environmental disclosure
  - Hardware, accelerator‑hours, region, energy/CO2e estimates; efficiency measures.
- Limitations
  - When the model should not be used; domain/language coverage gaps; failure modes (e.g., citation fabrication); monitoring requirements.

Venue-specific disclosure and artifact adherence

NeurIPS
- Required
  - Reproducibility checklist (methods, datasets, compute, evaluation).
  - Ethical considerations if applicable (privacy, legal risks, environmental impact).
  - Limitations and societal risks encouraged.
- Artifacts
  - Code strongly encouraged at camera‑ready; dataset redistribution only if licenses allow.
  - Optional Artifact Evaluation; provide Docker/conda, one‑command runs.
- Law‑specific emphasis
  - Clear license table; UPL/misuse guardrails; no proprietary legal text redistribution.

ICLR (OpenReview)
- Required
  - Limitations section (mandatory).
  - Reproducibility checklist.
  - Ethics review for flagged submissions.
- Artifacts
  - Anonymous code link at submission preferred; public code by camera‑ready expected.
  - Public discussion: ensure anonymized artifacts.
- Law‑specific emphasis
  - Public claims matched by public artifacts (e.g., citation verification scripts); sanitized sample data only.

ICML
- Required
  - Reproducibility checklist; ethics statement if applicable.
- Artifacts
  - Code strongly encouraged by camera‑ready; clear instructions for data acquisition (no restricted mirrors).
- Law‑specific emphasis
  - Dataset/TOS compliance statement; explicit exclusion (or gating) of any restricted legal corpora.

ACL/EMNLP/NAACL (via ARR)
- Required
  - Ethics statement per ACL Ethics Policy (human subjects, risks/harms, sensitive data).
  - Responsible NLP Checklist (data, annotations, biases, licensing, compute).
  - Limitations section (required).
  - Data and Software Availability statements (explicit licenses/URLs).
- Artifacts
  - Anonymous code at submission encouraged; release by camera‑ready expected.
  - For datasets, provide a data card and documentation; do not host restricted text.
- Law‑specific emphasis
  - Legal‑domain risks and UPL; annotator qualifications/compensation; jurisdictional coverage and drift.

AAAI (general AI)
- Required
  - Ethics/societal impact discussion for flagged work (privacy, safety).
  - Reproducibility items (methods, data availability, code expectations vary by year).
- Artifacts
  - Code/data release encouraged; clear licensing; no redistribution of restricted corpora.
- Law‑specific emphasis
  - Misuse analysis (fraud, harassment) and mitigations; PII/privilege safeguards.

TMLR (rolling journal, OpenReview)
- Required
  - Strong reproducibility; limitations; ethics where applicable.
- Artifacts
  - Code expected unless justified; datasets documented; open reviews.
- Law‑specific emphasis
  - Extended artifact pack (eval harness, auditing scripts, model/data cards).

Master disclosure checklist (cross‑venue; use as paper/supplement outline)
- Ethics statement
  - [ ] Non‑advice/UPL disclaimer and human‑in‑the‑loop requirement
  - [ ] Misuse risks (fake citations/filings, harassment, evasion) + guardrails and release policy
  - [ ] Jurisdiction/time scope; concept drift; dual‑use analysis
- Data provenance and licensing
  - [ ] Per‑dataset license table and TOS compliance
  - [ ] Redistribution stance (no proprietary text mirrors)
  - [ ] PII/privilege screening and takedown policy
- Human subjects/annotation
  - [ ] IRB/ethics determination; consent; pay; demographics handling; IAA metrics
- Privacy and confidentiality
  - [ ] De‑identification methods; residual risk; no raw sensitive data release
- Fairness and safety
  - [ ] Group/jurisdictional performance; calibration; unsafe prompt/jailbreak tests; citation hallucination rates
- Reproducibility and artifacts
  - [ ] Exact preprocessing/tokenizers/prompts; seeds; splits; hyperparameters
  - [ ] Eval scripts; one‑command runs; container/lockfiles
  - [ ] Release plan: code, configs, checkpoints (weights/deltas/API) consistent with upstream licenses
- Compute/environment
  - [ ] Hardware, accelerator‑hours; energy/CO2e with method/assumptions
- Limitations
  - [ ] Explicit non‑goals; failure modes; monitoring/verification needs in deployment
- Availability statements (ACL style)
  - [ ] Data availability (with licenses/URLs/DUAs)
  - [ ] Software availability (license, repo)
  - [ ] Model availability (license, gating, acceptable‑use policy)

Artifact adherence checklist (tailored for legal‑domain LMs)
- Repository
  - [ ] Clean, reproducible repo; CITATION.cff; LICENSE for code and separate LICENSE for weights
  - [ ] Makefile/reproduce.sh mapping tables/figures → configs/seeds; results manifest with expected metrics ± CI
  - [ ] Container (Docker) and/or conda/poetry lockfile; determinism flags
- Data handling
  - [ ] Fetch scripts to official sources (CourtListener/CAP/EUR‑Lex/etc.); checksums; no redistribution of restricted documents
  - [ ] Redaction utilities to remove PII/privileged content in any examples; sanitized toy/synthetic samples
  - [ ] Data card(s) detailing provenance, licensing, known biases
- Models
  - [ ] Weights or weight deltas (if base license restricts redistribution); model card with intended use/limitations/risks
  - [ ] Refusal/citation‑verification behavior documented and tested
- Evaluation
  - [ ] Task definitions (citation retrieval, statute Q&A, summarization) with metrics; jurisdictional splits; temporal splits
  - [ ] Safety evals: hallucination/citation fabrication, jailbreaks, prompt‑leakage tests
  - [ ] Confidence intervals; seeds; multiple runs
- Documentation and policies
  - [ ] Acceptable‑use policy; non‑advice disclaimer; deployment caveats
  - [ ] Takedown/contact; vulnerability disclosure process
  - [ ] Environmental impact note (compute/CO2e)

Law‑specific red flags to preempt in text and artifacts
- Using or redistributing proprietary legal databases without rights (Westlaw/Lexis).
- Publishing raw court filings with PII or privileged content.
- Claims implying the system replaces licensed counsel or provides binding legal advice.
- Opaque citation generation without verification; failing to quantify hallucination or stale law reliance.

If you share your target venue (e.g., ICLR vs ACL), I can tailor this into a section-by-section template (exact headings/wording), fill a license table scaffold with your datasets, and produce an artifact README that matches that venue’s checklist.