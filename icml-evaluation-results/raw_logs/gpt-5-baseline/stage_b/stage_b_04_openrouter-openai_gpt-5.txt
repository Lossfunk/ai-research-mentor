Short answer: Yes, but only if you narrow scope and lean on existing code. Building a novel GNN for sea‑ice from scratch with zero coding isn’t realistic; a small, working prototype in a few weeks is.

Practical paths
- Fastest path (collab): Partner with someone who codes. You handle problem framing, data choices, evaluation, and write‑up; they implement. This gets you a credible result fastest.
- Learn‑and‑build path (2–6 weeks, part‑time): Learn just enough Python + PyTorch to adapt an existing spatiotemporal GNN notebook to sea‑ice data and run it on Colab/Kaggle.

Minimal viable prototype (keep it tiny)
- Scope
  - Target: daily sea‑ice concentration (SIC) nowcast or 1–3 day forecast.
  - Region: a small box (e.g., Barents or Hudson Bay), not pan‑Arctic.
  - Grid: downsample to ~25–50 km so you have a few thousand nodes max.
- Data
  - SIC: OSI‑SAF or NSIDC daily SIC (netCDF).
  - Forcing (optional for v1): ERA5 10 m winds (u10, v10), SST.
- Baselines (must beat these)
  - Persistence (copy yesterday’s SIC).
  - Climatology (day‑of‑year mean).
- First model (don’t start with a fancy GNN)
  - A simple ConvLSTM or UNet from an existing repo/notebook to establish a workflow and beat baselines.
- Then a GNN
  - Treat grid cells as nodes; connect 4–8 nearest neighbors.
  - Node features: past k days of SIC (and optional winds/SST).
  - Model: an off‑the‑shelf spatiotemporal GNN (STGCN/DCRNN/GraphWaveNet) from PyTorch Geometric Temporal or DGL examples.
- Metrics
  - RMSE/MAE on SIC; accuracy/Brier score for “ice presence” (e.g., SIC ≥ 15%).
  - Ice‑edge distance error and regional ice extent error.

What you need to learn (minimum)
- Week 1: Python + data
  - Basics of Python, NumPy, and xarray for netCDF; plotting with matplotlib.
- Week 2: PyTorch basics
  - Tensors, dataloaders, training loops, saving/loading models.
  - Run a ConvLSTM/UNet notebook on your subset.
- Week 3: Graphs
  - PyTorch Geometric (or DGL): build a k‑NN grid graph, attach features, run an STGCN example.
- Week 4: Apply to sea‑ice
  - Build the dataset windowing, train the GNN, compare to baselines, make plots.

Compute and tooling
- Use Google Colab/Kaggle notebooks with a free GPU; keep models small and regions cropped.
- Libraries: xarray, numpy, pytorch, pytorch‑lightning (optional), torch‑geometric or dgl, cartopy (for maps).
- Keep training under 1–2 hours per run; start with 1–3 months of data before scaling.

Common pitfalls to avoid
- Data alignment: make sure SIC and winds/SST are on the same grid/time; apply land/invalid masks consistently.
- Leakage: train/val/test split by time, not random; respect seasons.
- Class imbalance at the ice edge: report both continuous (RMSE) and edge‑focused metrics.
- Overclaiming: a small‑region, short‑lead demo is a prototype, not SOTA.

Feasibility checklist
- If you can: load a netCDF with xarray; compute a simple persistence baseline; run an existing PyTorch notebook end‑to‑end. If yes, you can do this with guidance.
- If not: start with the collab path and focus on data curation, metrics, and evaluation.

If you want, I can outline a concrete starter plan for one region (data URLs, preprocessing steps, and which example notebook to adapt) and a checklist of plots and metrics to produce.