Great options. Pick the one that fits your constraints and what you enjoy day to day. Here’s a quick way to decide, plus beginner-friendly first projects for each and a short plan.

How they differ (practically)
- AI ethics
  - Typical work: evaluations, dataset/model documentation, bias/harms audits, policy-guided guidelines.
  - Skills: Python, data wrangling, careful experimental design, clear writing. Hardware not required.
  - Outputs: benchmarks, model/data cards, small eval datasets, methodology notes.
- Robotics safety
  - Typical work: preventing unsafe behavior in embodied agents via simulation, control limits, safe RL, perception reliability.
  - Skills: Python + simulators (PyBullet/Webots/Gazebo), RL/control basics, debugging pipelines. Hardware optional if you use sim.
  - Outputs: sim experiments, safety wrappers/shields, failure analyses, videos/plots.

Quick decision guide
- If you have only a laptop/Colab and 3–5 hrs/week: start with AI ethics.
- If you like building/debugging interactive systems and can use simulation: try robotics safety.
- If you prefer writing and community impact: ethics (docs/evals) gets you merged PRs faster.
- If you want hands-on engineering with clear demos: robotics safety in sim is satisfying.
- You can bridge later: e.g., safety evals for LLMs controlling robots, or documenting risks for robotics datasets.

Beginner-friendly starter projects

AI ethics (no hardware)
1) Mini-benchmark for harmless failure modes
- Curate 50–100 benign prompts (e.g., fact Q&A with citations or school-policy compliance).
- Evaluate 2–3 open models; measure accuracy, refusal rate, and hallucinated citations.
- Deliver: CSV prompts, eval script, table + short write-up, limitations.

2) Dataset/model transparency PR
- Pick a small HF dataset or model lacking a good card.
- Write a Data Card/Model Card (intended use, licenses, limitations, simple bias checks).
- Deliver: merged PR + tiny analysis script.

3) Basic fairness audit
- Choose an open tabular/text dataset with demographic attributes.
- Train simple models; compute group metrics (accuracy, FPR/FNR, demographic parity/EO).
- Deliver: results, fairness trade-off plots, recommendations.

Robotics safety (simulation only)
1) Action-limiter safety wrapper in PyBullet
- Task: cartpole or reaching.
- Baseline: vanilla controller/RL policy.
- Extension: clip joint torques/velocities and add a rule-based emergency stop on threshold events.
- Measure: task reward, safety violations, time-to-failure.

2) Safe RL with constraints
- Use Safety-Gymnasium or safe-control-gym on a simple task.
- Compare unconstrained PPO vs constrained PPO/Lagrangian.
- Report reward vs constraint violations with confidence intervals.

3) Perception robustness check
- Simulate a camera sensor (PyBullet/Webots) on a toy classification/detection task.
- Add “corruptions” (blur, lighting, occlusion); test a small model’s failure rate.
- Deliver: accuracy vs corruption plots, suggested thresholds/fallbacks.

8-week micro-plan (2–4 hrs/week; pick one track)

Weeks 1–2: Setup + baseline
- Ethics: choose topic, assemble data/prompts, run one model end-to-end, save results.csv.
- Robotics: install simulator, run a baseline policy/controller; log reward and any violations.

Weeks 3–4: Your one change
- Ethics: add paraphrases or a simple defense (system prompt, refusal filter) or write a first draft of a model/data card.
- Robotics: add a safety wrapper (action limits, emergency stop) or swap to a constrained algorithm.

Weeks 5–6: Robustness + analysis
- Ethics: test on a variant set (paraphrases, different topics); add inter-rater agreement if labeling.
- Robotics: test under perturbations (sensor noise, randomization); report mean ± std over seeds.

Weeks 7–8: Ship
- Clean repo (env, scripts, seeds). Write a 2–3 page note (question, method, results, limitations).
- If applicable, open a PR (eval task or documentation) or share a demo video/gif from sim.

Free tools to use
- Ethics: Hugging Face Datasets/Evaluate, lm-evaluation-harness, AIF360 or Fairlearn, Colab/Kaggle, model/data card templates.
- Robotics: PyBullet or Webots (free), Gymnasium/Safety-Gymnasium or safe-control-gym, Stable Baselines3, Colab (CPU okay for classic control; small GPU helps for RL).

Starter readings (1–2 hours total per track)
- Ethics: Datasheets for Datasets; Model Cards; NIST AI Risk Management Framework (overview); a short survey on LLM safety evals.
- Robotics safety: García & Fernández “A Comprehensive Survey on Safe RL” (skim); short intro to control barrier functions; Safety-Gymnasium docs.

Bridge project idea (if you can’t decide)
- Evaluate simple safety prompts or refusal filters for an LLM that outputs robot actions in a toy sim. Measure task success vs prevented unsafe actions.

How to choose this week
- Write a 1-page plan for both tracks (question, dataset/sim, metric, deliverable). Which feels clearer and more exciting? Pick that and time-box 6–8 weeks. You can always sample the other afterward.

Tell me your time/week, laptop/GPU situation, and which of the starter projects resonates. I’ll give you exact datasets/sim envs, commands, and a checklist for your first two sessions.