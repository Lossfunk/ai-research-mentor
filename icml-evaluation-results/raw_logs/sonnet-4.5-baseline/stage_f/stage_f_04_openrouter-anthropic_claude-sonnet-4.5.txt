# **VENUE-SPECIFIC FORMATTING & ARTIFACT REQUIREMENTS MAP**
## **"Do Multiple Instance Learning Models Transfer?" - Adapted Submission Plan**

---

## **üìä COMPREHENSIVE VENUE COMPARISON TABLE**

| Venue | Page Limit | Anonymization | Code Release | Data Release | Supplementary | Review Type | Acceptance Rate |
|-------|-----------|---------------|--------------|--------------|---------------|-------------|-----------------|
| **ICLR 2025** | No limit (8-10 typical) | Double-blind | Expected | Expected | Unlimited | Open review | ~30% |
| **CVPR 2025** | 8 pages + refs | Double-blind | Strongly encouraged | Encouraged | Allowed | Double-blind | ~25% |
| **ICML 2025** | 8 pages + refs | Double-blind | Expected | Expected | Unlimited | Double-blind | ~28% |
| **NeurIPS 2025** | 9 pages + refs | Double-blind | Expected | Expected | Unlimited | Double-blind | ~26% |
| **MICCAI 2025** | 8 pages total | Double-blind | Required | Required | 2 pages | Double-blind | ~31% |
| **AISTATS 2025** | 8 pages + refs | Single-blind | Encouraged | Encouraged | Unlimited | Single-blind | ~30% |
| **AAAI 2025** | 7 pages + 1 ref | Double-blind | Encouraged | Encouraged | 2 pages | Double-blind | ~23% |

---

## **üéØ TIER 1: TOP RECOMMENDATIONS FOR MIL TRANSFER**

---

### **OPTION 1: ICLR 2025 (RECOMMENDED PRIMARY)**

#### **üìÖ Timeline**
- **Abstract Deadline**: ~September 28, 2024
- **Submission Deadline**: ~October 1, 2024 (11:59 PM AoE)
- **Reviews Released**: ~December 2024
- **Rebuttal Period**: ~January 2025
- **Decisions**: ~February 2025
- **Camera-Ready**: ~March 2025
- **Conference**: May 2025 (location TBA)

#### **üìè Formatting Requirements**

**Page Structure:**
```
Main Paper: No strict limit, but aim for 8-10 pages
  - Introduction: 1-1.5 pages
  - Related Work: 1-1.5 pages
  - Method: 2-2.5 pages
  - Experiments: 3-4 pages
  - Discussion/Conclusion: 0.5-1 page
  
References: Unlimited (separate section)

Appendix: Unlimited
  - Proofs: As needed
  - Additional experiments: As needed
  - Implementation details: 1-2 pages
  - Broader impact: 0.5-1 page
  - Dataset details: 1-2 pages
```

**LaTeX Template:**
```latex
\documentclass{article}
\usepackage{iclr2025_conference,times}

% CRITICAL: Remove author information for submission
% \author{Anonymous Submission}

% DO NOT include:
% - Author names
% - Affiliations
% - Acknowledgments (add after acceptance)
% - Funding sources

\title{Do Multiple Instance Learning Models Transfer?}

\begin{document}
\maketitle

\begin{abstract}
[250 words max - include problem, method, key results]
\end{abstract}
```

#### **üé≠ Anonymization Requirements (STRICT)**

**‚úÖ MUST DO:**
- [ ] Remove all author names and affiliations
- [ ] Use "Anonymous submission" or leave author field blank
- [ ] Remove acknowledgments section entirely
- [ ] Strip PDF metadata (author, institution)
  ```bash
  # Use this script to clean metadata:
  exiftool -all:all= paper.pdf
  ```
- [ ] Anonymize self-citations:
  - ‚ùå "In our previous work [5], we showed..."
  - ‚úÖ "Prior work [5] showed..."
  - ‚ùå "We extend Smith et al. [5]..." (if you're Smith)
  - ‚úÖ "We extend the approach of [5]..."
- [ ] Use anonymous GitHub repo for code:
  - Create temporary anonymous account
  - OR use Anonymous GitHub: https://anonymous.4open.science/
  - Include in paper: "Code available at [anonymous URL]"
- [ ] Anonymize dataset references if self-collected:
  - ‚ùå "University Hospital X dataset"
  - ‚úÖ "Medical center dataset (details in appendix)"
- [ ] Remove institution-specific compute resources:
  - ‚ùå "Stanford Sherlock cluster"
  - ‚úÖ "University HPC cluster"

**‚ö†Ô∏è ALLOWED (but be careful):**
- [ ] Cite your own published work (treat as any other citation)
- [ ] Include URLs to public datasets
- [ ] Reference standard benchmarks

**üö® COMMON ANONYMIZATION MISTAKES:**
```
‚ùå "We use the dataset from [our institution]"
‚ùå "Experiments run on [specific named cluster]"
‚ùå "Building on [Author's] work, we..." (when you're Author)
‚ùå GitHub links to personal account
‚ùå ArXiv preprint links (if posted close to deadline)
‚ùå "In concurrent work [under review], we..."
```

#### **üíæ Code & Data Release Expectations**

**Code Release (STRONGLY EXPECTED):**
```latex
\section*{Reproducibility Statement}

\textbf{Code Availability:} We commit to releasing all code, model 
architectures, training scripts, and evaluation code under the MIT 
license upon acceptance. 

\textbf{Anonymous Access:} Code is currently available for review at:
\url{https://anonymous.4open.science/r/mil-transfer-XXXX}

\textbf{Post-Acceptance:} Final code will be released at:
\url{https://github.com/[anonymous-for-review]/mil-transfer}

\textbf{Contents:}
\begin{itemize}
\item Training scripts for all source-target pairs
\item Pre-trained model checkpoints
\item Evaluation scripts with all metrics
\item Data preprocessing pipelines
\item Hyperparameter configurations
\item Requirements file (requirements.txt)
\item Docker container for exact environment replication
\end{itemize}
```

**Data Release (EXPECTED where possible):**
```latex
\textbf{Data Availability:}

\textbf{Public Datasets:} We use only publicly available datasets:
\begin{itemize}
\item MNIST-Bags: Available at [URL]
\item Camelyon16: Available at [URL] (requires registration)
\item TCGA-BRCA: Available via dbGaP (accession: phs000178)
\end{itemize}

\textbf{Preprocessing Scripts:} We provide scripts to reproduce our
exact train/val/test splits and bag construction:
- Bag construction: scripts/create\_bags.py
- Data splits: data/splits/ (JSON files with sample IDs)

\textbf{Derived Data:} We will release:
- Extracted features (if using pre-trained encoders)
- Train/val/test split indices
- Preprocessed datasets (where license permits)

\textbf{Restrictions:} Medical datasets (Camelyon16, TCGA) cannot be
redistributed per their licenses. We provide exact access instructions
and preprocessing code to enable full reproduction.
```

#### **üìé Supplementary Material**

**Unlimited appendix (same PDF):**
```
Appendix A: Proofs and Theoretical Analysis
  - Generalization bounds for MIL transfer
  - Domain divergence analysis

Appendix B: Additional Experimental Results
  - Full transfer matrix (all source-target pairs)
  - Per-class performance breakdowns
  - Additional ablation studies
  - Hyperparameter sensitivity analysis

Appendix C: Implementation Details
  - Network architectures (full specifications)
  - Training procedures (pseudocode)
  - Hyperparameter search methodology
  - Compute infrastructure details

Appendix D: Dataset Details
  - Dataset statistics tables
  - Sample visualizations
  - Bag construction methodology
  - Train/val/test split procedures

Appendix E: Broader Impact and Limitations
  - Extended ethics discussion
  - Failure case analysis
  - Societal implications

Appendix F: Reproducibility Checklist
  - ICLR reproducibility checklist (required)
```

**Separate supplementary file (optional):**
- Videos (if applicable)
- High-resolution figures
- Large tables
- Interactive visualizations

#### **‚úÖ ICLR-Specific Checklist**

- [ ] **Reproducibility Checklist** (MANDATORY):
  ```
  Download from: https://iclr.cc/Conferences/2025/AuthorGuide
  
  Required answers:
  ‚úì Code availability: Yes, anonymous link provided
  ‚úì Data availability: Yes, all public datasets listed
  ‚úì Experimental setup: Fully documented in appendix
  ‚úì Hyperparameters: All reported in Table X
  ‚úì Statistical significance: Error bars on all results
  ‚úì Compute resources: GPU hours and carbon footprint reported
  ```

- [ ] **Ethics Review** (if applicable):
  - Triggered if: human subjects, medical data, potential harm
  - Self-assess using ICLR ethics guidelines
  - May require additional review round

- [ ] **OpenReview Submission**:
  - Create OpenReview account
  - Submit PDF + supplementary materials
  - Add keywords: "transfer learning", "multiple instance learning", "domain adaptation"
  - Select subject areas: Machine Learning, Computer Vision (if applicable)

#### **üé® Formatting Best Practices**

```latex
% Font and spacing
\usepackage{times}  % Use Times font
\usepackage{microtype}  % Better typography

% Figures
\usepackage{graphicx}
\usepackage{subcaption}

% Tables
\usepackage{booktabs}  % Professional tables
\usepackage{multirow}

% Math
\usepackage{amsmath,amssymb,amsthm}

% Algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% Example figure
\begin{figure}[t]
\centering
\includegraphics[width=0.9\linewidth]{figures/transfer_matrix.pdf}
\caption{Transfer performance matrix showing AUC for all source‚Üítarget 
domain pairs. Darker colors indicate better transfer. Diagonal shows 
within-domain performance.}
\label{fig:transfer_matrix}
\end{figure}

% Example table
\begin{table}[t]
\centering
\caption{Dataset statistics for MIL transfer experiments.}
\label{tab:datasets}
\begin{tabular}{lcccc}
\toprule
Dataset & Domain & \# Bags & \# Instances & Classes \\
\midrule
MNIST-Bags & Digits & 10,000 & 100K & 10 \\
Camelyon16 & Histopathology & 400 & 1.2M & 2 \\
Tiger & Natural images & 1,220 & 12K & 2 \\
\bottomrule
\end{tabular}
\end{table}
```

---

### **OPTION 2: CVPR 2025 (IF VISION-FOCUSED)**

#### **üìÖ Timeline**
- **Submission Deadline**: November 14, 2024 (11:59 PM PST)
- **Supplementary Deadline**: November 21, 2024
- **Reviews Released**: ~February 2025
- **Rebuttal Period**: ~March 2025
- **Decisions**: ~March 2025
- **Conference**: June 10-17, 2025, Nashville, TN

#### **üìè Formatting Requirements**

**Page Structure (STRICT):**
```
Main Paper: 8 pages MAXIMUM (excluding references)
  - Introduction: 1 page
  - Related Work: 0.75-1 page
  - Method: 2-2.5 pages
  - Experiments: 3-3.5 pages
  - Conclusion: 0.5 page

References: Unlimited (separate section)

Supplementary Material: Separate PDF/ZIP
  - Maximum size: 100 MB
  - Can include: code, data, videos, additional results
  - Appendix: Unlimited pages in supplementary
```

**LaTeX Template:**
```latex
\documentclass[10pt,twocolumn,letterpaper]{article}
\usepackage{cvpr}  % Official CVPR style
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include the review option for submission
\cvprfinalcopy  % Remove for submission, add for camera-ready

% Paper ID (assigned after submission)
\def\cvprPaperID{****}

% Anonymization
\ifcvprfinal
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\else
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}
\fi

\begin{document}

\title{Do Multiple Instance Learning Models Transfer?}

% For submission (anonymous)
\author{Paper ID \cvprPaperID}

% For camera-ready (after acceptance)
% \author{First Author\\
% Institution1\\
% {\tt\small firstauthor@i1.org}
% \and
% Second Author\\
% Institution2\\
% {\tt\small secondauthor@i2.org}
% }

\maketitle
```

#### **üé≠ Anonymization Requirements (VERY STRICT)**

**CVPR has stricter anonymization than ICLR:**

- [ ] **Double-blind review** (reviewers don't know authors, authors don't know reviewers)
- [ ] Remove ALL identifying information:
  - [ ] No author names
  - [ ] No affiliations
  - [ ] No acknowledgments
  - [ ] No grant numbers
  - [ ] No project names that identify institution
- [ ] **Self-citation rules**:
  ```latex
  % Acceptable:
  Prior work [5] proposed attention-based MIL.
  
  % NOT acceptable:
  In our previous work [5], we proposed...
  We extend our earlier method [5]...
  
  % Gray area (avoid):
  Smith et al. [5] showed... (if you're Smith)
  ‚Üí Better: "Previous work [5] showed..."
  ```
- [ ] **Supplementary material anonymization**:
  - [ ] Code must be anonymous (no author names in files)
  - [ ] Remove institutional logos from figures
  - [ ] Anonymize dataset names if self-collected
- [ ] **ArXiv policy**:
  - ‚ö†Ô∏è **DO NOT** post to ArXiv before CVPR deadline
  - ‚ö†Ô∏è Posting to ArXiv can be grounds for rejection
  - Wait until after reviews or acceptance

#### **üíæ Code & Data Release**

**Code Release (STRONGLY ENCOURAGED):**
```latex
% In supplementary material README.txt:

CODE SUBMISSION FOR CVPR 2025 REVIEW
=====================================

This supplementary material contains:
1. Source code for all experiments
2. Pre-trained model checkpoints
3. Evaluation scripts
4. Instructions for reproduction

STRUCTURE:
/code
  /models          - MIL model architectures
  /datasets        - Data loading and preprocessing
  /train.py        - Training script
  /eval.py         - Evaluation script
  /configs         - Hyperparameter configurations
  /requirements.txt - Python dependencies
  /README.md       - Setup and usage instructions

REPRODUCTION:
1. Install dependencies: pip install -r requirements.txt
2. Download datasets: bash scripts/download_data.sh
3. Train models: python train.py --config configs/transfer.yaml
4. Evaluate: python eval.py --checkpoint checkpoints/model.pth

COMPUTE REQUIREMENTS:
- 4√ó NVIDIA V100 GPUs (32GB)
- ~48 hours total training time
- 500GB storage for datasets

POST-ACCEPTANCE:
Upon acceptance, we will release:
- Full code repository on GitHub
- Pre-trained models on HuggingFace
- Processed datasets (where licenses permit)
```

**Supplementary Material Structure:**
```
supplementary.zip (