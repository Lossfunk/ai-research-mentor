# **FINAL SUBMISSION CHECKLIST: Privacy-Preserving NLP Paper**
## **6-Week Countdown Plan with Artifact Requirements & Ethics Compliance**

---

## **üéØ EXECUTIVE SUMMARY**

**Paper Title**: [Privacy-Preserving NLP Paper - specify exact title]  
**Target Venue**: [Specify: ACL/EMNLP/NeurIPS/ICLR - see recommendations below]  
**Deadline**: [Date - 6 weeks from now]  
**High-Risk Areas**: Privacy guarantees, differential privacy implementation, human data, code vulnerabilities

---

## **üìÖ 6-WEEK TIMELINE WITH MILESTONES**

### **WEEK 1 (Days 1-7): Critical Gaps & Ethics Foundation**
**Deadline: [Date]**

#### **Day 1-2: Risk Assessment**
- [ ] **CRITICAL DECISION**: Confirm target venue (see Section 2 below)
- [ ] Identify privacy guarantee level (differential privacy, federated learning, encryption)
- [ ] Audit datasets for privacy compliance
- [ ] Check if human data requires IRB approval

#### **Day 3-5: Ethics Documentation Sprint**
- [ ] **Draft Ethics Statement** (see Section 4)
- [ ] **Draft Privacy Impact Assessment** (see Section 5)
- [ ] **Create Threat Model** (what attacks does your method prevent?)
- [ ] **Document Privacy-Utility Tradeoff Analysis**

#### **Day 6-7: Code Audit**
- [ ] Review code for privacy leaks (see Section 6)
- [ ] Test differential privacy implementation (if applicable)
- [ ] Verify no data leakage in logs/checkpoints
- [ ] Create reproducibility package structure

**‚úÖ WEEK 1 DELIVERABLES:**
- [ ] Ethics statement draft (500-1000 words)
- [ ] Privacy threat model documented
- [ ] Code audit report
- [ ] Venue decision finalized

---

### **WEEK 2 (Days 8-14): Experiments & Artifact Preparation**
**Deadline: [Date]**

#### **Day 8-10: Missing Experiments**
- [ ] **Privacy-critical experiments**:
  - [ ] Privacy budget (Œµ, Œ¥) sensitivity analysis
  - [ ] Membership inference attack resistance
  - [ ] Reconstruction attack resistance (if applicable)
  - [ ] Utility vs. privacy tradeoff curves
- [ ] **Baseline comparisons**:
  - [ ] Non-private baseline (upper bound on utility)
  - [ ] Standard DP-SGD (if applicable)
  - [ ] Other privacy-preserving methods

#### **Day 11-13: Artifact Creation**
- [ ] **Code repository setup** (see Section 7)
- [ ] **Dataset preparation** (see Section 8)
- [ ] **Model checkpoints** (privacy-safe versions only)
- [ ] **Documentation** (README, installation guide)

#### **Day 14: Mid-Point Review**
- [ ] Self-review against venue checklist
- [ ] Verify all figures/tables have captions
- [ ] Check page limit compliance
- [ ] Run plagiarism check (iThenticate/Turnitin)

**‚úÖ WEEK 2 DELIVERABLES:**
- [ ] All experiments complete
- [ ] Code repository 80% ready
- [ ] Artifacts organized
- [ ] First complete draft

---

### **WEEK 3 (Days 15-21): Writing & Compliance**
**Deadline: [Date]**

#### **Day 15-17: Core Writing**
- [ ] **Abstract** (highlight privacy guarantees quantitatively)
- [ ] **Introduction** (motivate privacy risks in NLP)
- [ ] **Method** (formal privacy definition, proofs if applicable)
- [ ] **Experiments** (privacy-utility tradeoff emphasized)
- [ ] **Limitations** (be explicit about what's NOT protected)

#### **Day 18-19: Compliance Sections**
- [ ] **Ethics Statement** (final version)
- [ ] **Broader Impact** (dual-use considerations)
- [ ] **Limitations** (privacy assumptions, failure modes)
- [ ] **Reproducibility Statement**
- [ ] **Data/Code Availability Statement**

#### **Day 20-21: Formatting**
- [ ] Apply venue template (LaTeX)
- [ ] Anonymize paper (see Section 3)
- [ ] Format references (BibTeX cleanup)
- [ ] Create supplementary material PDF

**‚úÖ WEEK 3 DELIVERABLES:**
- [ ] Complete draft with all sections
- [ ] Ethics/compliance sections finalized
- [ ] Formatted to venue standards
- [ ] Supplementary material drafted

---

### **WEEK 4 (Days 22-28): Internal Review & Revision**
**Deadline: [Date]**

#### **Day 22-24: Internal Review**
- [ ] Co-author review round
- [ ] Privacy expert review (CRITICAL - get external eyes)
- [ ] Security expert review (if making security claims)
- [ ] NLP expert review (domain validity)

#### **Day 25-27: Major Revisions**
- [ ] Address co-author feedback
- [ ] Fix experimental gaps
- [ ] Strengthen privacy proofs
- [ ] Improve clarity of privacy guarantees

#### **Day 28: Code Freeze**
- [ ] Finalize code repository
- [ ] Test installation on clean machine
- [ ] Verify reproducibility of key results
- [ ] Create Docker container (recommended)

**‚úÖ WEEK 4 DELIVERABLES:**
- [ ] Revised draft incorporating feedback
- [ ] Code repository complete and tested
- [ ] Privacy guarantees validated by expert
- [ ] All figures finalized

---

### **WEEK 5 (Days 29-35): Artifact Finalization & Testing**
**Deadline: [Date]**

#### **Day 29-31: Artifact Testing**
- [ ] **Code testing**:
  - [ ] Run on fresh environment
  - [ ] Verify privacy budget calculations
  - [ ] Test with different random seeds
  - [ ] Check for data leakage in outputs
- [ ] **Documentation review**:
  - [ ] README complete and clear
  - [ ] API documentation (if applicable)
  - [ ] Usage examples provided
  - [ ] Troubleshooting guide

#### **Day 32-34: Anonymization & Security**
- [ ] **Paper anonymization** (see Section 3)
- [ ] **Code anonymization**:
  - [ ] Remove author names from code comments
  - [ ] Remove institutional references
  - [ ] Remove internal project names
  - [ ] Strip Git history (create clean repo)
- [ ] **Security audit**:
  - [ ] No hardcoded credentials
  - [ ] No internal URLs/paths
  - [ ] No sensitive data in examples

#### **Day 35: Final Compliance Check**
- [ ] Run venue-specific checklist (Section 9)
- [ ] Verify ethics statement completeness
- [ ] Check artifact requirements met
- [ ] Validate supplementary material format

**‚úÖ WEEK 5 DELIVERABLES:**
- [ ] All artifacts tested and working
- [ ] Anonymous code repository ready
- [ ] Paper fully anonymized
- [ ] Compliance checklist 100% complete

---

### **WEEK 6 (Days 36-42): Final Polish & Submission**
**Deadline: [Date]**

#### **Day 36-38: Final Writing Polish**
- [ ] Proofread entire paper
- [ ] Check grammar/spelling (Grammarly)
- [ ] Verify all citations formatted correctly
- [ ] Ensure consistent terminology
- [ ] Check all cross-references (figures, tables, sections)

#### **Day 39-40: Pre-Submission Review**
- [ ] Final co-author approval
- [ ] Legal/compliance review (if institutional policy requires)
- [ ] Privacy disclosure review (ensure no accidental leaks)
- [ ] Export control check (if applicable for cryptography)

#### **Day 41: Submission Package Assembly**
- [ ] **Main PDF**:
  - [ ] Metadata stripped
  - [ ] Fonts embedded
  - [ ] File size within limits
- [ ] **Supplementary Material**:
  - [ ] Code (ZIP or GitHub link)
  - [ ] Appendix (PDF)
  - [ ] Data (if shareable)
  - [ ] README.txt
- [ ] **Submission Form**:
  - [ ] Abstract
  - [ ] Keywords
  - [ ] Subject areas
  - [ ] Conflicts of interest
  - [ ] Ethics/privacy checkboxes

#### **Day 42: SUBMISSION DAY**
- [ ] Submit 2-3 hours before deadline (buffer for technical issues)
- [ ] Verify submission confirmation email
- [ ] Download submitted files (backup)
- [ ] Check submission portal shows "complete"

**‚úÖ WEEK 6 DELIVERABLES:**
- [ ] Paper submitted
- [ ] Confirmation received
- [ ] All materials backed up
- [ ] Post-submission checklist complete

---

## **1. VENUE SELECTION & REQUIREMENTS**

### **üéØ Recommended Venues for Privacy-Preserving NLP**

| Venue | Deadline | Format | Privacy Focus | Artifact Policy |
|-------|----------|--------|---------------|-----------------|
| **ACL 2025** | ~Feb 2025 | 8 pages + refs | ‚≠ê‚≠ê‚≠ê‚≠ê | Encouraged |
| **EMNLP 2025** | ~May 2025 | 8 pages + refs | ‚≠ê‚≠ê‚≠ê‚≠ê | Encouraged |
| **NeurIPS 2025** | ~May 2025 | 9 pages + refs | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Expected |
| **ICLR 2025** | ~Oct 2024 | No limit (8-10) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Expected |
| **CCS 2025** | ~May 2025 | 18 pages total | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Required |
| **USENIX Security** | ~Feb/Aug 2025 | No limit | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Required |
| **S&P (Oakland)** | ~Various | 13 pages | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Required |

**Decision Matrix:**
- **If theoretical DP contribution**: NeurIPS, ICLR
- **If NLP application focus**: ACL, EMNLP
- **If security/privacy primary**: CCS, USENIX Security, S&P
- **If federated learning**: NeurIPS, ICML
- **If cryptographic methods**: CCS, CRYPTO, EUROCRYPT

---

## **2. VENUE-SPECIFIC FORMATTING REQUIREMENTS**

### **ACL/EMNLP 2025**

**Page Limits:**
```
Main Paper: 8 pages (strict)
References: Unlimited
Appendix: Unlimited (in supplementary material)
Supplementary: Separate PDF + code ZIP
```

**Template:**
```latex
\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2025}
\usepackage{times}
\usepackage{latexsym}

% Anonymization for review
\aclfinalcopy  % Remove this line for submission

\title{Privacy-Preserving [Your Specific Method] for [Task]}

% For submission:
\author{Anonymous Submission}

% For camera-ready (after acceptance):
% \author{First Author \\ Institution \\ \texttt{email} 
%   \And Second Author \\ Institution \\ \texttt{email}}
```

**Anonymization (Double-Blind):**
- [ ] Remove author names/affiliations
- [ ] Anonymize self-citations: "Prior work [X]" not "Our work [X]"
- [ ] Remove acknowledgments
- [ ] Anonymize code repositories (use Anonymous GitHub)
- [ ] Remove institutional references in examples
- [ ] Strip PDF metadata

**Ethics Requirements:**
```latex
\section*{Ethics Statement}

\textbf{Privacy Guarantees:} This work implements differential privacy 
with (Œµ=X, Œ¥=Y)-DP guarantees. We formally prove privacy in Appendix A.

\textbf{Data Sources:} We use publicly available datasets [list]. All 
datasets were collected with participant consent per original studies.

\textbf{Limitations:} Our privacy guarantees assume [honest-but-curious 
adversary / trusted aggregator / etc.]. Protections do not extend to 
[specific threats].

\textbf{Dual-Use:} While privacy-preserving methods enable beneficial 
applications (medical NLP, personal assistants), they may also obscure 
malicious use. We recommend [specific safeguards].

\textbf{Reproducibility:} Code released at [anonymous URL] with privacy 
audit logs.
```

**Artifact Requirements (Encouraged):**
- [ ] Code repository (GitHub/GitLab)
- [ ] README with installation instructions
- [ ] Requirements.txt / environment.yml
- [ ] Example usage scripts
- [ ] Pre-trained models (if privacy-safe)
- [ ] Evaluation scripts
- [ ] Privacy budget tracking logs

---

### **NeurIPS 2025**

**Page Limits:**
```
Main Paper: 9 pages (strict, excluding references)
References: Unlimited
Appendix: Unlimited (same PDF)
Supplementary: Separate ZIP (100MB limit)
```

**Template:**
```latex
\documentclass{article}
\usepackage{neurips_2025}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}

\title{Privacy-Preserving [Method] for [Task]}

% Anonymization
\author{
  Anonymous Authors \\
  Anonymous Institution \\
  \texttt{anonymous@email.com}
}
```

**Anonymization (Double-Blind):**
- Same as ACL, plus:
- [ ] Do NOT post to ArXiv before submission
- [ ] Avoid phrases like "concurrent work" that reveal identity
- [ ] Anonymize dataset names if self-collected
- [ ] Remove internal project codenames

**Ethics Requirements (MANDATORY):**
```latex
\section*{Ethics Statement}

\subsection*{Privacy Guarantees and Limitations}
We provide (Œµ, Œ¥)-differential privacy with Œµ=[value], Œ¥=[value]. 
This protects against [specific attacks] but does NOT protect against 
[other attacks]. Assumptions: [list all assumptions].

\subsection*{Data and Consent}
All datasets are publicly available and de-identified. Original data 
collection obtained informed consent (citations provided).

\subsection*{Broader Impact}
\textbf{Positive:} Enables privacy-preserving analysis of sensitive 
text (medical records, personal communications).

\textbf{Negative:} May reduce model utility, potentially creating 
disparate impact on underrepresented groups. Privacy guarantees may 
give false sense of security if assumptions violated.

\textbf{Mitigation:} We provide clear documentation of assumptions 
and failure modes. We test for fairness degradation (Section X).

\subsection*{Dual-Use Considerations}
Privacy-preserving NLP can enable both beneficial (healthcare) and 
harmful (surveillance evasion) applications. We recommend:
- Mandatory privacy audits before deployment
- Clear communication of limitations to end users
- Regulatory oversight for high-stakes applications
```

**Artifact Requirements (STRONGLY EXPECTED):**

**Code Submission (via CMT):**
```
supplementary/
‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îú‚îÄ‚îÄ README.md                 # Installation & usage
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îÇ   ‚îú‚îÄ‚îÄ setup.py                  # Package setup
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/               # Model architectures
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ privacy/              # DP mechanisms
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data/                 # Data loading
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/                # Helper functions
‚îÇ   ‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Training script
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py           # Evaluation script
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ privacy_audit.py      # Privacy budget tracking
‚îÇ   ‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ experiment_configs.yaml
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_privacy.py       # Privacy unit