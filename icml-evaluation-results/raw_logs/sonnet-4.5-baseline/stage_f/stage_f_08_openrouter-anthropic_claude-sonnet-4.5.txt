# **VENUE-SPECIFIC SUBMISSION PLAN: Robotics Safety Paper**
## **Complete Guide with Video Requirements, Artifacts, and Ethics Review**

---

## **ðŸŽ¯ EXECUTIVE SUMMARY**

**Paper Type**: Robotics Safety  
**High-Priority Requirements**:
- Supplementary videos (MANDATORY for most robotics venues)
- Hardware/software artifacts (code, CAD files, datasets)
- Safety evaluation protocols
- Human-robot interaction ethics (if applicable)
- Real-world deployment considerations

**Critical Timeline**: Video production requires 2-3 weeks minimum

---

## **ðŸ“Š SECTION 1: VENUE COMPARISON & RECOMMENDATIONS**

### **Top-Tier Robotics Venues for Safety Research**

| Venue | Deadline | Video Req. | Page Limit | Acceptance | Best For |
|-------|----------|------------|------------|------------|----------|
| **RSS 2025** | ~Feb 2025 | **REQUIRED** | 8 pages + refs | ~27% | Novel safety algorithms |
| **ICRA 2025** | ~Sep 2024 | **REQUIRED** | 8 pages total | ~43% | Broad robotics safety |
| **IROS 2025** | ~Mar 2025 | **REQUIRED** | 8 pages total | ~45% | Applied safety systems |
| **CoRL 2025** | ~Jun 2025 | **REQUIRED** | 8 pages + refs | ~30% | Learning-based safety |
| **IJRR** | Rolling | Encouraged | No limit | ~15% | Comprehensive safety theory |
| **RA-L** | Rolling | Encouraged | 6 pages + refs | ~50% | Concise safety methods |
| **HRI 2025** | ~Oct 2024 | Encouraged | 8 pages + refs | ~25% | Human-robot safety |
| **SafeAI @ AAAI** | ~Nov 2024 | Optional | 7 pages | ~40% | AI safety focus |

---

## **ðŸŽ¬ SECTION 2: SUPPLEMENTARY VIDEO REQUIREMENTS**

### **2.1 Video Specifications by Venue**

#### **RSS 2025 (Robotics: Science and Systems)**

**Video Requirements (MANDATORY)**:
```
Format: MP4 (H.264 codec)
Resolution: 1920Ã—1080 (1080p minimum), 4K acceptable
Frame Rate: 30 fps minimum
Duration: 1-3 minutes (STRICT - longer videos may be rejected)
File Size: 100 MB maximum (upload limit)
Audio: Optional but recommended (narration or captions)
Submission: Uploaded via CMT with paper submission
```

**Content Requirements**:
- [ ] **Robot hardware demonstration** (show physical system)
- [ ] **Safety scenario visualization** (demonstrate failure modes)
- [ ] **Real-world experiments** (not just simulation)
- [ ] **Comparison to baselines** (side-by-side if possible)
- [ ] **Clear captions/annotations** (explain what's happening)
- [ ] **Failure cases** (show limitations, not just successes)

**RSS-Specific Video Structure**:
```
0:00-0:10  Title card with paper title
0:10-0:30  Problem motivation (show unsafe behavior)
0:30-1:30  Proposed method demonstration (show safe behavior)
1:30-2:30  Experimental results (quantitative + qualitative)
2:30-2:50  Comparison to baselines
2:50-3:00  Conclusion + acknowledgments (optional)
```

**Example Script Template**:
```
[0:00-0:10] TITLE CARD
"Safe Navigation in Dynamic Environments via 
Predictive Shielding"

[0:10-0:30] PROBLEM SETUP
Narration: "Traditional motion planners struggle with 
unpredictable obstacles, leading to collisions."
Visual: Show robot colliding with moving obstacle (baseline)
Caption: "Baseline: 23% collision rate"

[0:30-1:30] METHOD DEMONSTRATION
Narration: "Our predictive shielding method anticipates 
obstacle motion and adjusts the robot's trajectory."
Visual: Split-screen showing:
  - Left: Predicted obstacle trajectories (colored overlays)
  - Right: Robot's safe trajectory (green path)
Caption: "Our method: 2% collision rate"

[1:30-2:30] EXPERIMENTAL RESULTS
Visual: Montage of different scenarios:
  - Crowded environment (10+ obstacles)
  - High-speed motion
  - Narrow corridors
Caption: "100 trials across 5 environments"

[2:30-2:50] COMPARISON
Visual: Bar chart animation showing:
  - Success rate: Baseline 77% vs. Ours 98%
  - Computation time: Baseline 50ms vs. Ours 45ms

[2:50-3:00] CONCLUSION
Visual: Robot successfully completing complex task
Caption: "Code available at: [anonymous URL]"
```

---

#### **ICRA 2025 (IEEE International Conference on Robotics and Automation)**

**Video Requirements (MANDATORY)**:
```
Format: MP4 or AVI
Resolution: 640Ã—480 minimum (720p or 1080p recommended)
Duration: Maximum 5 minutes (3 minutes recommended)
File Size: 500 MB maximum
Audio: Required (narration or music + captions)
Submission: YouTube link (unlisted) + uploaded file
```

**ICRA-Specific Requirements**:
- [ ] **IEEE copyright notice** (if using copyrighted music)
- [ ] **Narration or detailed captions** (accessibility requirement)
- [ ] **Safety disclaimers** (if showing risky scenarios)
- [ ] **Experimental protocol description** (IRB approval if humans involved)

**Video Checklist**:
```latex
% Include in paper:
\section*{Multimedia Material}
A video demonstrating our safe navigation system is available 
as supplementary material and at: 

\url{https://youtu.be/[UNLISTED-LINK]}

The video shows:
\begin{itemize}
\item Real-world experiments with a mobile robot in dynamic environments
\item Comparison between baseline and proposed safety methods
\item Quantitative results across 100 trials
\item Failure case analysis
\end{itemize}

All experiments were conducted following institutional safety 
protocols [reference safety approval].
```

---

#### **CoRL 2025 (Conference on Robot Learning)**

**Video Requirements (MANDATORY)**:
```
Format: MP4 (H.264)
Resolution: 1080p minimum
Duration: 1-2 minutes (shorter is better)
File Size: 50 MB maximum (strict)
Audio: Optional
Submission: Embedded in supplementary PDF or separate upload
Anonymization: REQUIRED (no lab names, logos, or identifying features)
```

**CoRL Anonymization Requirements (CRITICAL)**:
- [ ] **Blur lab backgrounds** (remove posters, logos, distinctive features)
- [ ] **Remove audio** if it contains identifying information (voices, names)
- [ ] **Anonymize robot names** (don't show "Stanford Robot Lab" on chassis)
- [ ] **Remove timestamps** that could identify location/timezone
- [ ] **Generic captions** (no institutional affiliations)

**Video Anonymization Script**:
```python
import cv2
import numpy as np

def anonymize_video(input_path, output_path, blur_regions):
    """
    Blur specified regions in video for anonymization
    
    blur_regions: list of (x1, y1, x2, y2, start_frame, end_frame)
    """
    cap = cv2.VideoCapture(input_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_num = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # Apply blur to specified regions
        for region in blur_regions:
            x1, y1, x2, y2, start_f, end_f = region
            if start_f <= frame_num <= end_f:
                roi = frame[y1:y2, x1:x2]
                blur = cv2.GaussianBlur(roi, (51, 51), 0)
                frame[y1:y2, x1:x2] = blur
        
        # Add anonymization watermark
        cv2.putText(frame, "Anonymized for review", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        out.write(frame)
        frame_num += 1
    
    cap.release()
    out.release()

# Example usage:
anonymize_video(
    'robot_demo.mp4',
    'robot_demo_anonymous.mp4',
    blur_regions=[
        (50, 50, 300, 200, 0, 500),    # Blur lab logo (frames 0-500)
        (800, 600, 1200, 800, 0, 1000) # Blur poster (frames 0-1000)
    ]
)
```

---

### **2.2 Video Production Guide**

#### **Equipment & Software**

**Minimum Equipment**:
- Camera: Smartphone (iPhone 11+ or equivalent Android)
- Microphone: Built-in OK, lapel mic recommended
- Lighting: Natural light + desk lamp
- Tripod: $20 basic tripod sufficient

**Recommended Equipment**:
- Camera: DSLR or mirrorless (Sony A7, Canon EOS)
- Microphone: Blue Yeti or Rode VideoMic
- Lighting: 2-point lighting setup
- Tripod: Fluid head for smooth panning

**Software Options**:

| Software | Cost | Platform | Best For |
|----------|------|----------|----------|
| **iMovie** | Free | Mac | Quick editing, beginners |
| **DaVinci Resolve** | Free | All | Professional editing |
| **Adobe Premiere** | $20/mo | All | Full-featured editing |
| **Camtasia** | $250 | All | Screen recording + editing |
| **FFmpeg** | Free | All | Command-line processing |

**Quick Editing with FFmpeg**:
```bash
# Trim video
ffmpeg -i input.mp4 -ss 00:00:10 -to 00:02:30 -c copy output.mp4

# Compress to meet size limits
ffmpeg -i input.mp4 -vcodec h264 -crf 28 output.mp4

# Add captions from SRT file
ffmpeg -i input.mp4 -vf subtitles=captions.srt output.mp4

# Convert to required format
ffmpeg -i input.avi -c:v libx264 -c:a aac -strict experimental output.mp4

# Create thumbnail for video
ffmpeg -i input.mp4 -ss 00:00:05 -vframes 1 thumbnail.jpg

# Concatenate multiple clips
# Create file list.txt with: file 'clip1.mp4' \n file 'clip2.mp4'
ffmpeg -f concat -safe 0 -i list.txt -c copy output.mp4
```

#### **Video Shooting Best Practices**

**Camera Setup**:
```
Distance: 1.5-3 meters from robot
Angle: Slightly elevated (30-45 degrees) for better depth perception
Framing: Robot centered with 20% margin for movement
Focus: Manual focus on robot (avoid autofocus hunting)
White Balance: Manual (avoid color shifts between scenes)
```

**Lighting Setup**:
```
Key Light: 45 degrees to left/right of camera, elevated
Fill Light: Opposite side, lower intensity (50% of key)
Back Light: Behind robot, highlights edges (optional)
Avoid: Direct sunlight (harsh shadows), overhead fluorescent (flicker)
```

**Common Mistakes to Avoid**:
- âŒ Shaky handheld footage (use tripod)
- âŒ Poor audio (background noise, echo)
- âŒ Too fast pacing (give viewers time to understand)
- âŒ No context (show scale, environment)
- âŒ Only successes (show failures for credibility)
- âŒ Overly long (respect time limits)
- âŒ No captions (accessibility issue)

#### **Accessibility Requirements**

**Captions/Subtitles (REQUIRED for many venues)**:
```srt
1
00:00:00,000 --> 00:00:05,000
Our robot navigates safely in dynamic environments

2
00:00:05,000 --> 00:00:10,000
Traditional methods (red) collide with obstacles

3
00:00:10,000 --> 00:00:15,000
Our method (green) predicts and avoids collisions
```

**Generate Captions Automatically**:
- **YouTube**: Upload video, use auto-caption, then edit
- **Rev.com**: $1.25/minute human transcription
- **Otter.ai**: Free AI transcription (decent quality)
- **Whisper (OpenAI)**: Free, local, high-quality

```python
# Using OpenAI Whisper for captions
import whisper

model = whisper.load_model("base")
result = model.transcribe("robot_video.mp4")

# Export as SRT
with open("captions.srt", "w") as f:
    for i, segment in enumerate(result["segments"]):
        f.write(f"{i+1}\n")
        f.write(f"{format_timestamp(segment['start'])} --> "
                f"{format_timestamp(segment['end'])}\n")
        f.write(f"{segment['text'].strip()}\n\n")
```

---

## **ðŸ“¦ SECTION 3: ARTIFACT REQUIREMENTS**

### **3.1 Code Artifacts**

**Required Code Components**:

```
robotics-safety-code/
â”œâ”€â”€ README.md                       # âœ… CRITICAL
â”‚   â”œâ”€â”€ Installation (step-by-step)
â”‚   â”œâ”€â”€ Hardware requirements
â”‚   â”œâ”€â”€ Software dependencies
â”‚   â”œâ”€â”€ Quick start guide
â”‚   â”œâ”€â”€ Reproduction instructions
â”‚   â””â”€â”€ Troubleshooting
â”‚
â”œâ”€â”€ LICENSE                         # âœ… CRITICAL (MIT/BSD/Apache recommended)
â”‚
â”œâ”€â”€ requirements.txt                # âœ… Python dependencies
â”œâ”€â”€ environment.yml                 # âœ… Conda environment
â”œâ”€â”€ setup.py                        # âœ… Package installation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ safety/                     # âœ… Core safety algorithms
â”‚   â”‚   â”œâ”€â”€ collision_avoidance.py
â”‚   â”‚   â”œâ”€â”€ predictive_shielding.py
â”‚   â”‚   â””â”€â”€ safety_monitor.py
â”‚   â”œâ”€â”€ planning/                   # âœ… Motion planning
â”‚   â”œâ”€â”€ perception/                 # âœ… Perception modules
â”‚   â”œâ”€â”€ control/                    # âœ… Control loops
â”‚   â””â”€â”€ utils/                      # âœ… Helper functions
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ robot_params.yaml           # âœ… Robot specifications
â”‚   â”œâ”€â”€ safety_params.yaml          # âœ… Safety thresholds
â”‚   â””â”€â”€ experiment_configs/         # âœ… All experimental setups
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_simulation.py           # âœ… Simulation experiments
â”‚   â”œâ”€â”€ run_hardware.py             # âœ… Hardware experiments
â”‚   â”œâ”€â”€ reproduce_table1.sh         # âœ… Reproduce specific results
â”‚   â”œâ”€â”€ reproduce_figure3.sh        # âœ… Generate figures
â”‚   â””â”€â”€ visualize_results.py        # âœ… Visualization tools
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ datasets/                   # âœ… Experimental data
â”‚   â”‚   â”œâ”€â”€ trajectories/
â”‚   â”‚   â”œâ”€â”€ sensor_logs/
â”‚   â”‚   â””â”€â”€ collision_events/
â”‚   â”œâ”€â”€ download_data.sh            # âœ… Data download script
â”‚   â””â”€â”€ README