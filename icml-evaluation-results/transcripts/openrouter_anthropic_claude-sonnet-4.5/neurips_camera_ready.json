{
  "scenario": {
    "scenario_id": "neurips_camera_ready",
    "topic": "diffusion models for molecular generation",
    "persona": "postdoc preparing camera-ready for NeurIPS",
    "constraints": "need to finalize supplementary materials, code release, and address minor revisions",
    "extra": {
      "stage": "F"
    }
  },
  "system_id": "openrouter:anthropic/claude-sonnet-4.5",
  "stop_reason": "goal_reached",
  "stopped_by_student": true,
  "error": null,
  "turn_count": 4,
  "elapsed_seconds": 246.35355806350708,
  "transcript": [
    {
      "role": "user",
      "content": "Hey, I'm postdoc preparing camera-ready for NeurIPS. I want to get started in research in diffusion models for molecular generation. Constraints: need to finalize supplementary materials, code release, and address minor revisions. How should I start?",
      "turn": 0
    },
    {
      "role": "assistant",
      "content": "Great! Based on the search results, here's a strategic plan that respects your time constraints:\n\n## Immediate Action Plan (While Finishing Camera-Ready)\n\n### **Phase 1: Quick Orientation (This Week - Low Time Investment)**\n\nWhile handling your NeurIPS revisions, do these **lightweight** activities:\n\n1. **Read 2-3 foundational papers** (skim during breaks):\n   - **GeoDiff** (Xu et al., 2022) - The foundational geometric diffusion model for molecules\n   - **Torsional Diffusion** (Jing et al., 2022) - Clever approach using torsion angles\n   - **Graph DiT** (Liu et al., 2024) - Recent transformer-based approach with multi-conditional generation\n\n2. **Bookmark key resources**:\n   - Tutorial: https://github.com/gerritgr/diffusion_gnn_tutorial (GNN + Diffusion tutorial from 2024)\n   - Recent review on diffusion for proteins/molecules (Yim 2024)\n\n### **Phase 2: Deep Dive (After Camera-Ready Submission)**\n\nOnce your supplementary materials and code release are done:\n\n1. **Core Technical Understanding**:\n   - Study the E(3)-equivariance requirements (critical for 3D molecules)\n   - Understand the trade-offs: Graph vs 3D representations\n   - Recent advances: Frame-based methods, Clifford algebra approaches\n\n2. **Identify Your Niche** - Hot areas from the papers:\n   - **Training-free guidance** (Kerby & Moon, 2024) - New frontier\n   - **Scalability/acceleration** (Das et al., 2026; Ni et al., 2025) - Addressing sampling bottlenecks\n   - **Multi-conditional generation** (Graph DiT) - Practical applications\n   - **Latent diffusion for molecules** (Lacombe & Vaidya, 2024)\n\n3. **Hands-on**:\n   - Clone repos from GeoDiff or Torsional Diffusion\n   - Experiment with molecular datasets (QM9, GEOM-Drugs)\n\n## Practical Tips for Your Situation\n\n**For the next 1-2 weeks (camera-ready mode)**:\n- ‚úÖ Spend 30 min/day reading abstracts and skimming papers\n- ‚úÖ Join relevant Discord/Slack communities (Valence Labs, etc.)\n- ‚úÖ Set up a Zotero/Notion library for papers\n- ‚ùå Don't try to implement anything yet\n- ‚ùå Don't go deep on math - just get intuition\n\n**After submission**:\n- Dedicate 1-2 weeks to intensive learning\n- Reproduce a baseline model\n- Identify gaps in current methods (your future research direction)\n\n## Key Research Questions (2024-2025)\n\nBased on recent papers, open problems include:\n- **Speed**: Models still need 100s-1000s of steps\n- **Discrete guidance**: Training-free guidance for discrete diffusion is nascent\n- **Scalability**: Large molecular libraries remain challenging\n- **Controllability**: Multi-property optimization needs work\n\nWould you like me to search for specific code repositories or provide more details on any particular aspect once you're through with your camera-ready deadline?",
      "turn": 1
    },
    {
      "role": "user",
      "content": "This plan is perfect for my current bandwidth. Regarding the 'E(3)-equivariance' you mentioned for Phase 2, are there specific lightweight tutorials or blog posts that explain the implementation of equivariant layers in diffusion without diving into a full textbook?",
      "turn": 1
    },
    {
      "role": "assistant",
      "content": "Perfect! I found some excellent lightweight resources for you. Here are the **best practical tutorials** that explain E(3)-equivariance without requiring a textbook:\n\n## üéØ Top Recommendations (Ranked by Accessibility)\n\n### **1. TeachOpenCADD Talktorial (BEST FOR YOU!)**\n**URL:** https://projects.volkamerlab.org/teachopencadd/talktorials/T036_e3_equivariant_gnn.html\n\n- ‚úÖ **Interactive Jupyter notebook** with code you can run\n- ‚úÖ Specifically designed for **molecules with 3D conformers**\n- ‚úÖ Step-by-step implementation walkthrough\n- ‚úÖ Part of a well-maintained educational series\n- **Time investment:** 2-3 hours\n\nThis is **perfect** for your situation - it's practical, molecular-focused, and you can work through it in an evening.\n\n### **2. EGNN Paper (Satorras et al., 2021)**\n**arXiv:** https://arxiv.org/abs/2102.09844\n\n- ‚úÖ **Surprisingly readable** for a research paper\n- ‚úÖ Introduces the simplest practical equivariant architecture\n- ‚úÖ Avoids expensive higher-order representations (unlike older methods)\n- ‚úÖ Clear mathematical formulation that's actually implementable\n- **Key insight:** Shows you can achieve equivariance with simple distance-based message passing\n\n**Read:** Sections 2-3 for the core idea (skip heavy theory in appendix initially)\n\n### **3. Code Repositories with Good Documentation**\n\n**GeoDiff/EDM Implementation:**\n- https://github.com/ehoogeboom/e3_diffusion_for_molecules\n- Clean implementation of E(3) equivariant diffusion\n- **Pro tip:** Read the `egnn.py` or `dynamics.py` files - they're well-commented\n\n## üìö Quick Conceptual Primers\n\n### **Blog Post Style:**\nUnfortunately, E(3)-equivariance is still mostly covered in papers rather than blog posts, BUT here's the **5-minute conceptual explanation**:\n\n**E(3)-Equivariance in Plain English:**\n- **E(3)** = Euclidean group in 3D (rotations, translations, reflections)\n- **Equivariance** = If you transform the input, the output transforms predictably\n- **Why it matters:** Molecules don't care how you rotate/translate them in space\n\n**Implementation Key Ideas:**\n1. **Use pairwise distances** (rotation/translation invariant)\n2. **Update coordinates using equivariant operations** (e.g., weighted sums of relative positions)\n3. **Never directly use absolute coordinates** in non-equivariant ways\n\n### **Minimal Code Pattern (EGNN-style):**\n```python\n# Invariant features (don't change with rotation)\ndistances = ||x_i - x_j||  # scalar distances\n\n# Equivariant updates (transform correctly)\nx_i_new = x_i + Œ£_j (x_i - x_j) * œÜ(distances, features)\n#              ‚Üë relative positions weighted by learned function\n```\n\n## üéì Learning Path for Phase 2\n\n**Week 1 (Post camera-ready):**\n1. **Day 1-2:** Work through TeachOpenCADD tutorial\n2. **Day 3-4:** Read EGNN paper (Satorras et al.)\n3. **Day 5:** Clone EDM repo and trace through one forward pass\n\n**Week 2:**\n1. Study how GeoDiff/EDM apply EGNN to diffusion\n2. Implement a toy example on QM9\n\n## Additional Resources Found\n\n- **Relaxed Equivariance** (Hofgard et al., 2024): Interesting recent work on *learning* when to break symmetry - could be a research direction!\n- **e3nn library**: Industry-standard PyTorch library for equivariant networks (steeper learning curve, but powerful)\n\n## Quick Reference Card\n\n**When reading papers, look for:**\n- ‚úÖ \"Invariant\" = scalar quantities (distances, angles)\n- ‚úÖ \"Equivariant\" = vector/tensor quantities that transform\n- ‚úÖ \"SE(3)\" vs \"E(3)\" = SE(3) excludes reflections, E(3) includes them\n- ‚úÖ \"Frame-based methods\" = Alternative approach using local coordinate frames\n\n---\n\n**My recommendation:** Start with the TeachOpenCADD tutorial this weekend (if you have a couple free hours), then read the EGNN paper next week. These two resources will give you 80% of what you need without drowning in formalism.\n\nWant me to search for any specific aspect (e.g., how equivariance interacts with the diffusion denoising process)?",
      "turn": 2
    },
    {
      "role": "user",
      "content": "This is exactly the 'no-nonsense' entry point I needed. Could you briefly explain how the equivariant update in the EGNN specifically handles the noise prediction step in a diffusion framework compared to a standard Gaussian diffusion model?",
      "turn": 2
    },
    {
      "role": "assistant",
      "content": "Excellent question! This is the **key conceptual bridge** between equivariant networks and diffusion. Let me break it down:\n\n## Standard Gaussian Diffusion (e.g., images)\n\n**Noise prediction:**\n```python\n# Input: noisy image x_t\n# Output: predicted noise Œµ_Œ∏(x_t, t)\n# Both are just tensors - no constraints\n\nx_t = x_0 + noise\npredicted_noise = UNet(x_t, t)  # arbitrary neural network\nx_0_pred = x_t - predicted_noise\n```\n\n**Key:** The network can be *any* architecture. No geometric constraints.\n\n## E(3)-Equivariant Diffusion (molecules)\n\n**The Challenge:**\n- Molecular coordinates are **3D positions** (N √ó 3)\n- Noise on positions must respect E(3) symmetry\n- **If you rotate the noisy molecule, the predicted noise should rotate too**\n\n**The Solution (GeoDiff/EDM approach):**\n\n```python\n# Input: noisy positions h_t (N √ó 3) + node features\n# Output: predicted noise Œµ_Œ∏(h_t, t) that is EQUIVARIANT\n\n# Forward diffusion (same as standard)\nh_t = h_0 + Œµ, where Œµ ~ N(0, œÉ_t¬≤I)  # Gaussian noise on coordinates\n\n# Denoising with EGNN\n# Key: Use equivariant network for noise prediction\npredicted_noise = EGNN(h_t, features, t)  # MUST be equivariant\n\n# The magic: EGNN update preserves equivariance\nfor layer in EGNN:\n    # 1. Compute invariant messages (distances)\n    d_ij = ||h_i - h_j||  # scalar, rotation-invariant\n    \n    # 2. Update node features (invariant)\n    m_i = Œ£_j MLP([features_i, features_j, d_ij, t])\n    \n    # 3. Equivariant coordinate update\n    Œîh_i = Œ£_j (h_i - h_j) * w_ij(features, d_ij, t)\n    #          ‚Üë relative positions  ‚Üë scalar weights\n    \n# Final predicted noise is equivariant!\n```\n\n## The Critical Difference\n\n### **Standard Diffusion:**\n- Noise: Œµ ‚àà ‚Ñù^d (arbitrary vector)\n- Network: Can use any architecture (CNN, Transformer, etc.)\n\n### **Equivariant Diffusion:**\n- Noise: Œµ ‚àà ‚Ñù^(N√ó3) but must be **equivariant**\n- Network: **Must use equivariant architecture** (EGNN, SE(3)-Transformer, etc.)\n- **Constraint:** If you rotate input ‚Üí predicted noise rotates identically\n\n## Concrete Example\n\nImagine a water molecule (H‚ÇÇO):\n\n```\nOriginal position:     Rotated 90¬∞:\nO: (0, 0, 0)          O: (0, 0, 0)\nH: (1, 0, 0)          H: (0, 1, 0)\nH: (0, 1, 0)          H: (-1, 0, 0)\n\nNoisy version:         Rotated noisy:\nO: (0.1, 0.05, 0)     O: (-0.05, 0.1, 0)\nH: (1.2, -0.1, 0)     H: (0.1, 1.2, 0)\nH: (-0.15, 0.9, 0)    H: (-0.9, -0.15, 0)\n\nPredicted noise:       Rotated predicted:\nŒµ_O: (0.1, 0.05, 0)   Œµ_O: (-0.05, 0.1, 0)  ‚Üê MUST match rotation!\nŒµ_H1: (0.2, -0.1, 0)  Œµ_H1: (0.1, 0.2, 0)\nŒµ_H2: (-0.15, -0.1, 0) Œµ_H2: (0.1, -0.15, 0)\n```\n\n**With standard network:** No guarantee the predicted noise respects this rotation symmetry.\n\n**With EGNN:** The architecture **guarantees** this property by construction.\n\n## Why This Matters for Diffusion\n\n### **1. Sample Efficiency**\n- The model doesn't waste capacity learning \"this molecule rotated\" as separate examples\n- **Learns faster** with less data\n\n### **2. Physical Correctness**\n- Generated molecules have **consistent geometry** regardless of orientation\n- Avoids artifacts from coordinate system choice\n\n### **3. Translation Invariance Trick**\nMost implementations add a clever detail:\n\n```python\n# Center coordinates before processing (translation invariance)\nh_t_centered = h_t - h_t.mean(dim=0)  # center of mass at origin\n\n# Process with EGNN\npredicted_noise = EGNN(h_t_centered, features, t)\n\n# Noise is automatically translation-invariant!\n# (because relative positions h_i - h_j don't change with translation)\n```\n\n## Practical Implementation Detail\n\n**GeoDiff/EDM specifically:**\n\n```python\nclass EquivariantDiffusion:\n    def denoise_step(self, h_t, t):\n        # h_t: noisy coordinates (N, 3)\n        \n        # Option 1: Predict noise (Œµ-prediction)\n        predicted_eps = self.egnn(h_t, t)\n        h_0_pred = h_t - sqrt(alpha_t) * predicted_eps\n        \n        # Option 2: Predict clean coordinates (x-prediction)\n        h_0_pred = self.egnn(h_t, t)  # directly predict clean structure\n        \n        # Option 3: Predict score (score-based)\n        score = self.egnn(h_t, t)  # ‚àálog p(h_t)\n        h_0_pred = h_t + sigma_t¬≤ * score\n        \n        # All work! Just need EGNN to be equivariant\n        return h_0_pred\n```\n\n**The key:** Regardless of parameterization (Œµ, x‚ÇÄ, or score), the **network output must be equivariant**.\n\n## Quick Comparison Table\n\n| Aspect | Standard Diffusion | E(3)-Equivariant Diffusion |\n|--------|-------------------|---------------------------|\n| **Noise** | Unconstrained Œµ ~ N(0,I) | Same, but on 3D coords |\n| **Network** | Any (UNet, Transformer) | EGNN, SE(3)-Transformer |\n| **Constraint** | None | Output must rotate with input |\n| **Loss** | MSE on noise/x‚ÇÄ | Same MSE, but equivariance implicit |\n| **Training** | Standard | Standard (equivariance is architectural) |\n\n## The Beautiful Part\n\nYou **don't need special loss functions** or training procedures! The equivariance is **baked into the architecture**. You just:\n\n1. Use EGNN instead of UNet\n2. Train with standard diffusion loss: `||Œµ - Œµ_Œ∏(h_t, t)||¬≤`\n3. Equivariance comes \"for free\" from the EGNN structure\n\n---\n\n**Bottom line:** The EGNN handles noise prediction **exactly like standard diffusion** (same forward/reverse process, same loss), but the architecture guarantees that predicted noise transforms correctly under rotations/translations. This is why understanding EGNN is crucial - it's the \"drop-in replacement\" that makes diffusion work for molecules.\n\nDoes this clarify the connection? Happy to dive deeper into any specific aspect!",
      "turn": 3
    },
    {
      "role": "user",
      "content": "That 'drop-in replacement' analogy is perfect for my mental model. Since I'm finalizing my NeurIPS code release now, are there any specific 'gotchas' regarding the zero-center-of-mass (CoM) constraint during the sampling loop that I should watch out for to ensure the likelihood remains valid?",
      "turn": 3
    },
    {
      "role": "assistant",
      "content": "Excellent question - this is a **critical implementation detail** that's often glossed over in papers but can break your model in subtle ways! Let me give you the practical gotchas:\n\n## üö® Critical Gotchas for Zero-CoM Constraint\n\n### **Gotcha #1: Naive Re-centering Breaks the Diffusion Process**\n\n**The Problem:**\n```python\n# ‚ùå WRONG - Common mistake!\ndef sampling_step(h_t, t):\n    # Predict noise\n    eps_pred = model(h_t, t)\n    \n    # Reverse diffusion step\n    h_t_minus_1 = sample_from_posterior(h_t, eps_pred, t)\n    \n    # Re-center naively\n    h_t_minus_1 = h_t_minus_1 - h_t_minus_1.mean(dim=0)  # ‚ö†Ô∏è BREAKS LIKELIHOOD!\n    \n    return h_t_minus_1\n```\n\n**Why it breaks:** The re-centering is a **deterministic projection** that's not accounted for in the diffusion posterior. You're effectively sampling from a different distribution than what you trained on.\n\n### **Gotcha #2: The Forward Process Must Preserve CoM**\n\n**The Solution (from EDM paper):**\n\nThe key insight is that if you start with zero-CoM and your noise preserves zero-CoM, you **never need to re-center during sampling**.\n\n```python\n# ‚úÖ CORRECT - CoM-preserving noise\ndef add_noise(h_0, t):\n    \"\"\"Forward diffusion with CoM constraint\"\"\"\n    # Sample noise\n    eps = torch.randn_like(h_0)  # (N, 3)\n    \n    # Project to zero-CoM subspace\n    eps = eps - eps.mean(dim=0, keepdim=True)  # Critical!\n    \n    # Standard diffusion\n    alpha_t = get_alpha(t)\n    h_t = sqrt(alpha_t) * h_0 + sqrt(1 - alpha_t) * eps\n    \n    # h_t automatically has zero CoM!\n    return h_t, eps\n```\n\n**Why this works:** You're restricting the diffusion to the (N-1)√ó3 dimensional subspace where CoM=0. The likelihood is still valid because you're modeling the **conditional** distribution p(h | CoM=0).\n\n### **Gotcha #3: Training vs Sampling Mismatch**\n\n**Check your training code:**\n\n```python\n# Training - make sure data has zero CoM\ndef prepare_batch(molecules):\n    h = molecules.coords  # (B, N, 3)\n    \n    # ‚úÖ Center each molecule\n    h = h - h.mean(dim=1, keepdim=True)\n    \n    # Add CoM-preserving noise\n    eps = torch.randn_like(h)\n    eps = eps - eps.mean(dim=1, keepdim=True)  # Don't forget this!\n    \n    h_t = sqrt(alpha_t) * h + sqrt(1 - alpha_t) * eps\n    \n    # Predict noise\n    eps_pred = model(h_t, t)\n    \n    # Loss on CoM-free noise\n    loss = ((eps - eps_pred) ** 2).mean()\n    return loss\n```\n\n**Sampling - must match:**\n\n```python\n# ‚úÖ CORRECT Sampling\ndef sample_molecule(model, num_atoms):\n    # Initialize from CoM-preserving noise\n    h_T = torch.randn(num_atoms, 3)\n    h_T = h_T - h_T.mean(dim=0, keepdim=True)  # Start in subspace\n    \n    for t in reversed(range(T)):\n        # Predict noise\n        eps_pred = model(h_T, t)\n        \n        # Reverse step with CoM-preserving noise\n        z = torch.randn_like(h_T)\n        z = z - z.mean(dim=0, keepdim=True)  # Critical!\n        \n        # DDPM update\n        h_t = (h_T - beta_t * eps_pred) / sqrt(alpha_t) + sigma_t * z\n        \n        # No need to re-center! Already in subspace\n        # assert h_t.mean().abs() < 1e-6  # Should be ~0\n        \n    return h_t\n```\n\n### **Gotcha #4: Numerical Drift**\n\nEven with CoM-preserving operations, **floating-point errors** can cause drift:\n\n```python\n# ‚úÖ Add periodic re-centering for numerical stability\ndef sampling_step(h_t, t):\n    eps_pred = model(h_t, t)\n    h_t_minus_1 = reverse_diffusion_step(h_t, eps_pred, t)\n    \n    # Re-center only if drift is significant (numerical stability)\n    com = h_t_minus_1.mean(dim=0)\n    if com.norm() > 1e-5:  # Threshold for numerical drift\n        h_t_minus_1 = h_t_minus_1 - com\n        \n    return h_t_minus_1\n```\n\n**Important:** This is **numerical correction**, not part of the model. The drift should be tiny (~1e-6 to 1e-8).\n\n### **Gotcha #5: Likelihood Evaluation**\n\nIf you're computing likelihoods (e.g., for evaluation):\n\n```python\ndef compute_likelihood(h_0, model):\n    \"\"\"\n    Likelihood is defined on the (N-1)*3 dimensional subspace\n    NOT the full N*3 space!\n    \"\"\"\n    # ‚ùå WRONG\n    log_p = standard_diffusion_likelihood(h_0, model)  # Assumes N*3 dims\n    \n    # ‚úÖ CORRECT - Account for CoM constraint\n    # Method 1: Compute in constrained subspace\n    log_p_constrained = diffusion_likelihood_with_com_constraint(h_0, model)\n    \n    # Method 2: Add correction term\n    # log p(h | CoM=0) = log p(h) - log p(CoM=0)\n    # But p(CoM=0) = 0 in continuous space, so use Jacobian\n    \n    # In practice, EDM uses variational bound (ELBO)\n    return log_p_constrained\n```\n\n**From EDM paper (Hoogeboom et al.):** They derive the proper likelihood by marginalizing over translations:\n\n```\np(h) = ‚à´ p(h + c) dc  where c is translation\n     = p(h - mean(h)) * det(Jacobian)\n```\n\nThe Jacobian accounts for the dimensionality reduction (N√ó3 ‚Üí (N-1)√ó3).\n\n## üìã Practical Checklist for Your Code Release\n\nBefore you release, verify:\n\n- [ ] **Training noise is CoM-preserving:**\n  ```python\n  eps = eps - eps.mean(dim=1, keepdim=True)\n  ```\n\n- [ ] **Sampling noise is CoM-preserving:**\n  ```python\n  z = z - z.mean(dim=0, keepdim=True)\n  ```\n\n- [ ] **Initial noise h_T has zero CoM:**\n  ```python\n  h_T = torch.randn(N, 3)\n  h_T = h_T - h_T.mean(dim=0, keepdim=True)\n  ```\n\n- [ ] **Data preprocessing centers molecules:**\n  ```python\n  coords = coords - coords.mean(dim=-2, keepdim=True)\n  ```\n\n- [ ] **No re-centering inside the sampling loop** (except for numerical stability with small threshold)\n\n- [ ] **Assertions in debug mode:**\n  ```python\n  if debug:\n      assert h_t.mean(dim=0).norm() < 1e-5, \"CoM drift detected!\"\n  ```\n\n## üî¨ How EDM/GeoDiff Handle This\n\n**EDM (Hoogeboom et al. 2022):**\n- Explicitly projects noise to zero-CoM subspace in both training and sampling\n- Derives proper likelihood with Jacobian correction\n- See Appendix B.2 in the paper for full derivation\n\n**GeoDiff (Xu et al. 2022):**\n- Uses a similar approach but with score-based formulation\n- Centers coordinates before each network call\n- The score (gradient of log-density) is naturally translation-invariant\n\n## Code Snippet for Your Release\n\n```python\nclass CoMPreservingDiffusion:\n    def project_com(self, h):\n        \"\"\"Project to zero center-of-mass subspace\"\"\"\n        return h - h.mean(dim=-2, keepdim=True)\n    \n    def sample_com_free_noise(self, shape):\n        \"\"\"Sample noise in zero-CoM subspace\"\"\"\n        eps = torch.randn(shape)\n        return self.project_com(eps)\n    \n    def forward_diffusion(self, h_0, t):\n        \"\"\"Add noise while preserving CoM\"\"\"\n        eps = self.sample_com_free_noise(h_0.shape)\n        alpha_t = self.get_alpha(t)\n        h_t = torch.sqrt(alpha_t) * h_0 + torch.sqrt(1 - alpha_t) * eps\n        # Numerical stability check\n        assert h_t.mean(dim=-2).abs().max() < 1e-5\n        return h_t, eps\n    \n    @torch.no_grad()\n    def sample(self, num_atoms, num_samples):\n        \"\"\"Sample molecules with zero CoM\"\"\"\n        # Initialize in CoM-free subspace\n        h = self.sample_com_free_noise((num_samples, num_atoms, 3))\n        \n        for t in reversed(range(self.num_timesteps)):\n            # Predict noise\n            eps_pred = self.model(h, t)\n            \n            # Sample CoM-free noise for stochastic step\n            z = self.sample_com_free_noise(h.shape) if t > 0 else 0\n            \n            # Reverse step (DDPM)\n            h = self.reverse_step(h, eps_pred, z, t)\n            \n            # Numerical stability (should be ~0)\n            h = self.project_com(h)\n            \n        return h\n```\n\n## Final Pro Tip\n\n**Add unit tests for your code release:**\n\n```python\ndef test_com_preservation():\n    model = YourDiffusionModel()\n    h_0 = torch.randn(10, 5, 3)  # 10 molecules, 5 atoms each\n    h_0 = h_0 - h_0.mean(dim=1, keepdim=True)\n    \n    # Test forward process\n    h_t, eps = model.forward_diffusion(h_0, t=0.5)\n    assert h_t.mean(dim=1).abs().max() < 1e-5, \"Forward breaks CoM\"\n    assert eps.mean(dim=1).abs().max() < 1e-5, \"Noise not CoM-free\"\n    \n    # Test sampling\n    samples = model.sample(num_atoms=5, num_samples=100)\n    assert samples.mean(dim=1).abs().max() < 1e-4, \"Sampling breaks CoM\"\n    \n    print(\"‚úÖ CoM preservation tests passed!\")\n```\n\n---\n\n**TL;DR for your code release:**\n1. **Always project noise to zero-CoM** in both training and sampling\n2. **Never re-center during sampling** (except tiny numerical corrections)\n3. **Start sampling from zero-CoM noise**\n4. **Add assertions** to catch violations early\n\nThis is one of those details that reviewers/users **will** check, so getting it right in your release will save you from bug reports later!",
      "turn": 4
    },
    {
      "role": "user",
      "content": "This is a lifesaver‚ÄîI realized I was naively re-centering in my sampling loop, which explains some of the likelihood instability I was seeing. I'll implement these CoM-preserving noise projections and unit tests tonight to ensure the code release is robust for the camera-ready.",
      "turn": 4
    }
  ]
}