<thinking>
  The user says they want to do AI research but hate math. This is a common tension. I need to be helpful and realistic.

First, I should acknowledge their feelings - hating math is valid, and it's a common barrier. I shouldn't just say "too bad, math is required" in a dismissive way.

But I also need to be accurate. Modern AI research, especially in deep learning, is very math-intensive: linear algebra, calculus, probability, optimization, etc. I shouldn't mislead them into thinking they can do cutting-edge AI research without any math.

However, there are nuances:
1. "AI research" is broad - it includes many subfields with different math requirements
2. "Hating math" might mean different things - maybe they dislike abstract proofs but are okay with applied/computational math
3. There are related roles that involve AI but aren't traditional "research"
4. There are ways to gradually build math tolerance or find alternative pathways

I should explore these nuances. The goal is to be helpful and informative, not discouraging but also realistic.

Let me structure my response:
1. Acknowledge the conflict and validate their feelings
2. Explain why math is currently central to AI research (honestly but not harshly)
3. Explore alternatives within AI that might be less math-heavy
4. Suggest related roles that might satisfy their interest without requiring as much math
5. Offer strategies if they want to persist in research despite hating math
6. Provide concrete examples and resources

I should be clear about the distinction between:
- AI Research Scientist (very math-heavy)
- AI Research Engineer (still math but more implementation)
- Applied AI/ML Engineer (less math, more engineering)
- AI product/design/research in social sciences (different kind of research)

Also, subfields like:
- Robotics (still math but more physics/engineering)
- NLP (some subareas are more empirical/engineering)
- AI safety/governance (more philosophy, policy)
- Human-computer interaction with AI
- AI ethics/fairness (can be more social science oriented)

I should mention that even in less math-heavy areas, some baseline is needed. But the *type* and *intensity* of math varies greatly.

I should also address the "hate" part - maybe it's about how they learned math, or the abstractness. Suggesting resources that teach math in more applied, intuitive ways could help. Like 3Blue1Brown, geometric intuitions, etc.

Let me think about specific examples:
- For someone who likes coding: focus on empirical research, large-scale experiments, systems
- For someone interested in brains: computational neuroscience (but that's also math-heavy...)
- For someone interested in social impact: AI policy, fairness, interpretability (some of these are less math-heavy)
- For someone who likes building things: robotics, AI engineering

I should be careful not to over-promise. Even empirical ML research requires understanding experimental design, statistics, etc. which is mathematical.

The key is to help them find a path that aligns with their strengths while being honest about requirements. I should also suggest they might reconsider *why* they hate math and whether it's a fixed preference.

Let me draft a response that's empathetic, informative, and actionable.
</thinking>

That's a real tension—AI research is deeply mathematical, but your feelings are valid and not uncommon. Let's be honest about the landscape and explore your options:

## The Hard Truth
Core AI research (neural network theory, optimization, new architectures) requires **heavy math**: linear algebra, calculus, probability, and statistics at a graduate level. There's no way around it—papers are full of equations, and intuition is built on mathematical foundations. If you truly hate math, traditional AI research will be miserable.

## But "AI Research" Is Broad

**Lower-math (but not zero-math) options:**
- **Empirical ML research**: Focus on large-scale experiments, systematic evaluations, and dataset creation. You'll need statistics and experimental design, but less theory. Think "AI scientist" roles at labs that run massive compute experiments.
- **AI for science**: Apply existing methods to biology, climate, etc. The domain science may dominate the math.
- **Robotics**: More physics, engineering, and systems work, though control theory is mathematical.
- **Human-AI interaction**: Study how people use AI—more psychology/design, but requires stats.
- **AI safety/governance**: Policy, ethics, and interpretability research can be more philosophical/social-scientific.

**Minimal-math alternatives that still advance AI:**
- **AI engineering**: Build tools, optimize training infrastructure, scale systems. You're implementing research, not creating it.
- **MLOps**: Focus on deployment, monitoring, and reliability—software engineering heavy.
- **Dataset/annotation research**: Curate and analyze data, design benchmarks—critical but coding/data skills > math.
- **Research engineering**: Work in a lab building prototypes for researchers' ideas.

## Strategies If You Want to Persist

**Reframe the math**: Maybe you hate *symbolic manipulation* but could tolerate *geometric intuition*? Resources like 3Blue1Brown's Essence of Linear Algebra/Calculus teach math visually and computationally, which might click better.

**Start applied**: Build projects with PyTorch/TensorFlow. The concrete coding can make the abstract math meaningful later. Many researchers admit they learned the math *after* getting results empirically.

**Find your niche**: Some top researchers are known for being "hacker" types who focus on empirical insights over theory. They still know the math, but their strength is intuition through experimentation.

**Consider adjacent fields**: Cognitive science, computational social science, or HCI let you study intelligence/AI with different toolkits.

## Bottom Line
You can't do *zero-math* AI research, but you can find roles where math isn't the *main* thing you do. Be brutally honest about what you dislike—if it's proofs, maybe avoid theory; if it's all quantitative thinking, AI may not fit.

What specifically do you hate about math? That might help narrow down which paths are viable versus which are dead ends.