<thinking>
  <thinking>
The user wants to know how to add fairness/ethics audits to a Hierarchical Transformer evaluation without contaminating original labels and how to report uncertainty. This is a practical methodology question. I need to give them a concrete, actionable plan that addresses contamination risks and uncertainty quantification.

Key points to cover:
1. How to structure the audit to avoid label contamination
2. Specific fairness metrics relevant to hierarchical transformers
3. Uncertainty reporting methods
4. Practical implementation steps

I should be direct and critical where needed, but this is a solid question so I'll focus on giving them a clear path forward.
</thinking>

To add fairness audits without contaminating your original evaluation:

**1. Separate Annotation Workflow**
Run audits on *copies* of your test set with new annotators who never see original labels. Use a disjoint set of reviewers for fairness annotations versus performance annotations. Store fairness metadata (demographic proxies, group labels) in a separate file that gets joined at analysis time, not baked into the dataset.

**2. Hierarchical-Specific Fairness Metrics**
For hierarchical transformers, measure:
- **Group performance parity** at *each hierarchy level* separately (e.g., sentence-level F1 vs document-level accuracy)
- **Attention disparity**: Are attention weights systematically lower for text from certain groups? Compute correlation between group membership and average attention scores
- **Error propagation**: Do errors on content from Group A cascade more severely up the hierarchy than errors from Group B?

**3. Uncertainty Reporting**
Report **bootstrap confidence intervals** (1000+ resamples) for all fairness metrics. Don't just report point estimates. For attention disparity, show the *distribution* of attention weights per group, not just means. If you have multiple annotators for fairness labels, compute inter-annotator agreement (Krippendorff's alpha) and incorporate that uncertainty into your metrics using Bayesian hierarchical models.

**4. Documentation**
Create a separate "Fairness Appendix" that details annotation procedures, proxy limitations, and uncertainty ranges. Never modify your original test set filesâ€”keep fairness analysis entirely reproducible through code that merges datasets at runtime.
</thinking>