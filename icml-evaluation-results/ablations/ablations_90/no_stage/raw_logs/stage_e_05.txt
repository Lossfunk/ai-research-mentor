<thinking>
  <thinking>
The user wants help framing a response to reviewers who doubt domain transferability of PeerRead aspect score models. This is a specific, technical question about peer review. I need to:

1. Lead with honest assessment: The reviewers have a valid concern - domain transferability is a real issue for peer review models
2. Be specific about why this matters: Different fields have different norms, criteria, writing styles
3. Give concrete experimental directions, not vague suggestions
4. Keep it focused and actionable

Key points to address:
- What experiments would actually convince reviewers?
- What ablations would isolate the transferability problem?
- How to frame this as a strength rather than just defense?

I should avoid generic advice and give specific, implementable suggestions.
</thinking>

The reviewers are right to question this—domain transferability is a critical weakness in peer review modeling, and hand-waving won't convince anyone.

**Lead with this acknowledgment**: "We agree that domain transferability is non-trivial and requires empirical validation, not assumption."

**Experiments that would actually address the critique:**

1. **Cross-domain evaluation**: Train on CS papers (PeerRead), test on Bio/Medicine (PubPeer or published reviews). Report separate performance per domain and analyze error patterns—are failures due to field-specific terminology or deeper criterion differences?

2. **Domain adaptation ablation**: Start with your trained model, then fine-tune on 10/50/100 target-domain papers. Plot performance vs. adaptation data size. This quantifies the transfer gap and shows how much target data is needed—reviewers want numbers, not claims.

3. **Probe for domain-specific features**: Train a classifier to predict domain from model's hidden representations. If it succeeds, your model *is* learning domain-specific patterns that may not generalize. Then show whether these features correlate with aspect predictions.

**Don't just run these—frame them as contributions**: "To our knowledge, this is the first systematic analysis of domain transferability for review aspect prediction."

**What not to do**: Don't claim "we'll test on more domains" without specifying which, how much data, and what metrics will constitute success. That's vague and will get rejected again.
</thinking>