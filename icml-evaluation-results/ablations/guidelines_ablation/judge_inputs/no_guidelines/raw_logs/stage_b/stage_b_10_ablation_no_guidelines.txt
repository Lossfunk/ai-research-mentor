Running self-supervised learning on hospital shift notes is technically feasible and has growing precedent, but it carries **extremely high ethical and legal risks** that require institutional oversight and robust safeguards. Here’s a breakdown:

---

### **Prior Work & Technical Feasibility**

Yes, there is substantial prior work on self-supervised learning (SSL) with clinical text:

- **General clinical notes**: Models like **ClinicalBERT, BioBERT, PubMedBERT, and BlueBERT** are SSL models pretrained on MIMIC-III notes, PubMed abstracts, and other clinical corpora. They’ve shown strong performance on downstream tasks (NER, readmission prediction, etc.).
- **Shift notes specifically**: Research on **handoff/signon notes** exists (e.g., Cohen et al., *JAMA*; Starmer et al., *NEJM* on I-PASS). Some studies use these notes for tasks like predicting deterioration or readmission, but **pretraining directly on shift notes is less common**—most work uses broader EHR note types.
- **Privacy-a...