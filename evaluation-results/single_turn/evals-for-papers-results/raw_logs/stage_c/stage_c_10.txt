1. Problem framing and goals
- Problem: Build a robust, privacy-preserving multimodal misinformation detector that works in low-bandwidth regions on commodity Android devices. Prioritize on-device triage, minimal uplink, and resilience to out-of-context image reuse.
- Scope: Image–text post pairs (e.g., social media posts); languages: English + one non-English (e.g., Chinese) for coverage; threat models include text-only falsehoods, image-only hoaxes, and image–text inconsistency.
- Primary goals:
  - Accuracy: ≥0.80 macro-F1 on public multimodal datasets (Fakeddit subsets, FakeNewsNet) and ≥0.75 on an out-of-context split. [W1][W3]
  - Efficiency: ≤120 ms median inference on mid-range Android (Snapdragon 778G or similar), ≤25 MB app binary for models, ≤10 KB/post average uplink with triage.
  - Robustness: ≤5% drop under 8-bit quantization; calibration ECE ≤0.08.
- Approach: Distil from a CLIP-like teacher into a compact student (TinyCLIP/MobileCLIP-style visual encoder + DistilBERT/mBERT-lite text encoder) with late-fusion consistency head; progressive transmission sends only hashed/quantized embeddings for uncertain cases. [W4][W5][W6]; Use synthetic data augmentation to improve multimodal consistency learning [P1].

Intuition
- Most multimodal misinformation hinges on conflicts between image content and accompanying text. A compact student model can learn teacher-aligned cross-modal consistency signals and flag likely mismatches; when uncertain, send tiny, privacy-preserving signatures rather than raw media.

Why this is principled
- Synthetic and auxiliary signals can improve multimodal misinformation detection and consistency modeling [P1][P3]. Edge-deployed fake news detection is feasible with lightweight transformers at the network edge [P4], and CLIP distillation/efficient variants demonstrate strong accuracy–latency trade-offs on mobile hardware [W4][W5][W6].

2. Experiments
Experiment 1: Distilled lightweight multimodal consistency model
- Hypothesis: An 8-bit quantized student (≤25M params) distilled from a CLIP-like teacher retains ≥90% of teacher F1 while 3–5× faster on-device. [W4][W5][W6]
- Setup: Teacher = CLIP ViT-B/16 fine-tuned for misinformation classification on Fakeddit and FakeNewsNet; Student = MobileCLIP/TinyCLIP-size visual backbone + DistilBERT/mBERT-small text encoder with late fusion; KD losses: feature, logit, and cross-modal agreement; int8 post-training quantization; deploy with TFLite/ONNX Runtime Mobile. [W4][W5][W6][W3][W1]
- Baselines: (a) Text-only DistilBERT, (b) Image-only MobileNet/ViT-Tiny, (c) Server-side full CLIP, (d) Student without KD.
- Metrics: Macro-F1, AUROC, ECE; latency (ms), energy (mJ/inference), model size (MB).
- Expected outcomes: Student within 2–5 F1 points of teacher; ≥5–10 F1 over text-only on image–text inconsistency subset; ≤120 ms inference. If gap >5 F1, increase feature distillation weight or add intermediate-layer KD.

Experiment 2: Progressive transmission and triage under bandwidth constraints
- Hypothesis: On-device uncertainty triage plus hashed/quantized embeddings cuts uplink by 60–80% with <2 F1 loss versus sending all media. [P4]
- Setup: Confidence thresholding; if low confidence, upload 128–256D 8-bit embeddings + perceptual image hash (pHash) and short text (≤140 chars) only; simulate 2G/3G/4G uplinks; server teacher re-scores uncertain cases.
- Baselines: (a) Always-send baseline, (b) Text-only upload, (c) Random 20% sampling.
- Metrics: Macro-F1, recall at fixed bandwidth, average KB/post uplink, time-to-decision.
- Expected outcomes: 60–80% bandwidth reduction at <2 F1 drop; if too much accuracy loss, adapt threshold by bandwidth or add Bloom-filter lookups against known hoaxes.

Experiment 3: Out-of-context (OOC) detection via caption bridging
- Hypothesis: Adding a lightweight caption bridge improves OOC detection by ≥5 F1 vs. direct multimodal classification. [P3]
- Setup: Generate compact captions (on-device shallow captioner or server-assist only for uncertain cases); concatenate with post text; train a consistency head to detect contradictions; evaluate on OOC splits (construct from Fakeddit and curated OOC pairs; if available, use public OOC benchmarks; if not, create a 3–5k OOC dev set).
- Baselines: (a) Student from Exp.1, (b) Text-only, (c) Image-only.
- Metrics: OOC subset F1, confusion rate on benign re-posts, calibration.
- Expected outcomes: +5–8 F1 on OOC; if no gain, replace captioner with CLIP text prompts or add retrieval-based evidence (lightweight web search cache) and re-test. [P2][P3]

Experiment 4: Multilingual adaptation (English↔Chinese)
- Hypothesis: Translate-then-classify (compact En model) matches mBERT-small within 2 F1 while using less RAM on-device. [P5]
- Setup: Weibo rumor dataset + English subsets; pipelines: (a) mBERT-small, (b) Translation (offline small MT where available or server-assist for uncertain cases) + DistilBERT; share visual backbone; same fusion head.
- Baselines: Text-only per language; multilingual vs translate-then-classify.
- Metrics: Per-language F1, latency, memory footprint.
- Expected outcomes: Parity within 2 F1; if translation harms recall, add domain lexicon or language-specific adapters.

Experiment 5: Quantization/pruning–robustness sweep
- Hypothesis: Int8 quantization + 20–30% structured pruning yields ≥2× speedup with ≤1 F1 drop; ternary for visual encoder may still retain acceptable accuracy. [W7]
- Setup: Sweep int8 PTQ vs QAT; structured pruning on attention/MLP; optionally ternary quantization for visual backbone; measure on-device latency and accuracy drift.
- Baselines: FP32 and FP16 models.
- Metrics: F1, AUROC, ECE; latency; power; binary size.
- Expected outcomes: 2–3× speedup at ≤1 F1 loss; if accuracy drops, switch to per-channel quantization or selectively keep first/last layers in higher precision. [W7]

Literature anchors: Multimodal Misinformation Detection by Learning from Synthetic Data (Findings of EMNLP 2024) [P1]; MobileCLIP: Fast Image-Text Models for mobile efficiency [W4].

3. Timeline for the next 6 months with milestones
- Phase 0 (Weeks 1–2): Reproducibility and gating
  - Replicate a text-only DistilBERT and image-only MobileNet baseline on Fakeddit; set up latency/power harness on one Android device. Deliverables: prediction log (≥14 entries) and one reproduced figure/metric; experiment card + one ablation or negative result.
- Month 1: Teacher fine-tuning and student KD prototype
  - Fine-tune CLIP teacher; implement student with KD; initial PTQ; Milestone: ≥0.75 F1 on Fakeddit dev; on-device ≤180 ms.
- Month 2: Bandwidth triage pipeline
  - Implement uncertainty thresholding + embedding/hash uplink; simulate networks; Milestone: ≥60% bandwidth reduction at <3 F1 drop.
- Month 3: OOC detection and caption bridging
  - Build OOC split; integrate caption bridge; Milestone: +5 F1 on OOC vs Exp.1 baseline.
- Month 4: Multilingual track
  - Add Weibo/Twitter15/16; compare translate-then-classify vs mBERT-small; Milestone: ≤2 F1 gap with lower memory.
- Month 5: Compression sweeps and robustness
  - QAT, pruning, selective higher precision; Milestone: ≤120 ms median, ≤25 MB total model(s), ≤1 F1 drop from Month 3.
- Month 6: Hardening, evaluation, and draft
  - Privacy review, error analysis, failure taxonomy, ablations; Milestone: camera-ready draft with open-source demo APK and reproducible scripts.

4. Resources (compute, tools, datasets)
- Compute: 1× mid-range GPU (e.g., RTX 4090 or A5000) or 2× T4/A10G; 2–3 Android test devices (mid/low tier).
- Tools: PyTorch/Lightning; HuggingFace; ONNX Runtime Mobile or TFLite; TensorRT for server; quantization/pruning toolkit (e.g., PQV-Mobile ideas). [W7]
- Datasets: Fakeddit (multimodal, fine-grained) [W1], FakeNewsNet (news + social context) [W3], Weibo rumor dataset (Chinese), Twitter15/16 rumor sets. If OOC benchmark is insufficient, construct a small OOC set following [P2][P3] labeling principles.
- Privacy: pHash, CLIP-embedding L2 signatures; Bloom filters for known hoax media.

5. Risks and mitigations table
- Dataset mismatch to target locales — Curate small local validation set; use translation + lexicons; run per-language error analyses.
- OOC scarcity — Build a 3–5k OOC evaluation split; augment via synthetic caption shuffling; use evidence-grounded checks. [P2]
- On-device accuracy loss from compression — Use QAT and per-channel int8; keep embeddings and first/last layers in higher precision; selective dequantization. [W7]
- Bandwidth assumptions unrealistic — Evaluate across 2G/3G/4G profiles; adaptive thresholds tied to measured RTT/throughput.
- Privacy leakage via embeddings — Use low-dim, quantized embeddings; add DP-noise on uploads for uncertain cases; avoid raw media unless consent.
- Adversarial attacks (memes, OCR noise) — Add robustness training with common corruptions; include OCR-derived features when safe; fail closed to “uncertain.”
- Legal/ethical concerns in moderation — Keep outputs as risk scores; provide explanations; human-in-the-loop escalation; document limitations.

6. Stretch ideas or follow-up directions
- Federated learning with periodic teacher refresh; evaluate against centralized KD for accuracy/privacy trade-offs.
- Retrieval-augmented verification: cache fact-check snippets; lightweight on-device BM25/FAISS of vetted claims; only query server when uncertain. 
- Community signals: incorporate lightweight propagation/structure features (without heavy GNNs) as additional inputs; explore learned priors from [P2] with edge-feasible proxies.
- Ternary quantization for visual encoder and mixture-of-experts gating to keep most queries on-device, escalate only hard cases. [W7]
- Synthetic counterfactuals: Generate adversarial image–text pairs to stress-test consistency learning, building on [P1].

Citations
- [P1] Multimodal Misinformation Detection by Learning from Synthetic Data — https://aclanthology.org/2024.findings-emnlp.613.pdf
- [P2] Evidence-Grounded Multimodal Misinformation Detection with Attention-Based GNNs — https://arxiv.org/html/2505.18221v1
- [P3] Multi-Modal Fake News Detection via Bridging the Gap between Text and Images — https://pmc.ncbi.nlm.nih.gov/articles/PMC10138105/
- [P4] Smart Edge-based Fake News Detection using Pre-trained BERT — https://www.semanticscholar.org/paper/Smart-Edge-based-Fake-News-Detection-using-BERT-Guo-Lamaazi/ecd81d06f8bcba4658402ac62380ab802a7ebeb6
- [W1] r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection — https://arxiv.org/abs/1911.03854
- [W3] FakeNewsNet: A Data Repository with News Content, Social Context and Spatiotemporal Information — https://www.cs.emory.edu/~kshu5/files/FakeNewsNet_big_data.pdf
- [W4] MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training — https://arxiv.org/abs/2311.17049
- [W5] TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance — https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf
- [W6] CLIP-KD: An Empirical Study of CLIP Model Distillation — https://arxiv.org/abs/2307.12732
- [W7] PQV-Mobile: Pruning and Quantization Toolkit for Mobile Vision Transformers — https://arxiv.org/abs/2408.08437

Optional next step
- Kick off Phase 0: fine-tune a text-only DistilBERT baseline on Fakeddit and stand up the Android latency harness; share the reproduced metric, the experiment card draft, and a 10-sample qualitative error analysis to de-risk the path.