We acknowledge that our dataset and models are English-centric, so results may not generalize to multilingual venues where writing conventions, citation styles, and rubrics differ, and where morphology/tokenization can make length- and structure-based features brittle. To address this risk, we will construct a multilingual extension that (a) samples 300–500 recent papers per target language from non-English or bilingual venues; (b) collects aspect/acceptance annotations from native speakers aligned to venue rubrics; and (c) creates a small expert-verified parallel subset via professional translation to quantify translation-induced drift. We will evaluate three strategies side-by-side: native-language models (e.g., XLM-R, mDeBERTa-v3), translate-test (MT to English, apply the English model), and translate-train (bidirectional MT to augment training). For each language, we will report Kendall’s tau/RMSE (aspects) and AUC/F1 (acceptance), retained-performance ratio vs. English (OOD/ID), and calibration (ECE), with pre-registered success criteria (e.g., RPR ≥ 0.90 and τ drop ≤ 0.02; otherwise we limit claims to English venues). We will run zero-shot and few-shot adaptation (k=50–100 labeled examples per language) and include anti-leakage masking, fixed token budgets, and per-language feature-importance/error analyses to detect spurious cues. We will release annotations, translation protocols, and model configs to facilitate replication.

Sources
- Kang, D., Ammar, W., Schwartz, R., & Cohen, W. W. (2018). A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications — https://aclanthology.org/N18-1149.pdf
- Conneau, A., et al. (2020). Unsupervised Cross-lingual Representation Learning at Scale (XLM-R) — https://arxiv.org/abs/1911.02116
- Hu, J., et al. (2020). XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual Generalisation — https://arxiv.org/abs/2003.11080
- Pires, T., Schlinger, E., & Garrette, D. (2019). How Multilingual is Multilingual BERT? — https://arxiv.org/abs/1906.01502