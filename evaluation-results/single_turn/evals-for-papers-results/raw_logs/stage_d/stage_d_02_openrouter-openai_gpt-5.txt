Below is a targeted intervention to replace hierarchical pooling with flat mean pooling, plus baselines, datasets, metrics, and statistical tests designed for a clean comparison. I ground the evaluation setup (benchmarks and primary metrics) in the attached paper and mark unspecified implementation details as Conjecture with defensible defaults.

Intervention: flat mean pooling in place of hierarchical pooling
- Objective: Remove level-wise (hierarchical) pooled summaries and instead compute a single global summary embedding from all retained tokens at a step.
- Where it plugs in:
  - Any place the current model aggregates level-specific token groups into pooled summaries used by the controller, memory/summary tokens, or downstream planning modules. The paper emphasizes hierarchical masking and multi-level structure; this intervention specifically tests whether a simple, flat aggregation suffices. Conjecture.
- Proposed change (minimal-diff implementation):
  - Let E_t ∈ R^{N_t × d} be the embeddings of all retained tokens at step t after the current Transformer layer.
  - Replace per-level pooled vectors {s_t^(l)} with a single s_t = mean_i E_t[i].
  - Replace any per-level controller inputs with the concatenation [s_t, time_embed(t), optional aux], keeping dimensionality matched via linear layers. Conjecture.
  - If a memory/summary token attends to level-wise summaries, instead have it attend to s_t (or seed a single “summary token” whose initial value is s_t per step). Conjecture.
  - Maintain the same retained-token budget and rollout depth as the original model to ensure apples-to-apples compute comparisons [heirarchical-transformer.pdf:3].
  - Parameter parity: if the hierarchical pooling path removes parameters (e.g., per-level projection heads), reallocate a small MLP on s_t to keep total parameter count within ±1%. Conjecture.

Baselines and variants
- Original model (Hierarchical pooling): The unmodified hierarchical aggregation path (control). This directly targets the paper’s ablation interest in hierarchical masking/structure [heirarchical-transformer.pdf:3].
- Flat mean pooling (intervention): As above.
- Optional robustness baselines (recommended if budget allows):
  - Flat attention pooling: replace hierarchical pooling with attention pooling over all retained tokens to produce a single summary (global attention-weighted mean).
  - No pooling: rely solely on a learnable memory token without any pooled summary (tests necessity of explicit aggregation).
  - Flat token dropout baseline: the paper positions hierarchical structure against flat sparsification; include a flat sparsification variant with identical token-budget and depth for context [heirarchical-transformer.pdf:3]. Conjecture.

Datasets and evaluation protocol
- Benchmarks: Atari 100k and Crafter, as specified in the attached paper [heirarchical-transformer.pdf:3].
- Splits and seeds:
  - Use identical train/validation/test seeds across all variants; do not tune on test seeds. Conjecture.
  - Run ≥5 seeds per game (Atari) and per difficulty (Crafter) to estimate variance. Conjecture.
- Preprocessing and rollout settings:
  - Keep observation preprocessing, tokenization, frame stacking, action repeat, rollout horizon, context length, and retained-token budget identical across variants to isolate the pooling change [heirarchical-transformer.pdf:3]. Conjecture.

Primary metrics (as in paper) and how to compute them
- Rollout compute cost: per-step FLOPs and wall-clock time for imagination/planning at a fixed retained-token budget and rollout depth [heirarchical-transformer.pdf:3]. Report both training-time and evaluation-time compute if they differ.
- Rollout error: token-level and image-level prediction error at horizons H (e.g., H ∈ {25, 50, 100}) on held-out trajectories; summarize by area under the error-vs-horizon curve (AUC) [heirarchical-transformer.pdf:3]. Conjecture on AUC summary.
- Final RL performance: median human-normalized score on Atari 100k and Crafter; report mean ± 95% CI over seeds per game and aggregate across games as median with IQR, following standard reporting [heirarchical-transformer.pdf:3]. Conjecture on exact aggregation details.

Secondary metrics (stability and behavior diagnostics)
- Stability: across-seed variance in rollout error and RL score; failure rate (divergent training runs).
- Token budget adherence: average retained-token fraction and its variance per step; mask entropy.
- Calibration: uncertainty calibration error on rollouts if uncertainty signals are used downstream (expected calibration error).
- Memory/summary usage: attention mass on summary/memory tokens; representational drift across horizon (cosine distance between s_t and s_{t+k}). Conjecture.

Statistical tests and reporting
- Across games (Atari, Crafter):
  - Use paired Wilcoxon signed-rank tests comparing per-game median scores between hierarchical pooling (control) and flat mean pooling (intervention). Report effect size (Cliff’s delta) and adjusted p-values (Benjamini–Hochberg FDR across multiple variants). Conjecture.
- Across seeds (within each game/dataset):
  - Two-sided paired t-test on seed-wise means if normality holds (Shapiro–Wilk); otherwise Wilcoxon signed-rank.
  - Additionally report 10k bootstrap CIs for mean differences of primary metrics.
- Rollout error curves:
  - Compare AUCs via paired bootstrap (by sequence) with BCa 95% CIs; visualize mean ± 95% CI across seeds/horizons.
- Equivalence testing (recommended if differences are small):
  - Two one-sided tests (TOST) with pre-registered equivalence margins, e.g., ±1% for compute FLOPs and ±2% relative for rollout error, to support “no meaningful difference” conclusions. Conjecture.
- Pareto analysis:
  - For compute vs error trade-offs under varying token budgets, compute dominated hypervolume; compare via bootstrap. Conjecture.

Three concrete, falsifiable experiments
1) Direct substitution test: hierarchical vs flat mean pooling
- Setup: Train both variants with identical hyperparameters, token budgets, rollout depths, and training steps. Evaluate on Atari 100k and Crafter [heirarchical-transformer.pdf:3].
- Hypotheses:
  - H1: Flat mean pooling does not significantly degrade final RL performance vs hierarchical pooling (non-inferiority within Δ = 2% relative). Conjecture.
  - H2: Flat mean pooling reduces pooling overhead, yielding equal or lower per-step compute (FLOPs). Conjecture.
- Pass/fail:
  - Non-inferiority via TOST (Δ = 2%) on RL score; paired Wilcoxon p < 0.05 after FDR correction if superiority is claimed.
  - Compute reduction significant via paired tests across seeds.

2) Long-horizon stability under fixed compute
- Setup: Fix retained-token budget and rollout depth; compare rollout error AUC over horizons H ∈ {25, 50, 100}.
- Hypothesis: Hierarchical pooling yields lower long-horizon error AUC due to level-structure, while flat mean pooling may blur level-specific signals [heirarchical-transformer.pdf:3]. Conjecture.
- Pass/fail: Significant AUC difference via paired bootstrap with 95% CI not crossing 0; or TOST for equivalence within a pre-registered margin (e.g., ±2% relative AUC).

3) Budget sweep and Pareto efficiency
- Setup: Sweep retained-token budgets (e.g., 10%, 20%, 40%) at constant rollout depth; train light fine-tunes to keep capacity matched. Measure compute vs rollout error and compute vs RL score.
- Hypothesis: If hierarchical pooling is beneficial, its Pareto front should dominate flat mean pooling in at least one regime (low budgets), consistent with the paper’s efficiency/stability hypothesis [heirarchical-transformer.pdf:3].
- Pass/fail: Dominated hypervolume of hierarchical front significantly larger via bootstrap; or flat mean pooling achieves statistical parity (equivalence) across the sweep.

Practical notes for comparability
- Keep tokenization, masking policy, controller inputs (other than pooling), optimizer, schedule, and stopping criteria identical across variants [heirarchical-transformer.pdf:3]. Conjecture.
- Report all three primary metrics specified by the paper—rollout compute cost, rollout error, and final RL performance—on Atari 100k and Crafter to align with the paper’s evaluation [heirarchical-transformer.pdf:3].

Literature anchors (for implementation choices)
- Learning to play Atari in a world of tokens (DART): useful for tokenized Atari pipelines and memory/summary token patterns. https://arxiv.org/abs/2406.01361
- Transformers are sample-efficient world models: background on token-based visual world models and evaluation practices. https://arxiv.org/abs/2209.00588

Citations
- [heirarchical-transformer.pdf:3] We hypothesize that applying Sparse Hierarchical Imagination (SHI) will improve both computational efficiency and rollout stability; report rollout compute cost, rollout error, and final RL performance; benchmarks include Atari 100k and Crafter.
- Micheli et al., 2023. Transformers are sample-efficient world models — https://arxiv.org/abs/2209.00588
- Agarwal et al., 2024. Learning to play atari in a world of tokens (DART) — https://arxiv.org/abs/2406.01361

Key takeaways
- The intervention isolates the role of hierarchical pooling by replacing it with a single flat mean-pooled summary while holding token budgets and rollout depth fixed [heirarchical-transformer.pdf:3].
- Evaluate using the paper’s primary metrics on Atari 100k and Crafter and compare variants with paired nonparametric tests, bootstrap CIs, and equivalence tests to support both superiority and non-inferiority claims [heirarchical-transformer.pdf:3].