Based on the attached paper, I'll design a comprehensive two-phase replication study with rigorous power analysis and methods to isolate independent contributions.

## Phase 1: Baseline Re-implementation

### 1.1 Architecture Specification

**Core Components to Implement:**

**1. Hierarchical VQ-VAE Tokenizer** [heirarchical-transformer.pdf:2]
- Encodes observations `xt` into discrete token sequences `zt = [z¹t, z²t, ..., zᴷt]`
- Organizes tokens into semantic hierarchical levels

**Implementation Details (to be specified):**
```python
class HierarchicalVQVAE(nn.Module):
    """
    Missing from paper - need to specify:
    - Encoder architecture (ResNet? ConvNet depth?)
    - Number of hierarchy levels K
    - Codebook size per level
    - Quantization method (VQ-VAE, Gumbel-Softmax?)
    - Decoder architecture
    """
    def __init__(self, 
                 input_channels=3,
                 num_levels=3,  # ASSUMPTION: 3 levels
                 codebook_sizes=[512, 512, 512],  # ASSUMPTION
                 embedding_dim=64,  # ASSUMPTION
                 encoder_channels=[32, 64, 128, 256],  # ASSUMPTION
                 ):
        super().__init__()
        # To be implemented based on IRIS baseline
```

**2. Transformer World Model** [heirarchical-transformer.pdf:2]
- Processes token sequences for long-horizon imagination
- Maintains hidden state across rollout steps

**Implementation Details (to be specified):**
```python
class TransformerWorldModel(nn.Module):
    """
    Missing from paper - need to specify:
    - Number of layers
    - Hidden dimension
    - Number of attention heads
    - FFN dimension
    - Position encoding type
    - Autoregressive vs. parallel decoding
    """
    def __init__(self,
                 num_layers=6,  # ASSUMPTION: match IRIS
                 d_model=512,  # ASSUMPTION
                 num_heads=8,  # ASSUMPTION
                 d_ff=2048,  # ASSUMPTION
                 max_seq_len=1000,  # ASSUMPTION
                 ):
        super().__init__()
        # To be implemented
```

**3. SPARTAN Causal Graph Module** [heirarchical-transformer.pdf:2,3]
- Learns causal graphs over object tokens
- Provides dynamic information about token influence
- Informs masking decisions

**Implementation Details (to be specified):**
```python
class SPARTANCausalGraph(nn.Module):
    """
    Missing from paper - need to specify:
    - Graph learning architecture
    - How causal scores are computed
    - Integration with masking mechanism
    - Training objective for causal graph
    
    Reference: Lei et al., 2024 (SPARTAN paper)
    """
    def __init__(self,
                 num_tokens,
                 embedding_dim,
                 graph_hidden_dim=256,  # ASSUMPTION
                 ):
        super().__init__()
        # To be implemented from SPARTAN paper
```

**4. Hierarchical Masking Module** [heirarchical-transformer.pdf:3]
- Level-specific temporal masking
- Combines: SPARTAN scores + uncertainty estimates + attention to memory tokens

**Implementation Details:**
```python
class HierarchicalMasking(nn.Module):
    """
    Masking function combines:
    1. SPARTAN causal graph scores
    2. Token-level uncertainty (from stochastic Transformer, STORM)
    3. Attention scores to memory token
    
    Missing from paper:
    - Exact combination formula
    - Weighting of each component
    - Threshold selection mechanism
    - Memory token implementation
    """
    def __init__(self,
                 num_levels=3,
                 uncertainty_weight=0.3,  # ASSUMPTION
                 causal_weight=0.4,  # ASSUMPTION
                 memory_weight=0.3,  # ASSUMPTION
                 ):
        super().__init__()
        self.level_thresholds = nn.Parameter(torch.ones(num_levels))
```

**5. Stochastic Transformer (for Uncertainty)** [heirarchical-transformer.pdf:3]
- Following STORM [Zhang et al., 2023]
- Computes token-level uncertainty estimates

### 1.2 Training Procedure

**Training Schedule (to be specified):**

```python
training_config = {
    # Missing from paper - need to specify:
    "num_environment_steps": 100_000,  # Atari 100k
    "batch_size": None,  # UNKNOWN
    "learning_rate": None,  # UNKNOWN
    "optimizer": None,  # UNKNOWN (Adam? AdamW?)
    "lr_schedule": None,  # UNKNOWN
    "gradient_clip": None,  # UNKNOWN
    
    # Joint or alternating training
    "training_mode": "joint",  # or "alternating"? [heirarchical-transformer.pdf:2]
    "spartan_update_freq": None,  # If alternating
    
    # Reconstruction checkpoints
    "reconstruction_steps": [0, 5, 10],  # [heirarchical-transformer.pdf:3]
    
    # Rollout horizon
    "imagination_horizon": 15,  # ASSUMPTION
}
```

**Loss Functions:**

```python
def compute_loss(model, batch):
    """
    Missing from paper - need to specify:
    - Reconstruction loss weight
    - Reward prediction loss weight
    - SPARTAN causal graph loss
    - Uncertainty regularization
    - Any auxiliary losses
    """
    # Selective reconstruction at checkpoints [heirarchical-transformer.pdf:3]
    reconstruction_loss = 0
    for t in [0, 5, 10]:
        pred_obs = model.decode(latent_rollout[t])
        reconstruction_loss += F.mse_loss(pred_obs, batch['obs'][t])
    
    # Reward prediction (assumed)
    reward_loss = F.mse_loss(pred_rewards, batch['rewards'])
    
    # SPARTAN loss (to be specified from Lei et al., 2024)
    causal_graph_loss = spartan_module.compute_loss(...)
    
    # Total loss (weights unknown)
    total_loss = (w1 * reconstruction_loss + 
                  w2 * reward_loss + 
                  w3 * causal_graph_loss)
    
    return total_loss
```

### 1.3 Replication Validation Criteria

**Success Criteria:**

1. **Accuracy Match:**
   - Final median human-normalized score within ±5% of reported values
   - Per-game scores correlate ρ > 0.9 with reported results
   - Learning curves qualitatively similar

2. **Efficiency Match:**
   - Rollout FLOPs within ±10% of reported values
   - Token retention rate matches reported sparsity

3. **Ablation Consistency:**
   - Ablation studies (removing hierarchy, SPARTAN, uncertainty) show similar trends

**Validation Protocol:**

```python
validation_checks = {
    # Sanity checks during implementation
    "vqvae_reconstruction": "MSE < 0.01 on training data",
    "token_utilization": "Codebook usage > 80%",
    "masking_rate": "50-80% tokens masked per step",
    "gradient_flow": "No vanishing/exploding gradients",
    
    # Comparison to baselines
    "iris_parity": "Match IRIS performance when masking disabled",
    "spartan_parity": "Match SPARTAN causal graph quality",
    
    # Final validation
    "atari_100k_scores": "Median score within ±5% of paper",
    "crafter_scores": "Achievement score within ±5% of paper",
}
```

### 1.4 Missing Information Recovery Strategy

**Information Gaps:**

| Component | Missing Details | Recovery Strategy |
|-----------|----------------|-------------------|
| VQ-VAE architecture | Encoder/decoder depth, channels | Use IRIS implementation as template |
| Transformer size | Layers, hidden dim, heads | Match IRIS (6 layers, 512 dim, 8 heads) |
| SPARTAN integration | Exact architecture, loss | Implement from Lei et al., 2024 |
| Uncertainty estimation | STORM implementation | Implement from Zhang et al., 2023 |
| Masking combination | Weights, thresholds | Grid search: {0.2, 0.3, 0.4, 0.5} |
| Training hyperparams | LR, batch size, optimizer | Use IRIS defaults, tune if needed |
| Memory token | Implementation details | Implement as learnable query vector |

**Recovery Procedure:**

1. **Contact Authors:**
   - Request implementation details
   - Ask for hyperparameter configurations
   - Request clarification on ambiguous components

2. **Baseline Matching:**
   - Implement IRIS baseline first (well-documented)
   - Verify IRIS reproduction matches published results
   - Use IRIS architecture as template for SHI

3. **Ablation-Based Inference:**
   - Implement components incrementally
   - Validate each component independently
   - Use ablations to verify component contributions

4. **Hyperparameter Search:**
   - Grid search over plausible ranges
   - Use Bayesian optimization for efficiency
   - Document all search procedures

### 1.5 Implementation Timeline (Phase 1)

**Week 1-2: Core Infrastructure**
- [ ] Implement VQ-VAE (based on IRIS)
- [ ] Implement Transformer world model
- [ ] Verify reconstruction quality on Atari frames
- [ ] Unit tests for all components

**Week 3-4: SPARTAN Integration**
- [ ] Implement SPARTAN causal graph module (from Lei et al., 2024)
- [ ] Implement uncertainty estimation (from Zhang et al., 2023)
- [ ] Integrate with Transformer
- [ ] Verify causal graph learning on synthetic data

**Week 5-6: Hierarchical Masking**
- [ ] Implement masking combination logic
- [ ] Implement memory token mechanism
- [ ] Test masking on rollouts
- [ ] Verify sparsity levels

**Week 7-8: Training Pipeline**
- [ ] Implement full training loop
- [ ] Integrate with RL environment (Atari)
- [ ] Hyperparameter tuning
- [ ] Initial training runs (3 games, 1 seed)

**Week 9-10: Validation**
- [ ] Full Atari 100k evaluation (26 games, 5 seeds)
- [ ] Compare to reported results
- [ ] Ablation studies
- [ ] Debug discrepancies

**Week 11-12: Refinement**
- [ ] Address any performance gaps
- [ ] Final validation runs
- [ ] Documentation and code cleanup
- [ ] Prepare for Phase 2

**Total Phase 1 Duration:** 12 weeks

**Computational Budget:**
- Development/debugging: 500 GPU-hours
- Hyperparameter search: 1,000 GPU-hours
- Validation runs: 2,600 GPU-hours (26 games × 5 seeds × 4 hours)
- Ablations: 500 GPU-hours
- **Total:** ~4,600 GPU-hours (~$2,300 on A100s)

## Phase 2: Low-Parameter Alternative

### 2.1 Grouped Pooling Alternative

**Motivation:**
- Hierarchical token organization may add complexity without proportional benefit
- Grouped pooling provides similar sparsity with simpler mechanism
- Fewer parameters, easier to implement and tune

**Design:**

```python
class GroupedPoolingMasking(nn.Module):
    """
    Low-parameter alternative to hierarchical masking.
    
    Key differences from SHI:
    1. No explicit hierarchy levels - tokens grouped dynamically
    2. Simple k-means clustering instead of learned hierarchy
    3. Pool within groups, mask between groups
    4. Single masking threshold (not per-level)
    
    Parameters: ~1K (vs. ~10K for hierarchical masking)
    """
    def __init__(self,
                 num_groups=8,  # Fixed number of groups
                 embedding_dim=512,
                 pooling_method='attention',  # or 'mean', 'max'
                 ):
        super().__init__()
        self.num_groups = num_groups
        
        # Minimal parameters: just group assignment and pooling
        if pooling_method == 'attention':
            self.group_query = nn.Parameter(torch.randn(num_groups, embedding_dim))
            # ~4K parameters (8 groups × 512 dim)
        
        self.masking_threshold = nn.Parameter(torch.tensor(0.5))
        # Total: ~4K parameters vs. ~10K+ for hierarchical
        
    def forward(self, tokens, causal_scores=None, uncertainty=None):
        """
        Args:
            tokens: [B, L, D] token embeddings
            causal_scores: [B, L] from SPARTAN (optional)
            uncertainty: [B, L] from stochastic Transformer (optional)
        
        Returns:
            mask: [B, L] boolean mask (True = keep, False = mask)
        """
        B, L, D = tokens.shape
        
        # Step 1: Assign tokens to groups (k-means clustering)
        # Use token embeddings for clustering (no learned hierarchy)
        with torch.no_grad():
            distances = torch.cdist(tokens, self.group_query.unsqueeze(0))  # [B, L, G]
            group_assignments = distances.argmin(dim=-1)  # [B, L]
        
        # Step 2: Pool within each group
        group_importance = torch.zeros(B, self.num_groups, device=tokens.device)
        for g in range(self.num_groups):
            group_mask = (group_assignments == g)  # [B, L]
            
            if self.pooling_method == 'attention':
                # Attention-based pooling
                attn_scores = torch.matmul(
                    tokens, self.group_query[g]
                ) / math.sqrt(D)  # [B, L]
                attn_weights = F.softmax(attn_scores.masked_fill(~group_mask, -1e9), dim=-1)
                group_importance[:, g] = attn_weights.sum(dim=-1)
            elif self.pooling_method == 'mean':
                # Simple mean pooling
                group_importance[:, g] = group_mask.float().mean(dim=-1)
        
        # Step 3: Combine with optional causal scores and uncertainty
        token_importance = torch.zeros(B, L, device=tokens.device)
        for g in range(self.num_groups):
            group_mask = (group_assignments == g)
            token_importance[group_mask] = group_importance[:, g].unsqueeze(-1).expand(-1, L)[group_mask]
        
        if causal_scores is not None:
            token_importance = 0.5 * token_importance + 0.5 * causal_scores
        
        if uncertainty is not None:
            token_importance = token_importance * (1 - uncertainty)  # Mask uncertain tokens
        
        # Step 4: Apply threshold
        mask = token_importance > self.masking_threshold
        
        return mask, group_assignments
```

**Key Advantages:**

1. **Parameter Efficiency:**
   - Grouped pooling: ~4K parameters
   - Hierarchical masking: ~10K+ parameters (level embeddings, per-level thresholds, etc.)
   - **Reduction: 60%**

2. **Simplicity:**
   - No need to learn hierarchy levels
   - Single masking threshold
   - Easier to interpret and debug

3. **Flexibility:**
   - Number of groups is hyperparameter (not fixed by hierarchy)
   - Can adapt to different token distributions

4. **Compatibility:**
   - Still uses SPARTAN causal scores (if beneficial)
   - Still uses uncertainty estimates (if beneficial)
   - Can be combined with local attention windows

### 2.2 Experimental Design

**Variants to Compare:**

1. **SHI-Full** (Phase 1 baseline)
   - Hierarchical token organization
   - Level-specific masking
   - SPARTAN + uncertainty + memory token

2. **GroupPool-Full**
   - Grouped pooling masking
   - SPARTAN + uncertainty
   - No memory token (simpler)

3. **GroupPool-Minimal**
   - Grouped pooling only
   - No SPARTAN, no uncertainty
   - Tests if pooling alone is sufficient

4. **SHI-NoHierarchy**
   - SHI with flat masking (all tokens same level)
   - Isolates hierarchy contribution

5. **Random-Masking**
   - Random token masking at same sparsity level
   - Lower bound baseline

**Factorial Design:**

| Variant | Hierarchy | Grouped Pooling | SPARTAN | Uncertainty | Parameters |
|---------|-----------|-----------------|---------|-------------|------------|
| SHI-Full | ✓ | ✗ | ✓ | ✓ | High |
| GroupPool-Full | ✗ | ✓ | ✓ | ✓ | Medium |
| GroupPool-Minimal | ✗ | ✓ | ✗ | ✗ | Low |
| SHI-NoHierarchy | ✗ | ✗ | ✓ | ✓ | Medium |
| Random-Masking | ✗ | ✗ | ✗ | ✗ | Minimal |

### 2.3 Avoiding Double-Counting Correlated Improvements

**Problem:** Multiple components (hierarchy, SPARTAN, uncertainty) may provide overlapping benefits. Need to isolate independent contributions.

**Solution: Variance Decomposition via Hierarchical Regression**

**Model:**
```
Performance = β₀ + β₁·Hierarchy + β₂·GroupPool + β₃·SPARTAN + β₄·Uncertainty + 
              β₅·(Hierarchy × SPARTAN) + β₆·(GroupPool × SPARTAN) + 
              β₇·(Hierarchy × Uncertainty) + β₈·(GroupPool × Uncertainty) +
              ε
```

**Interpretation:**
- **β₁**: Independent contribution of hierarchy (controlling for other components)
- **β₂**: Independent contribution of grouped pooling
- **β₃**: Independent contribution of SPARTAN
- **β₄**: Independent contribution of uncertainty
- **β₅, β₆, β₇, β₈**: Interaction effects (synergies or redundancies)

**Variance Partitioning:**

Use **Shapley value decomposition** to fairly attribute performance to each component:

```python
def compute_shapley_values(variants, performance):
    """
    Compute Shapley values for each component.
    
    Shapley value = average marginal contribution across all possible
                    orderings of adding components
    
    Args:
        variants: Dict mapping variant name to component set
                  e.g., {'SHI-Full': {'hierarchy', 'spartan', 'uncertainty'}}
        performance: Dict mapping variant name to performance score
    
    Returns:
        shapley_values: Dict mapping component to marginal contribution
    """
    components = ['hierarchy', 'grouped_pool', 'spartan', 'uncertainty']
    shapley_values = {c: 0.0 for c in components}
    
    # For each component
    for component in components:
        marginal_contributions = []
        
        # For each subset not containing component
        for subset in powerset(set(components) - {component}):
            # Performance with subset
            perf_without = get_variant_performance(subset, variants, performance)
            
            # Performance with subset + component
            perf_with = get_variant_performance(subset | {component}, variants, performance)
            
            # Marginal contribution
            marginal = perf_with - perf_without
            marginal_contributions.append(marginal)
        
        # Shapley value = average marginal contribution
        shapley_values[component] = np.mean(marginal_contributions)
    
    return shapley_values
```

**Example Output:**

```
Component Contributions (Shapley Values):
- Hierarchy:      +0.08 (8% improvement)
- Grouped Pool:   +0.06 (6% improvement)
- SPARTAN:        +0.12 (12% improvement)
- Uncertainty:    +0.04 (4% improvement)
- Interactions:   +0.02 (2% synergy)
-------------------------------------------
Total:            +0.32 (32% improvement over baseline)
```

**Interpretation:**
- SPARTAN provides largest independent contribution (12%)
- Hierarchy provides 8%, but grouped pooling achieves 6% with fewer parameters
- Minimal interaction effects → components are largely independent

### 2.4 Power Analysis

**Objective:** Determine sample size (number of games × seeds) needed to detect meaningful differences between SHI-Full and GroupPool-Full.

**Effect Size Estimation:**

Based on typical RL performance differences:
- **Small effect:** Cohen's d = 0.2 (2% performance difference)
- **Medium effect:** Cohen's d = 0.5 (5% performance difference)
- **Large effect:** Cohen's d = 0.8 (8% performance difference)

**Target:** Detect medium effect (d = 0.5) with 80% power at α = 0.05

**Power Calculation:**

```python
from statsmodels.stats.power import TTestIndPower

# Two-sample t-test (comparing SHI-Full vs. GroupPool-Full)
power_analysis = TTestIndPower()

# Calculate required sample size
n_per_group = power_analysis.solve_power(
    effect_size=0.5,  # Medium effect
    alpha=0.05,       # Significance level
    power=0.80,       # Desired power
    alternative='two-sided'
)

print(f"Required sample size per group: {n_per_group:.0f}")
# Output: ~64 samples per group
```

**Sample Size Determination:**

For **paired design** (same games, same seeds):
- **Games:** 26 Atari games
- **Seeds:** 3 seeds per game
- **Total samples:** 26 × 3 = 78 per variant
- **Power:** >80% to detect d = 0.5

For **conservative design** (account for heterogeneity):
- **Games:** 26 Atari games
- **Seeds:** 5 seeds per game
- **Total samples:** 26 × 5 = 130 per variant
- **Power:** >90% to detect d = 0.5

**Recommendation:** Use 5 seeds per game (130 samples per variant)

**Power Curve:**

```python
import matplotlib.pyplot as plt
import numpy as np

effect_sizes = np.linspace(0.1, 1.0, 50)
powers = [power_analysis.solve_power(
    effect_size=d, alpha=0.05, nobs1=130, alternative='two-sided'
) for d in effect_sizes]

plt.plot(effect_sizes, powers)
plt.axhline(0.80, color='red', linestyle='--', label='80% power')
plt.axvline(0.5, color='blue', linestyle='--', label='d=0.5 (medium)')
plt.xlabel('Effect Size (Cohen\'s d)')
plt.ylabel('Statistical Power')
plt.title('Power Analysis: SHI-Full vs. GroupPool-Full')
plt.legend()
plt.grid(True)
```

**Sensitivity Analysis:**

Test power under different assumptions:

| Scenario | Games | Seeds | Total N | Power (d=0.5) | Power (d=0.3) |
|----------|-------|-------|---------|---------------|---------------|
| Minimal | 10 | 3 | 30 | 0.47 | 0.18 |
| Standard | 26 | 3 | 78 | 0.82 | 0.38 |
| Conservative | 26 | 5 | 130 | 0.93 | 0.58 |
| Extensive | 26 | 10 | 260 | 0.99 | 0.82 |

**Recommendation:** Use **Conservative** design (26 games × 5 seeds) for adequate power.

### 2.5 Statistical Testing Protocol

**Primary Hypothesis:**

**H1:** GroupPool-Full achieves equivalent performance to SHI-Full with fewer parameters

**Test:** Two one-sided tests (TOST) for equivalence
- Equivalence margin: ±3% human-normalized score
- If equivalent, compare parameter count and efficiency

**Secondary Hypotheses:**

**H2:** Grouped pooling provides independent benefit beyond SPARTAN/uncertainty

**Test:** Hierarchical regression with interaction terms
- Compare GroupPool-Full vs. GroupPool-Minimal
- Control for SPARTAN and uncertainty contributions

**H3:** Hierarchy and grouped pooling are redundant (not complementary)

**Test:** Compare SHI-Full vs. (SHI-NoHierarchy + GroupPool)
- If SHI-Full ≈ SHI-NoHierarchy + GroupPool, mechanisms are redundant
- If SHI-Full > both, hierarchy provides unique benefit

**Multiple Comparisons Correction:**

Use **Holm-Bonferroni** method (less conservative than Bonferroni):
1. Rank p-values from smallest to largest
2. Compare p₁ to α/k, p₂ to α/(k-1), ..., pₖ to α/1
3. Reject until first non-significant test

**Example:**
- 5 pairwise comparisons
- α = 0.05
- Adjusted thresholds: 0.01, 0.0125, 0.0167, 0.025, 0.05

### 2.6 Avoiding Correlated Improvements: Detailed Methods

**Method 1: Sequential Ablation with Residual Analysis**

**Procedure:**
1. Start with baseline (no components)
2. Add components one at a time in order of expected importance
3. At each step, measure **residual performance gain**
4. Residual gain = performance improvement not explained by previous components

**Example:**

| Step | Components Added | Performance | Marginal Gain | Residual Gain |
|------|------------------|-------------|---------------|---------------|
| 0 | None (baseline) | 0.50 | - | - |
| 1 | + SPARTAN | 0.62 | +0.12 | +0.12 |
| 2 | + Uncertainty | 0.68 | +0.06 | +0.06 |
| 3 | + Hierarchy | 0.76 | +0.08 | +0.08 |
| 4 | + GroupPool (instead of Hierarchy) | 0.74 | +0.06 | +0.06 |

**Interpretation:**
- SPARTAN: 12% independent contribution
- Uncertainty: 6% independent contribution (after SPARTAN)
- Hierarchy: 8% independent contribution (after SPARTAN + Uncertainty)
- GroupPool: 6% independent contribution (alternative to Hierarchy)
- **Conclusion:** Hierarchy provides 2% more than GroupPool, but at higher parameter cost

**Method 2: Orthogonal Decomposition via PCA**

**Procedure:**
1. Collect performance vectors for all variants across games
2. Perform PCA on performance matrix
3. Interpret principal components as independent sources of variation
4. Project component contributions onto PCs

**Example:**

```python
import numpy as np
from sklearn.decomposition import PCA

# Performance matrix: [variants × games]
# Each row = one variant's performance across 26 games
performance_matrix = np.array([
    [0.8, 0.7, 0.9, ...],  # SHI-Full
    [0.75, 0.68, 0.85, ...],  # GroupPool-Full
    [0.65, 0.60, 0.75, ...],  # GroupPool-Minimal
    # ... other variants
])

# PCA
pca = PCA(n_components=3)
pca.fit(performance_matrix)

print("Explained variance ratio:", pca.explained_variance_ratio_)
# Output: [0.65, 0.20, 0.10] - first PC explains 65% of variance

# Interpret PCs
# PC1: Overall performance (all components contribute)
# PC2: Hierarchy vs. GroupPool (orthogonal trade-off)
# PC3: SPARTAN vs. Uncertainty (orthogonal trade-off)
```

**Interpretation:**
- If PC2 separates Hierarchy from GroupPool → independent mechanisms
- If PC2 doesn't separate them → redundant mechanisms

**Method 3: Conditional Independence Testing**

**Procedure:**
1. Test if Hierarchy and GroupPool are conditionally independent given SPARTAN/Uncertainty
2. Use partial correlation or conditional mutual information

**Test:**

```python
from scipy.stats import pearsonr

# Performance gains from each component
hierarchy_gain = performance['SHI-Full'] - performance['SHI-NoHierarchy']
grouppool_gain = performance['GroupPool-Full'] - performance['GroupPool-Minimal']
spartan_gain = performance['SPARTAN-Only'] - performance['Baseline']

# Partial correlation: Hierarchy vs. GroupPool, controlling for SPARTAN
def partial_correlation(x, y, z):
    """Compute partial correlation between x and y, controlling for z."""
    # Residuals after regressing on z
    x_resid = x - np.polyval(np.polyfit(z, x, 1), z)
    y_resid = y - np.polyval(np.polyfit(z, y, 1), z)
    
    # Correlation of residuals
    r, p = pearsonr(x_resid, y_resid)
    return r, p

r_partial, p_partial = partial_correlation(hierarchy_gain, grouppool_gain, spartan_gain)

if p_partial > 0.05:
    print("Hierarchy and GroupPool are conditionally independent (given SPARTAN)")
    print("→ No double-counting concern")
else:
    print(f"Hierarchy and GroupPool are correlated (r={r_partial:.2f}, p={p_partial:.3f})")
    print("→ Risk of double-counting improvements")
```

**Method 4: Causal Mediation Analysis**

**Objective:** Determine if SPARTAN/Uncertainty mediate the effect of Hierarchy/GroupPool

**Model:**

```
Hierarchy → SPARTAN → Performance
         ↘         ↗
           Direct Effect
```

**Procedure:**
1. Estimate total effect: Hierarchy → Performance
2. Estimate indirect effect: Hierarchy → SPARTAN → Performance
3. Estimate direct effect: Total - Indirect
4. If direct effect ≈ 0, Hierarchy works entirely through SPARTAN (redundant)

**Implementation:**

```python
from sklearn.linear_model import LinearRegression

# Step 1: Total effect (Hierarchy → Performance)
model_total = LinearRegression()
model_total.fit(hierarchy_indicator.reshape(-1, 1), performance)
total_effect = model_total.coef_[0]

# Step 2: Hierarchy → SPARTAN
model_mediator = LinearRegression()
model_mediator.fit(hierarchy_indicator.reshape(-1, 1), spartan_scores)
a_path = model_mediator.coef_[0]

# Step 3: SPARTAN → Performance (controlling for Hierarchy)
model_outcome = LinearRegression()
model_outcome.fit(
    np.column_stack([hierarchy_indicator, spartan_scores]),
    performance
)
b_path = model_outcome.coef_[1]  # SPARTAN coefficient
direct_effect = model_outcome.coef_[0]  # Hierarchy coefficient

# Indirect effect (mediated by SPARTAN)
indirect_effect = a_path * b_path

print(f"Total effect: {total_effect:.3f}")
print(f"Direct effect: {direct_effect:.3f}")
print(f"Indirect effect (via SPARTAN): {indirect_effect:.3f}")
print(f"Proportion mediated: {indirect_effect / total_effect:.1%}")
```

**Interpretation:**
- If proportion mediated > 80%, Hierarchy works mostly through SPARTAN
- If proportion mediated < 20%, Hierarchy has independent mechanism

### 2.7 Experimental Protocol (Phase 2)

**Week 1-2: Implementation**
- [ ] Implement GroupedPoolingMasking module
- [ ] Integrate with Phase 1 codebase
- [ ] Unit tests and validation
- [ ] Verify parameter count reduction

**Week 3-4: Initial Experiments**
- [ ] Train all 5 variants on 3 Atari games, 1 seed
- [ ] Quick comparison of performance
- [ ] Identify any implementation issues
- [ ] Adjust hyperparameters if needed

**Week 5-8: Full Evaluation**
- [ ] Train all 5 variants on 26 Atari games, 5 seeds
- [ ] Collect performance, efficiency, and parameter metrics
- [ ] Monitor training stability
- [ ] Save checkpoints for analysis

**Week 9-10: Statistical Analysis**
- [ ] Compute Shapley values for component contributions
- [ ] Hierarchical regression with interaction terms
- [ ] Partial correlation analysis
- [ ] Causal mediation analysis
- [ ] Power analysis validation

**Week 11-12: Reporting**
- [ ] Generate all figures and tables
- [ ] Write results section
- [ ] Prepare supplementary materials
- [ ] Code and data release

**Total Phase 2 Duration:** 12 weeks

**Computational Budget:**
- Implementation/debugging: 200 GPU-hours
- Initial experiments: 300 GPU-hours
- Full evaluation: 5 variants × 26 games × 5 seeds × 4 hours = 2,600 GPU-hours
- Ablations and sensitivity: 500 GPU-hours
- **Total:** ~3,600 GPU-hours (~$1,800 on A100s)

## Combined Timeline & Budget

**Total Duration:** 24 weeks (6 months)

**Total Computational Budget:**
- Phase 1: 4,600 GPU-hours
- Phase 2: 3,600 GPU-hours
- **Total:** 8,200 GPU-hours (~$4,100 on A100s)

**Personnel:**
- 1 PhD student/postdoc (full-time): 6 months
- 1 research engineer (50% time): 3 months
- 1 advisor (consultation): 10% time

## Key Deliverables

### Phase 1 Deliverables

1. **Reproduced SHI Implementation**
   - Complete codebase with all components
   - Validation against reported results
   - Documentation of all design choices

2. **Replication Report**
   - Comparison to original paper results
   - Analysis of any discrepancies
   - Lessons learned and implementation notes

3. **Baseline Performance Data**
   - Full Atari 100k results (26 games × 5 seeds)
   - Efficiency measurements
   - Ablation study results

### Phase 2 Deliverables

1. **GroupPool Implementation**
   - Low-parameter alternative codebase
   - Integration with Phase 1 infrastructure
   - Parameter count comparison

2. **Comparative Analysis**
   - Performance comparison (SHI vs. GroupPool)
   - Shapley value decomposition
   - Statistical test results

3. **Research Paper**
   - Introduction and motivation
   - Methods (replication + alternative)
   - Results with full statistical analysis
   - Discussion of trade-offs
   - Recommendations for practitioners

4. **Open-Source Release**
   - GitHub repository with both implementations
   - Pre-trained checkpoints
   - Evaluation scripts
   - Documentation and tutorials

## Risk Mitigation

### Risk 1: Phase 1 Replication Fails

**Symptom:** Cannot match reported SHI performance within ±10%

**Mitigation:**
1. Contact authors for clarification
2. Attempt partial replication (match ablations, not absolute performance)
3. Proceed with Phase 2 using best-effort baseline
4. Clearly document limitations in paper

**Contingency:** If replication fails completely, pivot to:
- Implement GroupPool on top of IRIS (well-documented baseline)
- Compare GroupPool-IRIS vs. vanilla IRIS
- Still provides value even without SHI replication

### Risk 2: GroupPool Performs Poorly

**Symptom:** GroupPool significantly worse than SHI (>10% gap)

**Mitigation:**
1. Analyze failure modes (which games? which components?)
2. Iterate on GroupPool design (different pooling methods, group sizes)
3. Report negative result (still valuable for community)

**Contingency:**
- Explore other low-parameter alternatives (e.g., learned clustering, soft grouping)
- Focus on understanding why hierarchy is necessary
- Contribute insights about inductive biases in world models

### Risk 3: Components Are Highly Correlated

**Symptom:** Shapley values show >80% overlap between components

**Mitigation:**
1. This is a valid scientific finding (components are redundant)
2. Recommend simplest effective combination
3. Provide guidance on which components to prioritize

**Contingency:**
- Shift focus to identifying minimal sufficient set
- Develop decision tree for component selection
- Provide cost-benefit analysis for practitioners

### Risk 4: Insufficient Statistical Power

**Symptom:** Cannot detect differences due to high variance

**Mitigation:**
1. Increase sample size (more seeds or games)
2. Use variance reduction techniques (stratification, control variates)
3. Report confidence intervals and effect sizes (not just p-values)

**Contingency:**
- Use Bayesian analysis (posterior distributions instead of p-values)
- Report practical significance (effect sizes) even if not statistically significant
- Acknowledge limitations and recommend future work

## Reporting Standards

### Transparency Checklist

- [ ] Pre-register Phase 2 hypotheses before running experiments
- [ ] Report all planned comparisons (even non-significant)
- [ ] Include negative results and failed experiments
- [ ] Provide full hyperparameter search logs
- [ ] Share all raw data (performance, efficiency, parameters)
- [ ] Document all deviations from original plan
- [ ] Include reproducibility instructions
- [ ] Provide computational budget breakdown

### Statistical Reporting

For each comparison, report:
1. **Effect size** (Cohen's d or Hedges' g)
2. **Confidence interval** (95% CI via bootstrap)
3. **p-value** (with correction for multiple comparisons)
4. **Power** (post-hoc power analysis)
5. **Practical significance** (is effect meaningful?)

### Visualization Standards

**Figure 1: Replication Validation**
- Scatter plot: Original results (x) vs. Replicated results (y)
- Diagonal line (perfect replication)
- 95% confidence bands
- Per-game annotations

**Figure 2: Component Contributions (Shapley Values)**
- Bar chart: Component → Marginal contribution
- Error bars (95% CI via bootstrap)
- Stacked bars showing total improvement

**Figure 3: Performance vs. Parameters**
- Scatter plot: Parameters (x) vs. Performance (y)
- Pareto frontier highlighted
- GroupPool vs. SHI comparison

**Figure 4: Interaction Effects**
- Heatmap: Component A × Component B → Performance
- Diagonal = independent effects
- Off-diagonal = interaction effects

**Figure 5: Mediation Analysis**
- Path diagram: Hierarchy → SPARTAN → Performance
- Path coefficients with significance stars
- Direct vs. indirect effects

## Expected Outcomes

### Scenario 1: GroupPool Matches SHI

**Finding:** GroupPool-Full achieves 95-100% of SHI-Full performance with 60% fewer parameters

**Interpretation:** Hierarchy is unnecessary complexity; grouped pooling is sufficient

**Recommendation:** Use GroupPool for simpler, more efficient implementation

**Impact:** Simplifies adoption of sparse imagination methods

### Scenario 2: Hierarchy Provides Unique Benefit

**Finding:** SHI-Full significantly outperforms GroupPool-Full (>5% gap)

**Interpretation:** Semantic hierarchy provides important inductive bias

**Recommendation:** Use SHI when performance is critical; GroupPool when simplicity/efficiency is priority

**Impact:** Clarifies when hierarchical structure is worth the complexity

### Scenario 3: Components Are Redundant

**Finding:** Shapley analysis shows SPARTAN accounts for 80%+ of improvement; hierarchy/pooling add little

**Interpretation:** Causal graph learning is key mechanism; masking strategy is secondary

**Recommendation:** Focus on improving SPARTAN; use simplest masking (GroupPool or even random)

**Impact:** Redirects research effort to causal graph learning

### Scenario 4: Context-Dependent Trade-offs

**Finding:** Hierarchy helps on complex games (Montezuma), GroupPool sufficient for simple games (Pong)

**Interpretation:** Optimal approach depends on environment complexity

**Recommendation:** Adaptive method selection based on environment features

**Impact:** Enables principled deployment decisions

## Sources

This replication plan is based on:
- [heirarchical-transformer.pdf] - "Sparse Hierarchical Imagination for Efficient Transformer World Models" - provides the hierarchical token organization [heirarchical-transformer.pdf:2], SPARTAN causal graph integration [heirarchical-transformer.pdf:2,3], joint/alternating training approach [heirarchical-transformer.pdf:2], selective reconstruction at checkpoints [heirarchical-transformer.pdf:3], evaluation on Atari 100k and Crafter [heirarchical-transformer.pdf:3], and planned ablation studies [heirarchical-transformer.pdf:3]

For methodological guidance, I recommend:
- **Replication methodology:** Gundersen & Kjensmo (2018) "State of the Art: Reproducibility in Artificial Intelligence" (AAAI)
- **Power analysis:** Cohen (1988) "Statistical Power Analysis for the Behavioral Sciences"
- **Shapley values:** Lundberg & Lee (2017) "A Unified Approach to Interpreting Model Predictions" (NeurIPS)
- **Causal mediation:** Imai et al. (2010) "A General Approach to Causal Mediation Analysis" (Psychological Methods)
- **Multiple comparisons:** Holm (1979) "A Simple Sequentially Rejective Multiple Test Procedure" (Scandinavian Journal of Statistics)

For baseline implementations:
- **IRIS:** Micheli et al. (2023) "Transformers are Sample-Efficient World Models" [heirarchical-transformer.pdf:4]
- **SPARTAN:** Lei et al. (2024) (referenced in paper) [heirarchical-transformer.pdf:2]
- **STORM:** Zhang et al. (2023) (referenced for uncertainty estimation) [heirarchical-transformer.pdf:3]