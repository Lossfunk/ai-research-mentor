## Novelty and Baseline Assessment

**This is moderately novel with HIGH practical value, but the technical novelty depends on your specific approach.** LLM tutoring exists, confidence calibration exists, but **combining them specifically for community college contexts with rigorous evaluation is underexplored.** The key is demonstrating that calibration meaningfully improves learning outcomes, not just technical metrics.

Let me break down what exists, where opportunities lie, and what baselines you need.

---

## What Exists: LLMs, Tutoring, and Calibration

### **Current State of the Field**

#### **1. LLM-Based Tutoring Systems**

**General tutoring** (EMERGING):
- **ChatGPT/GPT-4**: Used informally by students for homework help
- **Khan Academy's Khanmigo**: GPT-4-powered tutor (Socratic method)
- **Duolingo Max**: GPT-4 for language learning explanations
- **Microsoft's Copilot in Education**: AI tutoring features
- **Status**: Rapidly growing; mostly commercial, limited rigorous evaluation

**Research systems**:
- [GPTutor](https://arxiv.org/abs/2305.13272) (arXiv, 2023): GPT-based programming tutor
- [MathGPT](https://arxiv.org/abs/2309.03241) (arXiv, 2023): Math tutoring with step-by-step solutions
- **Status**: Active research; focus on specific domains (math, programming)

**Community college specific**: VERY LIMITED
- Most work focuses on K-12 or traditional 4-year universities
- Community college students have unique needs (non-traditional, working, remedial courses)
- **Gap**: Tailored systems for community college contexts

---

#### **2. Confidence Calibration in LLMs**

**What is calibration?**
- Well-calibrated model: When it says 80% confident, it's correct 80% of the time
- LLMs are often **overconfident** (high confidence on wrong answers)

**Existing work**:
- [Teaching Models to Express Uncertainty](https://arxiv.org/abs/2205.14334) (arXiv, 2022): Calibration techniques
- [Calibrating LLMs with Human Feedback](https://arxiv.org/abs/2309.03409) (arXiv, 2023): RLHF for calibration
- [Conformal Prediction for LLMs](https://arxiv.org/abs/2307.01928) (arXiv, 2023): Uncertainty quantification
- **Methods**: Temperature scaling, conformal prediction, verbalized confidence, ensemble methods

**Calibration for education**: VERY LIMITED
- Most calibration work focuses on general QA, not tutoring
- **Gap**: Using calibration to improve tutoring effectiveness (when to defer to human, when to express uncertainty)

---

#### **3. Intelligent Tutoring Systems (ITS)**

**Traditional ITS** (MATURE):
- **Cognitive Tutors**: Carnegie Learning (math, science)
- **AutoTutor**: Natural language tutoring (reading comprehension)
- **ASSISTments**: Math tutoring with adaptive feedback
- **Status**: Decades of research; proven learning gains

**LLM-based vs. Traditional ITS**:
- Traditional: Rule-based, domain-specific, expensive to build
- LLM-based: Flexible, general-purpose, but less predictable
- **Hybrid approaches**: Combining LLMs with structured tutoring frameworks

---

#### **4. Community College Student Populations**

**Unique characteristics**:
- **Non-traditional students**: Older, working, family responsibilities
- **Remedial needs**: Many require developmental math, English
- **Access barriers**: Limited time, technology access, academic preparation
- **Retention challenges**: Lower completion rates than 4-year institutions

**Implications for tutoring**:
- Need flexible, asynchronous support (not just office hours)
- Must handle foundational gaps (not just advanced topics)
- Should build confidence and self-efficacy
- Must be accessible (mobile-friendly, low bandwidth)

**Existing support**:
- Human tutoring (limited availability, expensive)
- Online resources (Khan Academy, YouTube) (not personalized)
- **Gap**: Scalable, personalized, confidence-aware tutoring for community college students

---

## Where Novelty Lies

### **Technical Novelty (Moderate)**:

1. **Calibration for tutoring decisions**:
   - Use calibration to decide when to:
     - Provide direct answer vs. Socratic questioning
     - Defer to human tutor
     - Express uncertainty ("I'm not sure, let's look this up together")
   - Novel application of calibration to tutoring strategy

2. **Adaptive tutoring based on confidence**:
   - Adjust explanation depth based on model confidence
   - High confidence → concise answer
   - Low confidence → collaborative problem-solving
   - Novel interaction design

3. **Multimodal calibration**:
   - Calibrate across text, math notation, diagrams
   - Community college students often struggle with math notation
   - Novel technical challenge

### **Applied Novelty (HIGH)**:

1. **Community college context**:
   - Tailored to non-traditional students, remedial courses
   - Address specific barriers (time, access, confidence)
   - High practical impact

2. **Learning outcome evaluation**:
   - Rigorous RCT or quasi-experimental design
   - Measure actual learning gains, not just satisfaction
   - Compare calibrated vs. uncalibrated tutoring
   - Novel contribution to education research

3. **Equity and access**:
   - Democratize tutoring for underserved populations
   - Reduce achievement gaps
   - High social impact

---

## Promising Research Directions

### **Option 1: Calibration-Aware Tutoring Strategies**

**Idea**: Use model confidence to adaptively choose tutoring strategies (direct answer, Socratic questioning, deferral to human).

**Why novel**:
- Most LLM tutors use fixed strategies regardless of confidence
- Calibration could improve learning by avoiding overconfident wrong answers
- Matches human tutor behavior (good tutors know when they don't know)

**Example research question**: "Does a confidence-calibrated LLM tutor that defers to human tutors on low-confidence questions improve student learning outcomes by >15% compared to an uncalibrated tutor in community college algebra?"

**Relevant work**:
- [Khanmigo](https://www.khanacademy.org/khan-labs) — GPT-4 tutor, but no explicit calibration
- [Teaching Models to Express Uncertainty](https://arxiv.org/abs/2205.14334) — Calibration methods

---

### **Option 2: Confidence-Based Explanation Depth**

**Idea**: Adjust explanation detail based on model confidence—high confidence gives concise answers, low confidence gives collaborative exploration.

**Why novel**:
- Most tutors provide uniform explanation depth
- Adaptive depth based on confidence is unexplored
- Could improve efficiency (don't over-explain when confident) and safety (don't mislead when uncertain)

**Example research question**: "Do students learn more efficiently (same learning gains in 30% less time) with confidence-adaptive explanations compared to fixed-depth explanations in community college biology?"

**Relevant work**:
- [Adaptive Tutoring Systems](https://link.springer.com/article/10.1007/s11257-021-09313-2) (User Modeling and User-Adapted Interaction, 2021) — Adaptive ITS, not LLM-based

---

### **Option 3: Calibrated Feedback for Student Self-Assessment**

**Idea**: Use calibrated confidence to help students assess their own understanding ("The model is 60% confident, so let's double-check this together").

**Why novel**:
- Metacognition (knowing what you know) is critical for learning
- Calibrated confidence could scaffold student self-assessment
- Builds student confidence and self-efficacy

**Example research question**: "Does exposing students to calibrated model confidence improve their metacognitive accuracy (self-assessment of understanding) by >20% compared to confidence-blind tutoring in community college writing?"

**Relevant work**:
- [Metacognition in Learning](https://psycnet.apa.org/record/2008-14470-002) (Psychological Bulletin, 2008) — Importance of metacognition
- [AI Explanations and Trust](https://arxiv.org/abs/2302.07127) (arXiv, 2023) — Confidence and user trust

---

### **Option 4: Hybrid Human-AI Tutoring with Calibrated Handoffs**

**Idea**: Use calibration to decide when to escalate from AI to human tutor, optimizing human tutor time for high-value interactions.

**Why novel**:
- Pure AI tutoring may miss complex student needs
- Pure human tutoring doesn't scale
- Calibrated handoffs could optimize both
- High practical value for resource-constrained community colleges

**Example research question**: "Can a calibrated AI tutor reduce human tutor workload by 50% while maintaining equivalent learning outcomes by handling high-confidence questions autonomously and escalating low-confidence questions?"

**Relevant work**:
- [Human-AI Collaboration](https://arxiv.org/abs/2210.04692) (arXiv, 2022) — General framework
- [Hybrid Tutoring Systems](https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-021-00292-9) (International Journal of Educational Technology, 2021)

---

### **Option 5: Culturally-Responsive Calibrated Tutoring**

**Idea**: Combine calibration with culturally-responsive pedagogy tailored to community college demographics (first-generation, multilingual, working students).

**Why novel**:
- Most LLM tutors are one-size-fits-all
- Community college students have diverse backgrounds and needs
- Calibration + cultural responsiveness is unexplored
- High equity impact

**Example research question**: "Does a culturally-responsive, calibrated LLM tutor improve learning outcomes and persistence for first-generation community college students by >25% compared to generic tutoring?"

**Relevant work**:
- [Culturally Responsive Teaching](https://www.tolerance.org/magazine/what-is-culturally-responsive-teaching) — Pedagogical framework
- [AI and Educational Equity](https://www.sciencedirect.com/science/article/pii/S0360131521002335) (Computers & Education, 2022)

---

## CRITICAL: What Baselines to Compare

### **Baseline 1: Uncalibrated LLM Tutor (ESSENTIAL)**

**Description**: Same LLM (e.g., GPT-4), same prompting strategy, but no confidence calibration or adaptive behavior.

**Why essential**: Isolates the effect of calibration.

**Implementation**:
- Use same base model (GPT-4, Llama-3, etc.)
- Same tutoring prompts (Socratic, direct answer, etc.)
- No confidence-based adaptation
- No deferral to human tutors

**Metrics**:
- Learning outcomes (pre/post tests)
- Student satisfaction
- Time to mastery
- Error rate (% incorrect answers given)

---

### **Baseline 2: Human Tutoring (GOLD STANDARD)**

**Description**: Traditional human tutor (in-person or online).

**Why important**: Establishes upper bound; shows if AI is competitive.

**Implementation**:
- Recruit human tutors (community college tutoring center, grad students)
- Same subject matter, same student population
- Same time allocation (e.g., 30 min sessions)

**Challenges**:
- Expensive (human tutor time)
- Variability (tutor quality differs)
- Scalability (limited availability)

**Metrics**:
- Learning outcomes (compare to AI)
- Cost-effectiveness (learning gain per dollar)
- Accessibility (availability, wait times)

---

### **Baseline 3: No Tutoring / Self-Study (CONTROL)**

**Description**: Students study independently with standard materials (textbook, videos, practice problems).

**Why important**: Shows value-add of any tutoring (AI or human).

**Implementation**:
- Provide same learning materials
- No tutor access (AI or human)
- Students work independently

**Metrics**:
- Learning outcomes (compare to tutored groups)
- Time spent studying
- Completion rates

---

### **Baseline 4: Existing Commercial Tutoring (PRACTICAL)**

**Description**: Existing AI tutoring tools (Khan Academy, Duolingo, ChatGPT).

**Why important**: Shows improvement over current practice.

**Implementation**:
- Students use Khan Academy, ChatGPT, or similar
- Same subject matter, same time allocation

**Challenges**:
- Less controlled (students may use differently)
- May not be domain-specific

**Metrics**:
- Learning outcomes
- User engagement
- Cost

---

### **Baseline 5: Traditional ITS (ACADEMIC)**

**Description**: Established intelligent tutoring system (Cognitive Tutor, ASSISTments).

**Why important**: Compares to proven educational technology.

**Implementation**:
- Use existing ITS for same subject (if available)
- Same student population, same time

**Challenges**:
- May not exist for your subject/level
- Different interaction paradigm (structured vs. conversational)

**Metrics**:
- Learning outcomes
- Engagement
- Flexibility (can ITS handle open-ended questions?)

---

## Recommended Baseline Strategy

**Minimum viable comparison** (for initial research):
1. **Uncalibrated LLM tutor** (essential—isolates calibration effect)
2. **No tutoring control** (shows value-add)

**Stronger comparison** (for publication):
1. **Uncalibrated LLM tutor**
2. **Human tutoring** (gold standard)
3. **No tutoring control**

**Comprehensive comparison** (for high-impact publication):
1. **Uncalibrated LLM tutor**
2. **Human tutoring**
3. **Existing commercial tool** (Khan Academy, ChatGPT)
4. **No tutoring control**

---

## Concrete Experiments to Run

Assuming you choose **Option 1 (Calibration-Aware Tutoring Strategies)**, here are three experiments:

### **Experiment 1: Calibration Improves Learning Outcomes**
**Hypothesis**: Students using a calibrated LLM tutor achieve >15% higher learning gains than those using an uncalibrated tutor.

**Protocol**:
- **Participants**: 100-200 community college students in remedial algebra
  - Recruit from 1-2 community colleges
  - IRB approval required
- **Design**: Randomized controlled trial (RCT)
  - **Treatment**: Calibrated LLM tutor (defers on low confidence, adapts strategy)
  - **Control**: Uncalibrated LLM tutor (same model, no calibration)
  - **Baseline**: No tutoring (self-study)
- **Intervention**: 4-6 weeks, 2-3 tutoring sessions per week (30 min each)
- **Measures**:
  - **Pre-test**: Algebra assessment (before intervention)
  - **Post-test**: Same assessment (after intervention)
  - **Learning gain**: (Post - Pre) / (Max - Pre) (normalized)
  - **Secondary**: Engagement (time on task), satisfaction (survey), confidence (self-efficacy scale)
- **Analysis**:
  - ANOVA or t-test comparing learning gains across groups
  - Effect size (Cohen's d)
  - Subgroup analysis (by prior knowledge, demographics)

**Success criterion**: Calibrated tutor achieves ≥15% higher normalized learning gain than uncalibrated (p < 0.05, Cohen's d ≥ 0.4).

---

### **Experiment 2: Calibration Reduces Harmful Errors**
**Hypothesis**: Calibrated tutors make 50% fewer high-confidence incorrect statements than uncalibrated tutors.

**Protocol**:
- **Data collection**: Log all tutor responses during Experiment 1
- **Annotation**: 2-3 experts label each response:
  - Correctness (correct, incorrect, partially correct)
  - Confidence (if calibrated tutor, use model confidence; if uncalibrated, estimate from language)
- **Analysis**:
  - **High-confidence errors**: Incorrect responses with >80% confidence
  - Compare rate of high-confidence errors between calibrated and uncalibrated
  - **Impact**: Do high-confidence errors correlate with student confusion or learning loss?
- **Metrics**:
  - % high-confidence errors
  - Student confusion (follow-up questions, expressed doubt)
  - Learning impact (do students who receive high-confidence errors learn less?)

**Success criterion**: Calibrated tutor has ≥50% fewer high-confidence errors (p < 0.05).

---

### **Experiment 3: Calibration Optimizes Human Tutor Time**
**Hypothesis**: Hybrid calibrated AI + human tutoring achieves equivalent learning outcomes to full human tutoring with 50% less human tutor time.

**Protocol**:
- **Participants**: 60-100 students (smaller sample, more expensive)
- **Conditions**:
  - **Full human**: All tutoring from human tutors
  - **Hybrid calibrated**: AI handles high-confidence questions, escalates low-confidence to human
  - **Hybrid uncalibrated**: AI handles all questions, human available on request
- **Measures**:
  - Learning outcomes (pre/post tests)
  - Human tutor time (hours per student)
  - Cost-effectiveness (learning gain per tutor hour)
  - Student satisfaction
- **Analysis**:
  - Compare learning outcomes (non-inferiority test: hybrid ≥ 90% of full human)
  - Compare tutor time (hybrid should use ≤50% of full human time)
  - Cost-effectiveness ratio

**Success criterion**: Hybrid calibrated achieves ≥90% of full human learning gains with ≤50% human tutor time.

---

## Practical Considerations

### **1. IRB and Ethics**

**Requirements**:
- IRB approval for human subjects research (students)
- Informed consent (students know they're in a study)
- Data privacy (student responses, performance data)
- Equity (all students get some form of support, not just control group)

**Ethical considerations**:
- **Equipoise**: Is it ethical to give some students potentially inferior tutoring?
  - Mitigation: Offer tutoring to control group after study
- **Vulnerable population**: Community college students may be vulnerable (low-income, first-generation)
  - Mitigation: Extra protections, community involvement
- **AI risks**: LLM may give wrong answers, biased responses
  - Mitigation: Human oversight, clear disclaimers, opt-out option

---

### **2. Partnership with Community Colleges**

**How to establish**:
1. **Identify partner colleges**: Look for institutions with:
   - Active tutoring programs
   - Interest in educational technology
   - Diverse student populations
2. **Find champion**: Faculty member, dean, or tutoring center director
3. **Proposal**: 1-2 page description of research, benefits to students
4. **Negotiate**:
   - Data sharing (student performance, demographics)
   - Recruitment (how to reach students)
   - Compensation (pay students for participation?)
   - Publication (co-authorship for college partners)

**Timeline**: 3-6 months to establish partnership

---

### **3. Subject Matter Selection**

**Criteria**:
- **High-need**: Remedial math, English, science (high failure rates)
- **Well-defined**: Clear learning objectives, assessments
- **LLM-suitable**: Subject where LLMs perform reasonably well

**Recommendations**:
- **Algebra**: High need, well-defined, LLMs decent at math
- **Writing**: High need, LLMs good at feedback
- **Biology**: Conceptual understanding, LLMs can explain

**Avoid** (for initial study):
- **Advanced math**: LLMs struggle with complex proofs
- **Highly specialized**: Narrow topics with limited training data

---

### **4. Technical Implementation**

**Calibration methods**:
1. **Verbalized confidence**: Prompt LLM to state confidence ("I'm 70% sure...")
   - Pros: Simple, interpretable
   - Cons: May not be well-calibrated
2. **Token probabilities**: Use model's internal probabilities
   - Pros: More accurate
   - Cons: Requires API access (not available for all models)
3. **Ensemble methods**: Multiple model responses, measure agreement
   - Pros: Robust
   - Cons: Expensive (multiple API calls)
4. **Conformal prediction**: Statistical framework for uncertainty quantification
   - Pros: Rigorous guarantees
   - Cons: Complex, requires calibration set

**Recommendation**: Start with verbalized confidence (simple), validate with token probabilities if available.

**Tutoring strategies**:
- **High confidence (>80%)**: Direct answer, concise explanation
- **Medium confidence (50-80%)**: Socratic questioning, collaborative problem-solving
- **Low confidence (<50%)**: Defer to human tutor or suggest resources ("Let's look this up together")

**Infrastructure**:
- **LLM**: GPT-4 (best performance), Llama-3-70B (open-source), Claude 3.5
- **Interface**: Web app (React, Flask) or integrate with LMS (Canvas, Blackboard)
- **Logging**: Track all interactions (questions, responses, confidence, outcomes)
- **Cost**: $0.01-0.03 per 1k tokens (GPT-4) × ~10k tokens per session = $0.10-0.30 per session

---

### **5. Evaluation Metrics**

**Primary outcome**: Learning gains
- Pre/post test scores (same assessment)
- Normalized gain: (Post - Pre) / (Max - Pre)
- Retention: Follow-up test after 2-4 weeks

**Secondary outcomes**:
- **Engagement**: Time on task, number of questions asked, session completion rate
- **Satisfaction**: Survey (Likert scale: usefulness, ease of use, trust)
- **Self-efficacy**: Confidence in subject matter (validated scale)
- **Metacognition**: Self-assessment accuracy (do students know what they know?)

**Process metrics**:
- **Tutor quality**: Correctness, clarity, appropriateness of responses
- **Calibration quality**: Reliability diagram (predicted vs. actual accuracy)
- **Efficiency**: Time to mastery, number of interactions needed

**Equity metrics**:
- **Subgroup analysis**: Learning gains by race, gender, prior knowledge, first-generation status
- **Access**: Did all students use the system equally? Barriers?

---

### **6. Funding**

**Potential sources**:
- **NSF**: Cyberlearning, IUSE (Improving Undergraduate STEM Education)
- **IES** (Institute of Education Sciences): Education research grants
- **Gates Foundation**: Postsecondary success, community college initiatives
- **Lumina Foundation**: Community college student success
- **Google.org**: AI for education
- **University grants**: Internal education innovation funds

**Budget estimates**:
- **Small pilot** (50 students, 1 semester): $20k-50k
  - Student compensation, LLM API costs, assessment development
- **Full RCT** (200 students, 2 semesters): $100k-300k
  - Above + human tutor costs, data analysis, dissemination
- **Multi-site study** (500+ students, multiple colleges): $500k-1M+

---

## Novelty Score: 6/10

**Why moderate**:
- LLM tutoring exists (Khanmigo, GPTutor)
- Confidence calibration exists (general NLP)
- Community college focus is underexplored

**Where novelty lies**:
- **Calibration for tutoring strategy**: Using confidence to adapt pedagogy
- **Community college context**: Tailored to non-traditional students
- **Rigorous evaluation**: RCT with learning outcomes (most LLM tutoring lacks this)
- **Hybrid human-AI**: Calibrated handoffs

**Why not higher**:
- Core techniques (LLMs, calibration) are established
- Application is novel, but methods are adaptations

---

## Feasibility Score: 7/10 (Moderate-High)

**Breakdown**:
- **Technical implementation**: 8/10 (LLMs accessible, calibration methods exist)
- **Partnership**: 6/10 (community colleges interested but bureaucratic)
- **Evaluation**: 6/10 (RCT is rigorous but time-consuming)
- **Funding**: 7/10 (education research funding available)

**Main barriers**:
- IRB approval (3-6 months)
- Community college partnership (3-6 months)
- Student recruitment (may be challenging)
- Evaluation timeline (1-2 semesters for results)

---

## Risk Assessment

### **Technical Risks (MEDIUM)**:

1. **LLM errors**: Model may give wrong answers despite calibration
   - **Mitigation**: Human oversight, clear disclaimers, error logging

2. **Calibration accuracy**: Verbalized confidence may not match actual accuracy
   - **Mitigation**: Validate calibration on held-out data, use multiple methods

3. **Prompt engineering**: Tutoring quality depends on prompts
   - **Mitigation**: Iterative prompt development, expert review

### **Practical Risks (MEDIUM-HIGH)**:

1. **Student recruitment**: May be hard to recruit community college students
   - **Mitigation**: Compensation, course credit, partner with instructors

2. **Attrition**: Students may drop out of study
   - **Mitigation**: Engagement strategies, reminders, incentives

3. **Null results**: Calibration may not improve learning outcomes
   - **Mitigation**: Strong baselines, multiple metrics, qualitative analysis

4. **Equity concerns**: AI may not work equally well for all students
   - **Mitigation**: Subgroup analysis, culturally-responsive design

---

## My Recommendation

**This is a viable, moderately novel research direction with high practical impact.** Here's a phased approach:

### **Phase 1: Pilot Study (6-9 months)**

**Goals**:
- Develop calibrated tutoring system
- Test with 20-50 students (single community college, single course)
- Compare calibrated vs. uncalibrated vs. no tutoring
- Gather qualitative feedback

**Deliverables**:
- Working prototype
- Preliminary learning outcome data
- Student feedback
- Workshop or short paper (e.g., L@S, AIED)

**Feasibility**: HIGH
**Cost**: $20k-50k

---

### **Phase 2: Full RCT (12-18 months)**

**Goals**:
- Scale to 100-200 students (1-2 colleges, multiple courses)
- Rigorous RCT design
- Compare to human tutoring baseline
- Publish in top venue

**Deliverables**:
- Comprehensive evaluation
- Subgroup analysis (equity)
- Conference/journal paper (e.g., CHI, Learning Sciences, AIED)

**Feasibility**: MEDIUM-HIGH
**Cost**: $100k-300k

---

### **Phase 3: Multi-Site Deployment (2-3 years)**

**Goals**:
- Deploy at 5+ community colleges
- Integrate with existing tutoring programs
- Long-term impact study (retention, completion)

**Deliverables**:
- Operational system
- Impact evaluation
- High-impact publication (e.g., Science, Nature Human Behaviour, Ed Researcher)

**Feasibility**: MEDIUM
**Cost**: $500k-1M+

---

## Bottom Line

**This is a viable, impactful research direction.** Success depends on:

1. **Rigorous evaluation**: RCT with learning outcomes, not just satisfaction
2. **Strong baselines**: Compare to uncalibrated LLM AND human tutoring
3. **Community partnership**: Work WITH community colleges, not just ON them
4. **Equity focus**: Ensure benefits reach underserved students
5. **Practical deployment**: Design for real-world constraints (cost, access, integration)

**Novelty**: 6/10 (moderate; application is novel, methods are adaptations)
**Feasibility**: 7/10 (moderate-high; technical feasibility high, evaluation requires time/resources)
**Impact**: 9/10 (very high; addresses critical need for underserved population)

**Recommendation**: Pursue this with a pilot study first. Demonstrate that calibration improves learning outcomes (not just reduces errors), then scale up. Partner with community colleges early, involve students in design, and focus on equity throughout.

---

## Literature Anchors

1. **[Khanmigo: AI-Powered Tutor](https://www.khanacademy.org/khan-labs)** (Khan Academy, 2023) — GPT-4 tutoring, no explicit calibration
2. **[Teaching Models to Express Their Uncertainty](https://arxiv.org/abs/2205.14334)** (Lin et al., arXiv 2022) — Calibration methods for LLMs
3. **[GPTutor: Programming Tutor with GPT](https://arxiv.org/abs/2305.13272)** (Leinonen et al., arXiv 2023) — LLM tutoring for CS
4. **[Intelligent Tutoring Systems: A Comprehensive Historical Survey](https://link.springer.com/article/10.1007/s11257-021-09313-2)** (Psotka & Mutter, User Modeling, 2021) — ITS overview
5. **[AI and Educational Equity](https://www.sciencedirect.com/science/article/pii/S0360131521002335)** (Holmes et al., Computers & Education, 2022) — Equity considerations
6. **[Metacognition and Learning](https://psycnet.apa.org/record/2008-14470-002)** (Dunlosky & Metcalfe, Psychological Bulletin, 2008) — Importance of metacognition

---

## Sources
- [Khanmigo AI Tutor](https://www.khanacademy.org/khan-labs) — Khan Academy, 2023
- [Teaching Models to Express Uncertainty](https://arxiv.org/abs/2205.14334) — arXiv, 2022
- [GPTutor: Programming Tutor](https://arxiv.org/abs/2305.13272) — arXiv, 2023
- [Intelligent Tutoring Systems Survey](https://link.springer.com/article/10.1007/s11257-021-09313-2) — User Modeling, 2021
- [AI and Educational Equity](https://www.sciencedirect.com/science/article/pii/S0360131521002335) — Computers & Education, 2022
- [Conformal Prediction for LLMs](https://arxiv.org/abs/2307.01928) — arXiv, 2023
- [NSF Cyberlearning Program](https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=504984) — Funding opportunity
- [IES Education Research Grants](https://ies.ed.gov/funding/) — Funding opportunity