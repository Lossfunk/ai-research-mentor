## Novelty and Feasibility Assessment

**This is moderately novel with moderate-to-high feasibility, depending on your scope.** RL for autonomous drones is well-established, and wildfire monitoring drones exist, but **RL for active wildfire *containment* (not just monitoring) is less explored and presents significant technical and practical challenges.**

Let me break down what exists, where opportunities lie, and how to assess feasibility.

---

## What Exists: RL, Drones, and Wildfires

### **Current State of the Field**

#### **1. Drones for Wildfire Applications**

**Monitoring and detection** (MATURE):
- **Commercial systems**: DJI, senseFly, others used for fire detection, mapping
- **Research**: Computer vision for smoke/fire detection, thermal imaging
- **Deployment**: Widely used by fire agencies (CAL FIRE, USFS, etc.)
- **Status**: Operational; not novel

**Suppression/containment** (EMERGING):
- **Water/retardant dropping**: Some experimental systems (mostly large drones/helicopters)
- **Firebreak creation**: Very limited work
- **Active containment**: Minimal deployment; mostly conceptual
- **Status**: Early stage; opportunity for novelty

#### **2. Reinforcement Learning for Drones**

**General drone control** (MATURE):
- **Navigation**: RL for obstacle avoidance, path planning
- **Swarm coordination**: Multi-agent RL for drone swarms
- **Examples**:
  - [Learning to Fly by Crashing](https://arxiv.org/abs/1704.05588) (arXiv, 2017)
  - [Multi-Agent RL for Drone Swarms](https://arxiv.org/abs/2010.05273) (arXiv, 2020)
- **Status**: Well-established; many papers

**Disaster response** (MODERATE):
- **Search and rescue**: RL for victim detection, area coverage
- **Damage assessment**: Post-disaster mapping
- **Limited work on active intervention** (suppression, containment)
- **Status**: Active research area

#### **3. Wildfire Modeling and Simulation**

**Fire spread models** (MATURE):
- **Physics-based**: FARSITE, FlamMap, WRF-Fire (weather + fire dynamics)
- **Data-driven**: ML models for fire spread prediction
- **Cellular automata**: Grid-based fire propagation
- **Status**: Well-established; used operationally

**RL for wildfire management** (EMERGING):
- **Resource allocation**: RL for deploying firefighting resources
- **Prescribed burns**: RL for planning controlled burns
- **Limited work on real-time containment**
- **Examples**:
  - [RL for Wildfire Resource Allocation](https://arxiv.org/abs/2111.02755) (arXiv, 2021)
  - [Deep RL for Prescribed Fire Planning](https://www.sciencedirect.com/science/article/pii/S1364815221001602) (Environmental Modelling & Software, 2021)
- **Status**: Early research; not deployed

---

## Where Novelty Lies

### **Technical Novelty (Moderate-High)**:

1. **Active containment vs. monitoring**:
   - Most drone work is passive (observe, map)
   - Active intervention (dropping retardant, creating firebreaks) is underexplored
   - RL for real-time containment decisions is novel

2. **Multi-agent coordination**:
   - Coordinating swarms of drones for containment
   - Distributed decision-making under communication constraints
   - Heterogeneous teams (different drone types, capabilities)

3. **Sim-to-real transfer**:
   - Training in simulation, deploying in real wildfires
   - Domain randomization for fire dynamics, weather, terrain
   - Safety-critical deployment challenges

4. **Partial observability**:
   - Smoke obscures vision, fire spreads unpredictably
   - POMDP formulation with uncertainty
   - Sensor fusion (thermal, visual, weather data)

### **Applied Novelty (High)**:

1. **Real-world impact**:
   - Wildfires cause billions in damage, loss of life
   - Early containment is critical (first 24 hours)
   - Autonomous systems could respond faster than human crews

2. **Integration with existing systems**:
   - Coordination with human firefighters, aircraft
   - Integration with fire prediction models
   - Operational deployment challenges

---

## Promising Research Directions

### **Option 1: RL for Autonomous Retardant Dropping**

**Idea**: Train RL agents to optimize where/when to drop fire retardant or water from drones to maximize containment effectiveness.

**Why novel**:
- Most retardant dropping is manual (pilots, helicopters)
- RL could optimize drop locations based on fire spread predictions
- Multi-drone coordination for coverage

**Example research question**: "Can an RL-trained drone swarm reduce simulated wildfire spread by >30% compared to baseline strategies (perimeter defense, hotspot targeting) using 50% less retardant?"

**Relevant work**:
- [RL for Wildfire Resource Allocation](https://arxiv.org/abs/2111.02755) (arXiv, 2021) — Resource allocation, not drone control
- [Multi-Agent RL for Coverage](https://arxiv.org/abs/1908.02906) (arXiv, 2019) — General coverage, not wildfire

**Challenges**:
- Payload capacity (small drones carry limited retardant)
- Flight time constraints (battery life)
- Safety (flying near fire, smoke)

---

### **Option 2: RL for Firebreak Creation**

**Idea**: Use RL to plan and execute firebreak creation (clearing vegetation, controlled burns) using specialized drones.

**Why novel**:
- Firebreaks are critical containment strategy
- Autonomous creation is unexplored
- Requires long-term planning (where to create breaks) + short-term control (how to execute)

**Example research question**: "Can RL agents plan optimal firebreak locations and coordinate drone execution to contain simulated wildfires 40% faster than human-planned strategies?"

**Relevant work**:
- [Deep RL for Prescribed Fire Planning](https://www.sciencedirect.com/science/article/pii/S1364815221001602) (Environmental Modelling & Software, 2021) — Planning, not execution
- [Path Planning for Firefighting Robots](https://ieeexplore.ieee.org/document/8967572) (IEEE, 2020) — Ground robots, not drones

**Challenges**:
- Specialized equipment (vegetation clearing, ignition for backfires)
- Regulatory constraints (controlled burns require permits)
- Safety (creating fire to fight fire)

---

### **Option 3: Multi-Agent RL for Swarm Coordination**

**Idea**: Coordinate swarms of heterogeneous drones (monitoring, retardant dropping, communication relays) for wildfire containment.

**Why novel**:
- Heterogeneous swarms are underexplored for wildfires
- Communication constraints (smoke, terrain, range)
- Decentralized decision-making under uncertainty

**Example research question**: "Can a decentralized multi-agent RL approach coordinate 10+ heterogeneous drones to contain simulated wildfires with >25% improvement in containment time compared to centralized control?"

**Relevant work**:
- [Multi-Agent RL for Drone Swarms](https://arxiv.org/abs/2010.05273) (arXiv, 2020) — General swarms, not wildfire
- [Decentralized MARL](https://arxiv.org/abs/2006.07869) (arXiv, 2020) — General framework

**Challenges**:
- Scalability (10+ agents)
- Communication delays/failures
- Emergent behavior validation

---

### **Option 4: Sim-to-Real Transfer with Domain Randomization**

**Idea**: Develop RL policies in simulation with domain randomization (varying fire dynamics, weather, terrain) that transfer to real wildfire scenarios.

**Why novel**:
- Sim-to-real for wildfires is underexplored
- Fire dynamics are highly variable and uncertain
- Safety-critical deployment requires robust policies

**Example research question**: "Can RL policies trained with domain randomization on simulated wildfires achieve >80% of simulated performance when tested on real fire data (historical fire progression) without fine-tuning?"

**Relevant work**:
- [Sim-to-Real Transfer for Robotics](https://arxiv.org/abs/1703.06907) (arXiv, 2017) — General robotics
- [Domain Randomization for RL](https://arxiv.org/abs/1710.06537) (arXiv, 2017) — General framework

**Challenges**:
- Fidelity of fire simulation
- Validation without real wildfire deployment
- Safety constraints

---

### **Option 5: Safe RL with Human-in-the-Loop**

**Idea**: Develop safe RL approaches that allow human operators to intervene, provide feedback, or override drone decisions during wildfire containment.

**Why novel**:
- Safety is critical for wildfire applications
- Human-AI collaboration is underexplored for disaster response
- Regulatory requirements likely mandate human oversight

**Example research question**: "Can a safe RL approach with human-in-the-loop achieve >90% of fully autonomous performance while maintaining zero safety violations (defined by human operators) in simulated wildfire scenarios?"

**Relevant work**:
- [Safe Reinforcement Learning](https://arxiv.org/abs/1801.08757) (arXiv, 2018) — General safe RL
- [Human-in-the-Loop RL](https://arxiv.org/abs/1904.10509) (arXiv, 2019) — General framework

**Challenges**:
- Defining safety constraints
- Human workload (monitoring multiple drones)
- Latency in human feedback

---

## Feasibility Assessment Framework

### **Technical Feasibility**

#### **1. Simulation Environment (HIGH PRIORITY)**

**Requirements**:
- Realistic fire spread model (physics-based or data-driven)
- Drone dynamics (flight, payload, battery)
- Environmental factors (wind, terrain, smoke)
- Sensor models (thermal, visual, weather)

**Options**:
- **Custom simulator**: Build on existing fire models (FARSITE, cellular automata)
  - Pros: Full control, tailored to your needs
  - Cons: Time-consuming (3-6 months), validation challenges
- **Existing platforms**: Adapt robotics simulators (Gazebo, AirSim, Unity)
  - Pros: Faster setup, validated physics
  - Cons: May lack fire-specific features
- **Hybrid**: Couple fire model with robotics simulator
  - Pros: Best of both worlds
  - Cons: Integration complexity

**Feasibility**: HIGH if you use existing tools; MEDIUM if building custom simulator

**Recommendation**: Start with simple cellular automaton fire model + AirSim/Gazebo for drone dynamics

---

#### **2. RL Algorithm Selection**

**Considerations**:
- **Single-agent vs. multi-agent**: Start single-agent, scale to multi-agent
- **Model-free vs. model-based**: Model-free (PPO, SAC) easier to start; model-based (MPC, MBRL) more sample-efficient
- **On-policy vs. off-policy**: Off-policy (SAC, TD3) more sample-efficient
- **Continuous vs. discrete actions**: Continuous (drone control) or discrete (high-level decisions)

**Recommendations**:
- **Start**: PPO or SAC (well-established, stable)
- **Multi-agent**: MAPPO, QMIX, or MADDPG
- **Safety**: Constrained RL (CPO, TRPO with constraints)

**Feasibility**: HIGH (mature algorithms, good libraries)

---

#### **3. Computational Requirements**

**Training**:
- **Single-agent**: 1-2 GPUs, days to weeks
- **Multi-agent (10+ agents)**: 4-8 GPUs, weeks to months
- **Simulation speed**: Critical bottleneck (fire models can be slow)

**Inference** (deployment):
- Real-time control: <100ms latency
- On-board compute: Jetson Nano, Raspberry Pi, or offload to ground station

**Feasibility**: MEDIUM-HIGH (depends on simulation speed and scale)

**Recommendation**: Start small (single agent, simple fire model), scale up

---

#### **4. Validation and Evaluation**

**Levels of validation**:
1. **Simulation**: Compare to baselines (random, heuristic, human-designed strategies)
2. **Historical data**: Test on real fire progression data (if available)
3. **Controlled experiments**: Small-scale real fires (prescribed burns, controlled settings)
4. **Operational deployment**: Real wildfires (requires extensive validation, regulatory approval)

**Feasibility**:
- Simulation: HIGH
- Historical data: MEDIUM (data availability)
- Controlled experiments: LOW-MEDIUM (requires partnerships, permits, funding)
- Operational deployment: LOW (long timeline, regulatory hurdles)

**Recommendation**: Focus on simulation + historical data validation for research; partner with fire agencies for real-world testing

---

### **Practical Feasibility**

#### **5. Hardware and Equipment**

**Drone requirements**:
- **Monitoring**: Commercial drones (DJI Matrice, senseFly) ~$5k-20k
- **Retardant dropping**: Custom or specialized drones ~$20k-100k
- **Swarms**: Multiple drones = $50k-500k+

**Sensors**:
- Thermal cameras: $2k-10k
- Visual cameras: $500-2k
- Weather sensors: $500-2k

**Feasibility**:
- **Simulation-only research**: HIGH (no hardware needed)
- **Small-scale hardware validation**: MEDIUM (1-2 drones, $10k-30k)
- **Full swarm deployment**: LOW (expensive, complex)

**Recommendation**: Start simulation-only; seek funding/partnerships for hardware

---

#### **6. Regulatory and Safety Constraints**

**Drone regulations** (U.S. FAA, similar elsewhere):
- **Part 107**: Commercial drone operations (line-of-sight, <400ft, daylight)
- **Waivers**: Required for beyond visual line-of-sight (BVLOS), night operations, swarms
- **Restricted airspace**: Wildfires often have Temporary Flight Restrictions (TFRs)

**Wildfire-specific**:
- **Coordination**: Must coordinate with fire agencies, manned aircraft
- **Safety**: Risk of drone crashes, interference with firefighting
- **Liability**: Who's responsible if drone causes harm?

**Feasibility**:
- **Simulation research**: HIGH (no regulatory constraints)
- **Controlled testing**: MEDIUM (requires permits, waivers)
- **Operational deployment**: LOW (extensive regulatory approval, years)

**Recommendation**: Focus on simulation; partner with fire agencies for regulatory pathways

---

#### **7. Partnerships and Stakeholders**

**Essential partners**:
- **Fire agencies**: CAL FIRE, USFS, local fire departments (domain expertise, deployment)
- **Drone companies**: DJI, senseFly, custom manufacturers (hardware, integration)
- **Research institutions**: Wildfire research centers, robotics labs (collaboration, resources)
- **Regulators**: FAA, state agencies (approval, waivers)

**How to establish**:
1. Identify relevant agencies/companies
2. Reach out with brief proposal (1-2 pages)
3. Demonstrate value (simulation results, proof-of-concept)
4. Negotiate partnership (data sharing, testing, deployment)

**Feasibility**: MEDIUM (fire agencies are interested in innovation but cautious about unproven tech)

**Recommendation**: Start with academic collaborators; approach fire agencies with preliminary results

---

#### **8. Funding**

**Potential sources**:
- **NSF**: Cyber-Physical Systems, Smart & Connected Communities
- **USDA/USFS**: Wildfire research grants
- **DARPA**: Disaster response, autonomous systems
- **State agencies**: CAL FIRE, state emergency management
- **Industry**: Drone companies, insurance companies (wildfire risk reduction)

**Budget estimates**:
- **Simulation-only**: $50k-100k (student stipend, compute)
- **Small-scale hardware**: $100k-300k (drones, sensors, field testing)
- **Full deployment**: $1M+ (swarms, operational integration)

**Feasibility**: MEDIUM-HIGH (wildfire is a high-priority problem; funding available)

---

## Concrete Experiments to Run

Assuming you choose **Option 1 (RL for Retardant Dropping)**, here are three experiments:

### **Experiment 1: Single-Agent RL vs. Baselines**
**Hypothesis**: An RL-trained agent outperforms baseline strategies (perimeter defense, hotspot targeting) for retardant dropping by >20% in containment effectiveness.

**Protocol**:
- **Simulation**:
  - Fire model: Cellular automaton (simple) or FARSITE (realistic)
  - Drone: Single agent with limited retardant capacity
  - Environment: 1km² area, varying wind, terrain
- **Baselines**:
  - Random: Drop retardant randomly
  - Perimeter: Prioritize fire perimeter
  - Hotspot: Target highest-intensity areas
  - Heuristic: Human-designed strategy (consult fire experts)
- **RL agent**:
  - Algorithm: PPO or SAC
  - State: Fire map, drone position, retardant remaining, wind
  - Action: Where to drop retardant (continuous or discrete grid)
  - Reward: Negative fire spread area, penalty for retardant use
- **Training**: 1M-10M timesteps (days to weeks on 1-2 GPUs)
- **Evaluation**:
  - Metrics: Fire spread area, containment time, retardant efficiency
  - Test on 100+ fire scenarios (varying initial conditions)
  - Statistical significance testing

**Success criterion**: RL agent reduces fire spread by ≥20% compared to best baseline (p < 0.05).

---

### **Experiment 2: Multi-Agent Coordination**
**Hypothesis**: Multi-agent RL with 5 drones improves containment by >30% compared to 5 independent single-agent policies.

**Protocol**:
- **Setup**: 5 drones, each with limited retardant
- **Baselines**:
  - Independent: 5 agents trained independently (no coordination)
  - Centralized: Single policy controlling all 5 drones
- **Multi-agent RL**:
  - Algorithm: MAPPO, QMIX, or MADDPG
  - Communication: Shared observations (full info) vs. limited (realistic)
  - Coordination: Implicit (learned) vs. explicit (communication protocol)
- **Evaluation**:
  - Metrics: Containment time, retardant efficiency, coordination quality
  - Ablation: Test with 2, 3, 5, 10 agents (scalability)

**Success criterion**: Multi-agent RL achieves ≥30% improvement over independent agents.

---

### **Experiment 3: Sim-to-Real Transfer Validation**
**Hypothesis**: RL policies trained with domain randomization generalize to unseen fire scenarios (historical fire data) with <20% performance degradation.

**Protocol**:
- **Training**: Domain randomization over:
  - Fire spread rate (±50%)
  - Wind speed/direction (±30°, ±5 m/s)
  - Terrain (flat, hilly, mountainous)
  - Initial fire size/shape
- **Evaluation**:
  - Test on historical fire progression data (e.g., from USFS, CAL FIRE)
  - Compare simulated performance vs. performance on real fire data
  - Metrics: Generalization gap (% performance drop)
- **Analysis**:
  - Which factors cause largest performance drops?
  - Can we improve domain randomization based on results?

**Success criterion**: <20% performance degradation on real fire data compared to simulation.

---

## Novelty Score: 6.5/10

**Why moderate-high**:
- RL for drones is well-established
- Wildfire monitoring drones exist
- Active containment with RL is less explored
- Multi-agent coordination for wildfires is novel
- Sim-to-real transfer for safety-critical wildfire applications is novel

**Why not higher**:
- General RL techniques (PPO, SAC, MARL) are standard
- Wildfire simulation models exist
- Similar work on resource allocation, prescribed burns

---

## Feasibility Score: 6/10 (Moderate)

**Breakdown**:
- **Simulation research**: 8/10 (feasible with existing tools)
- **Small-scale hardware validation**: 5/10 (requires funding, partnerships)
- **Operational deployment**: 2/10 (long timeline, regulatory hurdles)

**Main barriers**:
- Simulation fidelity (fire models may not capture all dynamics)
- Hardware costs (drones, sensors)
- Regulatory approval (FAA waivers, TFRs)
- Stakeholder buy-in (fire agencies cautious about autonomous systems)

---

## Risk Assessment

### **Technical Risks (MEDIUM)**:

1. **Simulation-reality gap**: Policies may not transfer to real fires
   - **Mitigation**: Domain randomization, validate on historical data, conservative deployment

2. **Sample efficiency**: RL may require millions of samples (slow simulation)
   - **Mitigation**: Use efficient algorithms (SAC, model-based RL), parallel simulation

3. **Safety**: RL policies may take unsafe actions (crash, interfere with firefighters)
   - **Mitigation**: Safe RL, human-in-the-loop, extensive validation

### **Practical Risks (MEDIUM-HIGH)**:

1. **Regulatory barriers**: FAA approval for BVLOS, swarms, wildfire operations
   - **Mitigation**: Partner with fire agencies, start with simulation, seek waivers

2. **Stakeholder resistance**: Fire agencies may be skeptical of autonomous systems
   - **Mitigation**: Demonstrate value in simulation, involve firefighters in design, emphasize human oversight

3. **Funding**: Hardware and field testing are expensive
   - **Mitigation**: Start simulation-only, seek grants, partner with industry

4. **Timeline**: Operational deployment could take 5-10 years
   - **Mitigation**: Focus on research contributions (simulation, algorithms), not immediate deployment

---

## My Recommendation

**This is a viable, moderately novel research direction with real-world impact potential.** Here's a phased approach:

### **Phase 1: Simulation Research (6-12 months)**

**Goals**:
- Develop simulation environment (fire model + drone dynamics)
- Implement single-agent RL baseline
- Compare to heuristic strategies
- Publish initial results (workshop or conference)

**Deliverables**:
- Working simulator (open-source if possible)
- Trained RL policies
- Benchmark results vs. baselines
- Paper (e.g., ICRA, IROS, or wildfire-specific venue)

**Feasibility**: HIGH
**Cost**: Low ($0-10k for compute)

---

### **Phase 2: Multi-Agent and Advanced Methods (12-18 months)**

**Goals**:
- Scale to multi-agent coordination
- Implement domain randomization for sim-to-real
- Validate on historical fire data
- Explore safe RL, human-in-the-loop

**Deliverables**:
- Multi-agent RL results
- Sim-to-real transfer analysis
- Conference/journal paper (e.g., ICRA, IROS, Autonomous Robots)

**Feasibility**: MEDIUM-HIGH
**Cost**: Moderate ($10k-50k for compute, data)

---

### **Phase 3: Hardware Validation (18-36 months, optional)**

**Goals**:
- Partner with fire agency or research institution
- Test on small-scale controlled fires (prescribed burns)
- Demonstrate proof-of-concept with real drones

**Deliverables**:
- Field test results
- Lessons learned for operational deployment
- High-impact publication (e.g., Science Robotics, Nature Communications)

**Feasibility**: MEDIUM
**Cost**: High ($100k-500k for hardware, field testing)
**Requires**: Partnerships, funding, regulatory approvals

---

### **Phase 4: Operational Deployment (3-10 years, aspirational)**

**Goals**:
- Integrate with fire agency operations
- Obtain regulatory approvals
- Deploy in real wildfire scenarios

**Feasibility**: LOW-MEDIUM (long timeline, many dependencies)
**Cost**: Very high ($1M+)
**Requires**: Sustained funding, strong partnerships, proven track record

---

## Recommended Starting Point

**Start with Phase 1 (simulation research):**

1. **Build simple simulator** (2-3 months):
   - Cellular automaton fire model (or use existing like FARSITE)
   - AirSim or Gazebo for drone dynamics
   - Simple retardant dropping mechanics

2. **Implement baselines** (1 month):
   - Random, perimeter, hotspot strategies
   - Consult fire experts for heuristic strategies

3. **Train RL agent** (2-3 months):
   - Start with PPO or SAC
   - Single agent, single fire scenario
   - Tune hyperparameters, validate training

4. **Evaluate and iterate** (2-3 months):
   - Test on diverse fire scenarios
   - Compare to baselines
   - Analyze failure modes, improve

5. **Write paper** (2-3 months):
   - Target: ICRA, IROS, or wildfire-specific venue
   - Emphasize novelty (active containment, RL for wildfires)
   - Discuss limitations, future work

**Total timeline**: 9-15 months for Phase 1

---

## Literature Anchors

1. **[Reinforcement Learning for Wildfire Resource Allocation](https://arxiv.org/abs/2111.02755)** (Ganapathi Subramanian & Crowley, arXiv 2021) — RL for wildfire, but resource allocation not drone control
2. **[Deep Reinforcement Learning for Prescribed Fire Planning](https://www.sciencedirect.com/science/article/pii/S1364815221001602)** (Houtman et al., Environmental Modelling & Software 2021) — RL for fire planning
3. **[Multi-Agent Reinforcement Learning for Drone Swarms](https://arxiv.org/abs/2010.05273)** (Hu et al., arXiv 2020) — MARL for drones, not wildfire
4. **[Learning to Fly by Crashing](https://arxiv.org/abs/1704.05588)** (Gandhi et al., arXiv 2017) — RL for drone control
5. **[Sim-to-Real Transfer in Robotics](https://arxiv.org/abs/1703.06907)** (Tobin et al., arXiv 2017) — Domain randomization
6. **[Safe Reinforcement Learning](https://arxiv.org/abs/1801.08757)** (García & Fernández, arXiv 2018) — Safe RL survey

---

## Bottom Line

**This is a viable research direction with moderate novelty and feasibility.** Success depends on:

1. **Realistic simulation**: Fire models must capture key dynamics
2. **Strong baselines**: Compare to well-designed heuristics, not just random
3. **Validation strategy**: Historical data, controlled experiments, or partnerships
4. **Scope management**: Start small (single agent, simple fire), scale up
5. **Stakeholder engagement**: Involve fire experts early for domain knowledge and deployment pathways

**Novelty**: 6.5/10 (moderate-high; active containment with RL is underexplored)
**Feasibility**: 6/10 (moderate; simulation is feasible, real-world deployment is challenging)
**Impact**: 8/10 (high; wildfires are a critical problem with significant societal impact)

**Recommendation**: Pursue this with a phased approach. Start with simulation research (Phase 1), demonstrate value, then seek partnerships and funding for hardware validation (Phase 2-3). Don't expect operational deployment in the short term, but focus on research contributions that advance the field.

---

## Sources
- [RL for Wildfire Resource Allocation](https://arxiv.org/abs/2111.02755) — arXiv, 2021
- [Deep RL for Prescribed Fire Planning](https://www.sciencedirect.com/science/article/pii/S1364815221001602) — Environmental Modelling & Software, 2021
- [Multi-Agent RL for Drone Swarms](https://arxiv.org/abs/2010.05273) — arXiv, 2020
- [Learning to Fly by Crashing](https://arxiv.org/abs/1704.05588) — arXiv, 2017
- [Sim-to-Real Transfer in Robotics](https://arxiv.org/abs/1703.06907) — arXiv, 2017
- [Safe Reinforcement Learning Survey](https://arxiv.org/abs/1801.08757) — arXiv, 2018
- [FARSITE Fire Simulation](https://www.firelab.org/project/farsite) — USFS Fire Lab
- [AirSim Drone Simulator](https://microsoft.github.io/AirSim/) — Microsoft Research