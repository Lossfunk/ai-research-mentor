Short answer: Not saturated. Wildlife counting has strong prior work in aerial image detection and density-based counting, plus emerging transformer-based detectors for drone views, but there is clear room for novelty specifically around low-cost, data-efficient ViTs (tiny backbones, distillation, quantization), annotation‑efficient training, and robust uncertainty-aware counts at the edge [2][3][4]. Demonstrating rigorously better accuracy–cost trade‑offs (counts per watt, per dollar, and per hour of annotation) would be a publishable contribution.

Where novelty likely lies
- Edge efficiency as a first-class objective: Quantized/distilled ViTs (e.g., DeiT‑Tiny/MobileViT‑class) deployed on Jetson/Raspberry Pi with validated accuracy–latency–power curves; most wildlife work optimizes accuracy, not energy or hardware cost [3][4].
- Annotation minimization: Point/scribble supervision, active learning, and semi/self‑supervised pretraining to reduce labels needed for new sites/species; the aerial wildlife community explicitly highlights annotation burden as a bottleneck [2].
- Counting under occlusion/colonies: ViT‑based density map heads for huddled seabirds/seals vs box detection; density methods have shown promise for aerial animal counts but are underexplored with transformers [4].
- Uncertainty and calibration: Deliver calibrated abundance estimates (intervals) suitable for survey decisions, not just point counts (use conformal or probabilistic heads). General DL evaluations in wildlife note gaps in robustness/calibration [5].
- Cross‑site generalization: Pretrain on unlabeled aerial imagery and show few‑shot adaptation to new reserves/habitats with reliable uncertainty.

At least three concrete, falsifiable experiments
- E1. Accuracy–latency–power frontier on edge devices
  - Setup: Train the same detector with different backbones (DeiT‑Tiny/Small, MobileViT, YOLOv8n as non‑ViT baseline) and an efficient DETR variant for aerial views. Deploy on Jetson Nano/Xavier.
  - Metrics: mAP for detection, MAE/RMSE for counts, end‑to‑end latency (ms), power (W), and energy per image (J). Plot accuracy vs energy.
  - Falsifiable outcome: At ≤10 W, a tiny/distilled ViT matches or beats a non‑ViT baseline on MAE with lower energy per image. If not, claim of “low‑cost ViT advantage” is not supported. Relevant background on detection transformers for drone views: SF‑DETR [3]; density-based counting tradeoffs in aerial surveys: [4].
- E2. Annotation-efficiency study
  - Setup: Compare (a) standard full‑box training, (b) point‑only supervision with density head, (c) active learning that selects 10–20% most informative images for full annotation.
  - Metrics: Labeling time (minutes), MAE/mAP, and sample efficiency (performance vs labeled fraction).
  - Falsifiable outcome: Point‑supervised or active‑learning ViT achieves within 5–10% of full‑label accuracy with ≥50% less labeling time; otherwise, annotation‑efficient training offers limited benefit. Motivation: minimizing annotation effort in aerial wildlife surveys [2].
- E3. Detection vs density for colony counts
  - Setup: On a colony dataset (e.g., penguins/seals), train (a) DETR‑style ViT detector, (b) ViT backbone with density map head.
  - Metrics: MAE, MAPE under high‑density scenes; occlusion robustness (performance vs manually rated crowding).
  - Falsifiable outcome: Density‑ViT reduces MAE/MAPE in high‑crowding scenes versus detection; if not, prefer detection. Background on density map estimation for aerial animal counting: [4].
- E4. Calibration and shift robustness (optional)
  - Setup: Evaluate predictive intervals with conformal prediction across sites/seasons; test on a held‑out reserve.
  - Metrics: Count coverage at nominal 90%, interval width, and out‑of‑distribution degradation.
  - Falsifiable outcome: Calibrated intervals maintain nominal coverage under site shift; otherwise, add domain adaptation.

Data/baselines to include
- Use existing aerial wildlife datasets or curate small transects; include at least one high‑density colony and one sparsely distributed species.
- Baselines: a strong CNN detector (e.g., YOLOv8n) and a density CNN; compare to efficient DETR/ViT variants for fairness.
- Report both detection metrics (mAP) and survey‑relevant count metrics (MAE/MAPE) and operational costs (J/image, $/device, annotation minutes) to make the “low‑cost” claim concrete. DETR-style methods tailored for drone views and density‑based counting papers provide useful templates [3][4].

Bottom line
- The area is active but not saturated. A well‑designed study that optimizes for edge cost and annotation efficiency—and that reports calibrated counts—would be a meaningful, novel contribution, especially if you publish rate–accuracy–cost curves and show cross‑site generalization [2][3][4][5].

Citations
[1] Ensembles of data‑efficient vision transformers as a new paradigm for image classification — https://www.nature.com/articles/s41598-022-21910-0  
[2] How to minimize the annotation effort in aerial wildlife surveys — https://www.sciencedirect.com/science/article/pii/S1574954125003966  
[3] SF‑DETR: A Scale‑Frequency Detection Transformer for Drone‑View Object Detection — https://www.mdpi.com/1424-8220/25/7/2190  
[4] Counting animals in aerial images with a density map estimation method — https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.9903  
[5] Evaluating Deep Learning Models for African Wildlife Image Classification — https://arxiv.org/html/2507.21364v1