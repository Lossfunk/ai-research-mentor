core_metrics:
  research_quality:
    weight: 1.2
    description: "Depth of research insights, methodology understanding, novelty identification"
    anchors:
      "2.0": "Expert-level analysis with novel insights and sophisticated methodology critique"
      "1.5": "Solid analysis with good methodology suggestions and some novelty"
      "1.0": "Standard analysis with basic methodology understanding"
      "0.5": "Superficial analysis with methodological gaps"
      "0.0": "Incorrect analysis or harmful advice"
    scale_type: "scaled"
    
  actionability:
    weight: 1.0
    description: "Clarity and feasibility of next steps provided to user"
    anchors:
      "2.0": "Specific, executable steps with resources, timelines, and milestones"
      "1.5": "Clear direction with implementation guidance"
      "1.0": "General direction requiring user to fill gaps"
      "0.5": "Vague advice without concrete steps"
      "0.0": "No usable guidance provided"
    scale_type: "scaled"
    
  persona_fit:
    weight: 1.0
    description: "Appropriateness of tone, complexity, and constraint handling for target user"
    anchors:
      "2.0": "Perfectly tailored to persona's knowledge, constraints, and communication style"
      "1.5": "Appropriate content with minor persona misalignments"
      "1.0": "Some consideration of persona needs but inconsistent"
      "0.5": "Largely ignores persona context"
      "0.0": "Inappropriate for target persona (too complex/simple, wrong tone)"
    scale_type: "scaled"
    
  evidence_quality:
    weight: 0.8
    description: "Quality, relevance, and validity of supporting citations/sources"
    anchors:
      "2.0": "Excellent real citations directly supporting all key claims"
      "1.5": "Good real citations supporting most claims"
      "1.0": "Mixed quality - some real citations, some gaps/relevance issues"
      "0.5": "Few or tangentially relevant citations"
      "0.0": "No citations or clearly fabricated sources"
    scale_type: "scaled"
    
  question_asking:
    weight: 0.8
    description: "Probing for user uncertainties, scope, and hidden constraints"
    anchors:
      "2.0": "Excellent clarifying questions that reveal critical uncertainties"
      "1.5": "Good relevant questions with some missed opportunities"
      "1.0": "Basic clarifying questions with limited scope"
      "0.5": "Few or irrelevant questions"
      "0.0": "No clarifying inquiries despite clear ambiguities"
    scale_type: "scaled"

binary_checks:
  citation_validity:
    weight: 1.0
    description: "All cited sources are real academic records"
    criteria: "1 = all citable sources are real (arXiv, DOI, journals); 0 = any fabricated sources"
    
  tool_routing:
    weight: 1.0  
    description: "Expected tools invoked appropriately"
    criteria: "1 = all expected tools used; 0 = critical tools missing or misused"
    
  stage_appropriateness:
    weight: 0.8
    description: "Response complexity matches research stage"
    criteria: "1 = appropriate for stage A/B/C; 0 = misaligned complexity"
    
  constraint_handling:
    weight: 0.8
    description: "User constraints (time, resources, expertise) addressed"
    criteria: "1 = constraints acknowledged and planned around; 0 = ignored"

aggregation:
  overall_score: "weighted_average" # (sum(score * weight)) / (sum of all weights)
  pass_threshold: 1.5  # Minimum overall score for "good" responses
  critical_requirements:
    - citation_validity: 1  # Must use real sources
    - research_quality: 0.8  # Minimum research insight quality
