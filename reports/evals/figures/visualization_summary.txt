Summary of Latest Evaluation Visualizations (Generated 2025-11-03)

1. Expert Pairwise Comparisons (expert_pairwise_stacked.png/pdf/svg):
   • Mentor vs GPT-5 Baseline – Mentor wins 54.4% (49 of 90 comparisons) with ties at 6.7%; stage-level bars reveal strongest margins at Stage C (67%) and weakest at Stage B (40%).
   • Mentor vs Claude Sonnet 4.5 Baseline – Mentor wins 71.9% (64 of 89 comparisons) with minimal ties (3.4%); dominance is pronounced after Stage C where Mentor exceeds 79% per stage.

2. Expert Absolute Pro Derived Comparisons (expert_absolute_wins.png/pdf/svg):
   • Derived from absolute-pro judge scores, Mentor beats GPT-5 on 62.7% of prompts (47 of 75) across Stages A–E; Stage B shows the widest gap (87% mentor share).
   • Mentor outperforms Claude Sonnet 4.5 on 79.7% of prompts (59 of 74) with zero ties beyond Stage A; Stage D records a clean sweep (100%).

3. Student Judge Outcome Trends (student_judge_trends.png/pdf/svg and student_judge_trends_absolute.*):
   • Average student outcome scores decline from Stage A to C for all systems; Mentor remains consistently higher than baselines until Stage D where GPT-5 briefly narrows the gap.
   • Claude Sonnet 4.5 starts weakest but rebounds sharply at Stage E, while GPT-5 stabilizes around 1.4. Stage F student data is unavailable for all systems (explicitly noted in plots).

Key Takeaway: Mentor maintains a decisive lead over both baselines in expert evaluations—especially against Claude—and retains a student-perceived advantage through most stages, despite late-stage convergence with GPT-5 and partial data gaps.
