Below is a concrete, IRB-ready user study plan to test whether the hierarchical representations proposed in the attached work align with human-perceived structure in long documents. The plan adapts the paper’s idea of hierarchical token selection/clustering to text and adds human-grounded validation, since the paper’s current evaluation emphasizes rollout cost/error and RL performance rather than human structure alignment [heirarchical-transformer.pdf:3]. The paper’s method includes hierarchical token clustering (e.g., via hierarchical VQ-VAE) and hierarchical masking, which we leverage to induce document segmentations at multiple levels [heirarchical-transformer.pdf:2–3].

Study goal and hypotheses
- Goal: Determine whether the model’s learned hierarchical structure (multi-level segment boundaries and parent–child grouping) matches how humans structure long documents (e.g., section/subsection/paragraph-level outlines).
- H1 (Boundary alignment): Model boundary sets at each hierarchy level align with human boundary sets significantly better than strong baselines (TextTiling; paragraph or fixed-length chunking) measured by Pk/WindowDiff and boundary F1 [2][5].
- H2 (Tree alignment): The model’s hierarchical grouping (tree) is more similar to human-drawn outline trees than baselines, measured by tree-edit or Robinson–Foulds distances and clustering agreement (ARI/NMI).
- H3 (Utility): For navigation and information-finding tasks, users perform better (faster, higher success) using model-derived hierarchies than baseline structures.

Key link to attached paper
- The model provides multi-level token clustering and hierarchical masking signals; we treat text spans as tokens and apply the same hierarchical clustering/masking pipeline to produce document-level structures [heirarchical-transformer.pdf:2–3]. The paper does not evaluate human alignment, so this study fills that gap [heirarchical-transformer.pdf:3].

Materials and model outputs
- Documents: 60 long documents (20 scientific survey/introduction sections, 20 Wikipedia Featured Articles, 20 long-form reports). Each document >2,500 words, with existing section/subsection labels retained for evaluation and expert guidance.
- Model structure extraction:
  - Induce hierarchical token clusters over the document using the paper’s hierarchical VQ-VAE/token clustering procedure and masking signals (applied to text tokens or sentence embeddings), producing K levels (e.g., Level-1: coarse sections; Level-2: subsections; Level-3: paragraph-like units) [heirarchical-transformer.pdf:2–3].
  - Map clusters to contiguous text spans by maximizing coverage (e.g., dynamic programming or greedy alignment).
- Baselines: TextTiling, fixed-length chunking (e.g., 512/1,024 tokens), paragraph boundaries; optional discourse parser if available. TextTiling and segmentation metrics reference standard literature [2][5].

Participants
- Two cohorts:
  1) General proficient readers (n=60; fluent in English; crowd platform or lab; within-subject across methods) for boundary and utility tasks.
  2) Expert annotators (n=12; graduate-level NLP/linguistics/technical writing) for hierarchical outline/tree annotation and quality control.
- Rationale and power:
  - H1/H3: Within-subject comparisons with moderate effect size (d≈0.4–0.5) typically require about 34–52 participants for 80% power (two-sided, α=0.05). We target n=60 to account for dropouts and clustered data (docs nested in participants).
  - H2: Tree annotation is intensive; 12 experts, each annotating ~10 documents, yields sufficient reliability to detect medium effect differences in tree distances across methods with document-level bootstrapping.

Instruments
- Boundary annotation UI: Sentence-level timeline with the ability to add boundaries at 3 levels (coarse/medium/fine). Short training and 3 calibration items.
- Tree/outlining UI (expert): Drag-and-drop tree builder with constraints that nodes cover contiguous spans; allow 3-level outlines. Inspired by hierarchical annotation tools that support multi-stage labeling [P1].
- Utility task UI: A/B/C interface to navigate with different structures (model vs TextTiling vs paragraph); time-limited information-finding and question answering.
- Question sets: 4–6 factual/location questions per document (e.g., “Find where the author defines X”).
- Subjective measures: Per-structure usefulness, coherence, and satisfaction (7-point Likert); cognitive load (NASA-TLX short form).
- Quality controls: Gold-check documents with known sectioning; attention checks; minimum reading time thresholds; auto-flagging inconsistent boundary density.

Procedure
- Training and calibration: Short tutorial; boundary calibration on a short article with immediate feedback.
- Main tasks (within-subject; counterbalanced order of methods):
  1) Boundary task (n=60): For 6 documents per participant, mark boundaries at 3 levels. Participants receive definitions and examples (e.g., what counts as “coarse”).
  2) Utility task (n=60): For another 6 documents, answer navigation/locate questions using one of the structures (model or baseline), with counterbalancing and randomized ordering; record time and success.
  3) Expert tree annotation (n=12): Annotate 10 documents each with 3-level hierarchical outlines.

Metrics and analysis plan
- Pre-registration: Define primary/secondary outcomes, sample sizes, exclusion criteria, and analysis scripts before data collection.
- Inter-annotator agreement: Krippendorff’s α or Fleiss’ κ on boundary presence per position and level; tree-level agreement via average pairwise tree edit distance among experts.
- H1 (Boundary alignment):
  - Metrics: Boundary F1 (exact or ±1-sentence tolerance), Pk and WindowDiff against human consensus (majority, or soft boundary probability) [2].
  - Analysis: Document-level differences between model vs baselines using paired tests (Wilcoxon) and linear mixed-effects models with random intercepts for participant and document; report mean difference with 95% bootstrap CIs over documents; Holm–Bonferroni correction across levels.
- H2 (Tree alignment):
  - Metrics: Tree edit distance; Robinson–Foulds distance; Lowest Common Ancestor (LCA) distance correlation; ARI/NMI between clusterings from horizontal “cuts” at each depth.
  - Analysis: For each document, compute distances between human-consensus tree and each method’s tree; test paired differences; permutation tests by randomly reassigning node labels/spans to assess significance. Report effect sizes and CIs.
- H3 (Utility):
  - Metrics: Task success (binary), time-to-locate (log-transformed), number of navigational actions; subjective usefulness and coherence ratings.
  - Analysis: Mixed-effects logistic regression for success; linear mixed-effects for log-time and ratings; fixed effects: method, document length, familiarity; random intercepts for participant/document. Report odds ratios/time ratios with CIs.
- Robustness/ablations:
  - Evaluate across domains (wiki/science/reports) as fixed effects.
  - Sensitivity to number of hierarchy levels (2 vs 3 vs 4).
  - Ablate masking signals from the model (e.g., without causal or uncertainty guidance) to test their contribution to alignment [heirarchical-transformer.pdf:3].
- Multiple comparisons: Control FDR at 5% for secondary outcomes.

Three concrete, falsifiable experiments
1) Multi-level boundary alignment
   - Hypothesis: Model boundary sets at each level have lower Pk/WindowDiff and higher F1 than TextTiling and paragraph baselines (α=0.05).
   - Variables: Method (model, TextTiling, paragraph), level (coarse/medium/fine), document.
   - Metrics: Boundary F1 (±1-sentence tolerance), Pk, WindowDiff [2][5].
   - Expected outcome: Model outperforms baselines at coarse and medium levels; fine-level differences may be smaller.
   - Sample size: n=60 participants; 6 docs/participant; analysis aggregated at document level with mixed-effects models.

2) Tree-structure similarity
   - Hypothesis: Model hierarchy trees are closer to expert trees than baselines by ≥10% reduction in tree edit distance on average.
   - Variables: Method, document.
   - Metrics: Tree edit distance; Robinson–Foulds; ARI/NMI at fixed-depth cuts.
   - Expected outcome: Model’s tree shows significantly smaller distances to experts’ consensus than baselines.
   - Sample size: n=12 experts; 10 docs/expert; consensus from majority or MCMC aggregation over expert trees.

3) Navigation utility A/B/C test
   - Hypothesis: Users locate answers faster and with higher success using the model’s hierarchy vs baselines.
   - Variables: Method, question type (definition/location/cross-ref).
   - Metrics: Success rate; time-to-answer (log); number of navigation actions; subjective usefulness.
   - Expected outcome: Higher success and lower time for the model; subjective usefulness higher by ≥0.5 Likert points.
   - Sample size: n=60; 6 docs/participant; 4–6 questions/doc; within-subject with counterbalancing.

Mapping model representations to document structure
- Use the paper’s hierarchical token clustering or hierarchical VQ-VAE to produce multi-level clusters over text tokens/sentences [heirarchical-transformer.pdf:2], then align clusters to contiguous text spans and define boundaries at each level. The model’s masking/selection signals define which spans are salient for higher-level nodes [heirarchical-transformer.pdf:2–3]. This directly operationalizes the model’s “sparse hierarchical imagination” for text; human alignment is then tested through the experiments above.

Quality and ethics
- IRB review, informed consent, anonymized data, fair compensation (~$15–$20/hour), debriefing.
- Pilots (n≈6) to refine instructions and UI.
- Release evaluation code and (licensed) annotations for reproducibility.

Notes and anchors
- Hierarchical multi-stage annotation is feasible with modular tools (e.g., HUMAN annotator framework) and motivates the expert-tree instrument [P1].
- Pk and WindowDiff are standard metrics for segmentation alignment; use both to avoid metric-specific artifacts [2]. TextTiling is a strong classical baseline for topic-based segmentation [5].

Citations
- [heirarchical-transformer.pdf:2] The paper uses a hierarchical VQ-VAE or token clustering procedure and hierarchical masking to sparsify token sequences in a Transformer world model — attached PDF.
- [heirarchical-transformer.pdf:3] Evaluation focuses on rollout compute cost, rollout error, RL performance; ablations include hierarchical masking, causal/uncertainty guidance — attached PDF.
- [P1] HUMAN: Hierarchical Universal Modular ANnotator — http://arxiv.org/abs/2010.01080v1
- [2] Pevzner and Hearst. A Critique and Improvement of an Evaluation Metric for Text Segmentation (WindowDiff) — https://people.ischool.berkeley.edu/~hearst/papers/pevzner-01.pdf
- [5] Choi. Advances in domain independent linear text segmentation (TextTiling baseline discussion and segmentation evaluation) — http://www.cs.columbia.edu/~julia/papers/choi00.pdf

Sources
- Sparse Hierarchical Imagination for Efficient Transformer World Models (attached) — hierarchical token clustering/masking and evaluation scope [heirarchical-transformer.pdf:2–3].
- [P1] HUMAN: Hierarchical Universal Modular ANnotator — http://arxiv.org/abs/2010.01080v1
- Pevzner and Hearst (2002). A Critique and Improvement of an Evaluation Metric for Text Segmentation — https://people.ischool.berkeley.edu/~hearst/papers/pevzner-01.pdf
- Choi (2000). Advances in domain independent linear text segmentation — http://www.cs.columbia.edu/~julia/papers/choi00.pdf

Two literature anchors
- Pevzner and Hearst (2002). A Critique and Improvement of an Evaluation Metric for Text Segmentation — https://people.ischool.berkeley.edu/~hearst/papers/pevzner-01.pdf
- Choi (2000). Advances in domain independent linear text segmentation — http://www.cs.columbia.edu/~julia/papers/choi00.pdf

Takeaways
- The plan adapts the paper’s hierarchical clustering/masking to text [heirarchical-transformer.pdf:2–3] and evaluates boundary and tree alignment plus utility.
- It specifies sample sizes, instruments, and a rigorous analysis plan using established segmentation metrics and mixed-effects modeling [2][5][P1].
- Results will quantify whether the model’s hierarchy aligns with human structure and whether that alignment improves actual user navigation and comprehension.