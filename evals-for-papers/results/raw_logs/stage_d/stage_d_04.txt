Summary of FC3 (Task Verification) in MST
- The MST taxonomy isolates “Task (Quality Control) Verification” as a distinct failure category (FC3) with three submodes: FM‑3.1 Premature Termination, FM‑3.2 No or Incomplete Verification, and FM‑3.3 Incorrect Verification [Why Do Multi-Agent LLM Systems Fail_ - 2503.13657v2.pdf:5]. These reflect, respectively: ending the process before any verification occurs; conducting partial or missing checks; and conducting checks but drawing the wrong conclusion. An example in the paper illustrates missing corrective feedback (e.g., not telling the agent what to fix after an “Invalid credentials” message), which aligns with verification/feedback gaps [Why Do Multi-Agent LLM Systems Fail_ - 2503.13657v2.pdf:9].

Recommended benchmark and system
- Benchmark: SWE-bench Lite (or SWE-bench if resources allow) for software bug-fixing tasks with ground-truth unit tests. It provides an automated oracle, makes verification explicit (tests/logs), and is a good fit for multi-agent development pipelines where a verifier can run tests, linting, and static checks.
- System: ChatDev (or MetaGPT). ChatDev has clear roles (e.g., Developer/Reviewer/Tester) so the “verifier” can be mapped to Reviewer/Tester; MetaGPT similarly has QA/review hooks. Both are easy to toggle to ablate an explicit verifier with minimal changes. Recent work emphasizes explicit verification in multi-agent systems and frameworks that make verification a first-class component, which you can leverage or emulate in these systems [P1][P2].

Minimal ablations to isolate the verifier
Implement the following toggles as minimally invasive diffs. Keep the same generator model, temperature, tool budget, and planner across conditions; only change the verifier’s capabilities/authority.

- A0 (Baseline, No-Verifier): Remove the explicit verifier agent and any “review/test” step. In ChatDev, skip the Reviewer/Tester roles or gate them behind a flag so they don’t run or emit vetoes.
- A1 (Advisory-Only Verifier): Keep the verifier but remove veto/repair authority. The verifier can comment but cannot trigger a rework loop; downstream agents ignore “fail” signals and proceed to finalization.
- A2 (Blindfolded Verifier): Keep the verifier but remove tool access to oracles (unit tests, execution, linters). The verifier must decide based on static artifacts only (e.g., code diff, reasoning). This cleanly stresses FM‑3.2 and FM‑3.3.
- A3 (Budget-Capped Verifier): Keep authority and tools, but cap verifier compute (# tool calls, # turns). This probes whether “no/incomplete verification” arises from budget constraints rather than capability.

In ChatDev specifically:
- Comment out or flag the Tester/Reviewer invocation in the pipeline (e.g., TESTER_ENABLED=False).
- For A1, strip the branch that triggers a “revise-and-rerun” loop when tests fail.
- For A2, intercept the verifier’s tool calls (exec, test runner, linter) with no-ops or return masked outputs; keep the same prompts and role.
- For A3, set a small per-verifier tool-call budget and max_turns.

Failure modes to track and how to operationalize them
Align your logging/labels to MST’s FC3 to enable direct mapping.

- FM‑3.1 Premature Termination: The pipeline ends without a verifier step or ends before any checks complete. Detection: no verifier turn/logs; or verifier invited but exits before any check; or conversation ends before planned verification. Metric: premature-termination rate (%) [file:5].
- FM‑3.2 No or Incomplete Verification: The verifier runs fewer than K planned checks (e.g., runs 0 tests or a strict subset), or coverage < threshold (e.g., <90% of available failing tests addressed). Metric: verification coverage = tests_run / tests_available; check-count per task; coverage shortfall rate (%) [file:5].
- FM‑3.3 Incorrect Verification: The verifier’s final judgment disagrees with the ground-truth oracle (e.g., it accepts solutions that fail tests or rejects solutions that pass). Metrics: false-accept rate (FAR; incorrect but accepted), false-reject rate (FRR; correct but rejected), and overall verifier accuracy [file:5].

Primary outcome metrics
- Task success: fraction of tasks fully passing the benchmark oracle (unit-test pass rate).
- Verifier FAR/FRR/Accuracy: computed against the oracle on each task/version.
- Verification coverage: tests run / available; number and diversity of checks (unit tests, static analysis, runtime probes).
- Rework productivity: number of verifier-triggered iterations; success-after-rework rate.
- Cost/time overhead: additional tokens/tool calls/time attributable to the verifier.
- Premature termination rate (FM‑3.1).
- Calibration: correlation between verifier confidence (if logged) and correctness (ECE/Brier score).

Secondary diagnostics
- Root-cause labeling: proportion of failures attributed to FM‑3.2 vs FM‑3.3 (manual spot-checking of logs).
- Tool-use quality: fraction of verifier tool calls that produce actionable signals (e.g., failing test logs referenced correctly).
- Iteration quality: acceptance after N cycles and diminishing returns.

Three concrete, falsifiable experiments
- E1 (Verifier On vs Off, paired): Hypothesis: An explicit verifier reduces FAR and increases overall task success at the cost of time/cost. Design: Run ChatDev on N SWE-bench Lite tasks with fixed seed, temperature, and tool budget under A0 (No-Verifier) vs baseline with full verifier. Metrics: task success, FAR/FRR, tokens/tool calls/time. Expected: ↓FAR, ↑success, ↑overhead with verifier [file:5].
- E2 (Blindfolded Verifier): Hypothesis: Removing tool access (A2) increases FM‑3.2 and FM‑3.3 (more incomplete and incorrect verification) relative to full verifier. Design: Baseline vs A2 on the same tasks. Metrics: coverage, FAR/FRR, success, premature termination. Expected: ↓coverage, ↑FAR/FRR, ↓success with A2 [file:5].
- E3 (Authority Ablation): Hypothesis: Removing veto authority (A1) raises FAR (incorrect acceptances) but reduces cost/time. Design: Baseline vs A1. Metrics: FAR/FRR, rework rate, success, cost/time. Expected: ↑FAR, ↓rework, mixed effect on success depending on generator quality [file:5].

Experimental controls and analysis
- Use identical prompts, planner, generator model, seeds/temperatures, and per-agent budgets; vary only verifier toggles.
- Paired design on the same task set; use McNemar’s test on per-task correctness (pass/fail) and bootstrap CIs for FAR/FRR differences.
- Sample size: at least 100 tasks on SWE-bench Lite (or a power analysis using pilot effect sizes).
- Log granular verifier events (tests invoked, outputs parsed, judgments and confidences) to enable precise FM labeling.

Why this setup
- SWE-bench’s executable oracles make FC3 verifiable: verification is observable through unit tests, and incorrect/no verification is measurable (coverage, FAR/FRR). Multi-agent frameworks like ChatDev/MetaGPT make it straightforward to create an explicit “verifier” role you can ablate with minimal code changes. Recent research underscores the value of treating verification as a first-class process in multi-agent systems and provides design patterns you can mirror (e.g., verification-aware planning and integrated verification agents) [P1][P2].

Key takeaways
- Use SWE-bench Lite + ChatDev (or MetaGPT) with toggles for verifier presence, authority, tools, and budget.
- Map outcomes to MST’s FC3: FM‑3.1, FM‑3.2, FM‑3.3 [file:5].
- Track task success, FAR/FRR, coverage, rework, cost/time, and premature termination.
- Run paired ablations (On vs Off; Blindfolded; No-Veto) and analyze FAR/FRR and success differences.

Citations
- [file:5] Why Do Multi-Agent LLM Systems Fail? — FC3 “Task Verification” with FM‑3.1 Premature Termination, FM‑3.2 No or Incomplete Verification, FM‑3.3 Incorrect Verification — Why Do Multi-Agent LLM Systems Fail_ - 2503.13657v2.pdf:5
- [file:9] Why Do Multi-Agent LLM Systems Fail? — Example showing missing feedback on a credential failure, illustrating verification/feedback gaps — Why Do Multi-Agent LLM Systems Fail_ - 2503.13657v2.pdf:9
- [P1] Verification-Aware Planning for Multi-Agent Systems — http://arxiv.org/abs/2510.17109v1
- [P2] MAG-V: A Multi-Agent Framework for Synthetic Data Generation and Verification — http://arxiv.org/abs/2412.04494v2

Sources
- Why Do Multi-Agent LLM Systems Fail? (MST/MAST taxonomy) [file:5,9]
- [P1] Verification-Aware Planning for Multi-Agent Systems
- [P2] MAG-V: A Multi-Agent Framework for Synthetic Data Generation and Verification