Based on the attached paper, I'll design a comprehensive framework to test how privacy/governance constraints affect the Sparse Hierarchical Imagination (SHI) Transformer's verification-like failure rates.

## Privacy/Governance Constraint Framework

### 1. Constraint Definition

**Primary Constraint: Offline Inference**

The original SHI performs online world model rollouts during deployment [heirarchical-transformer.pdf:2], which may:
- Leak information through model queries
- Require continuous data access
- Enable model extraction attacks
- Violate data locality requirements

**Offline Inference Constraint:**
```python
class OfflineInferenceConstraint:
    """
    Enforce offline inference: No environment interaction during deployment.
    
    Implications:
    1. No online rollout refinement
    2. No adaptive masking based on new observations
    3. Fixed imagination horizon (no dynamic adjustment)
    4. No SPARTAN graph updates during deployment
    """
    def __init__(self, max_rollout_horizon=15):
        self.max_rollout_horizon = max_rollout_horizon
        self.allow_environment_queries = False
        self.allow_model_updates = False
        self.allow_adaptive_masking = False
        
    def validate_deployment(self, model_deployment):
        """
        Verify deployment satisfies offline constraint.
        """
        violations = []
        
        # Check 1: No environment queries
        if model_deployment.queries_environment():
            violations.append("Environment queries detected")
        
        # Check 2: No model updates
        if model_deployment.updates_model():
            violations.append("Model updates detected")
        
        # Check 3: Fixed rollout horizon
        if model_deployment.rollout_horizon > self.max_rollout_horizon:
            violations.append(f"Rollout horizon exceeds limit: {model_deployment.rollout_horizon}")
        
        # Check 4: No adaptive masking
        if model_deployment.uses_adaptive_masking():
            violations.append("Adaptive masking detected")
        
        return {
            'compliant': len(violations) == 0,
            'violations': violations
        }
```

**Secondary Constraints:**

```python
class PrivacyGovernanceConstraints:
    """
    Additional privacy/governance constraints.
    """
    def __init__(self):
        self.constraints = {
            'differential_privacy': DifferentialPrivacyConstraint(),
            'data_minimization': DataMinimizationConstraint(),
            'model_compression': ModelCompressionConstraint(),
            'federated_learning': FederatedLearningConstraint(),
        }
        
class DifferentialPrivacyConstraint:
    """
    Enforce differential privacy during training.
    
    Adds noise to gradients to prevent memorization.
    """
    def __init__(self, epsilon=1.0, delta=1e-5):
        self.epsilon = epsilon  # Privacy budget
        self.delta = delta      # Failure probability
        
    def apply_to_gradients(self, gradients, sensitivity, batch_size):
        """
        Add calibrated noise to gradients.
        """
        # Compute noise scale (Gaussian mechanism)
        noise_scale = sensitivity * np.sqrt(2 * np.log(1.25 / self.delta)) / self.epsilon
        
        # Add noise
        noisy_gradients = gradients + torch.randn_like(gradients) * noise_scale
        
        return noisy_gradients

class DataMinimizationConstraint:
    """
    Limit data retention and access.
    
    Only store minimal information needed for inference.
    """
    def __init__(self, max_context_length=100):
        self.max_context_length = max_context_length
        
    def filter_data(self, trajectory):
        """
        Keep only recent context.
        """
        return trajectory[-self.max_context_length:]

class ModelCompressionConstraint:
    """
    Compress model to reduce attack surface.
    
    Smaller models are harder to extract.
    """
    def __init__(self, compression_ratio=0.5):
        self.compression_ratio = compression_ratio
        
    def compress_model(self, model):
        """
        Apply pruning and quantization.
        """
        # Pruning
        pruned_model = self._prune_weights(model, self.compression_ratio)
        
        # Quantization
        quantized_model = torch.quantization.quantize_dynamic(
            pruned_model,
            {torch.nn.Linear},
            dtype=torch.qint8
        )
        
        return quantized_model

class FederatedLearningConstraint:
    """
    Train without centralizing data.
    
    Each client trains locally, only shares model updates.
    """
    def __init__(self, num_clients=10):
        self.num_clients = num_clients
        
    def aggregate_updates(self, client_updates):
        """
        Federated averaging.
        """
        avg_update = {}
        for key in client_updates[0].keys():
            avg_update[key] = torch.mean(
                torch.stack([update[key] for update in client_updates]),
                dim=0
            )
        return avg_update
```

### 2. Verification-Like Failure Modes

**Definition:** Failures where model predictions are confidently wrong, similar to verification failures in formal methods.

```python
class VerificationFailureDetector:
    """
    Detect verification-like failures in world model predictions.
    
    Failure types:
    1. High-confidence incorrect predictions
    2. Catastrophic rollout divergence
    3. Safety constraint violations
    4. Distributional shift failures
    """
    def __init__(self):
        self.failure_types = {
            'high_confidence_error': self._detect_high_confidence_error,
            'rollout_divergence': self._detect_rollout_divergence,
            'safety_violation': self._detect_safety_violation,
            'distribution_shift': self._detect_distribution_shift,
        }
        
    def detect_failures(self, predictions, ground_truth, metadata):
        """
        Detect all failure types.
        """
        failures = {}
        
        for failure_type, detector_fn in self.failure_types.items():
            failures[failure_type] = detector_fn(predictions, ground_truth, metadata)
        
        return failures
    
    def _detect_high_confidence_error(self, predictions, ground_truth, metadata):
        """
        Detect high-confidence incorrect predictions.
        
        Failure criterion: High predicted confidence + large prediction error
        """
        # Extract confidence (e.g., from uncertainty estimates)
        confidence = 1.0 - metadata.get('uncertainty', torch.zeros_like(predictions))
        
        # Compute prediction error
        error = torch.abs(predictions - ground_truth)
        
        # Detect failures: High confidence (>0.8) AND high error (>threshold)
        high_confidence_mask = confidence > 0.8
        high_error_mask = error > self._compute_error_threshold(ground_truth)
        
        failure_mask = high_confidence_mask & high_error_mask
        
        return {
            'failure_rate': failure_mask.float().mean().item(),
            'num_failures': failure_mask.sum().item(),
            'failure_indices': failure_mask.nonzero(as_tuple=True)[0].tolist(),
            'avg_error_on_failures': error[failure_mask].mean().item() if failure_mask.any() else 0.0,
        }
    
    def _detect_rollout_divergence(self, predictions, ground_truth, metadata):
        """
        Detect catastrophic rollout divergence.
        
        Failure criterion: Cumulative error exceeds threshold
        """
        # Assume predictions are multi-step rollouts [B, T, ...]
        if len(predictions.shape) < 2:
            return {'failure_rate': 0.0, 'num_failures': 0}
        
        # Compute cumulative error over rollout
        cumulative_error = torch.cumsum(
            torch.abs(predictions - ground_truth).mean(dim=tuple(range(2, len(predictions.shape)))),
            dim=1
        )  # [B, T]
        
        # Detect divergence: Cumulative error exceeds threshold
        divergence_threshold = 10.0  # Configurable
        divergence_mask = cumulative_error[:, -1] > divergence_threshold
        
        return {
            'failure_rate': divergence_mask.float().mean().item(),
            'num_failures': divergence_mask.sum().item(),
            'avg_cumulative_error': cumulative_error[:, -1].mean().item(),
            'max_cumulative_error': cumulative_error[:, -1].max().item(),
        }
    
    def _detect_safety_violation(self, predictions, ground_truth, metadata):
        """
        Detect safety constraint violations.
        
        Failure criterion: Predicted trajectory violates safety constraints
        """
        # Define safety constraints (domain-specific)
        # Example for Atari: Agent should not die
        
        safety_constraints = metadata.get('safety_constraints', None)
        if safety_constraints is None:
            return {'failure_rate': 0.0, 'num_failures': 0}
        
        # Check violations
        violations = safety_constraints.check_violations(predictions)
        
        return {
            'failure_rate': violations.float().mean().item(),
            'num_failures': violations.sum().item(),
            'violation_types': safety_constraints.get_violation_types(violations),
        }
    
    def _detect_distribution_shift(self, predictions, ground_truth, metadata):
        """
        Detect distributional shift failures.
        
        Failure criterion: Predictions are out-of-distribution
        """
        # Compute distribution statistics
        train_stats = metadata.get('train_statistics', None)
        if train_stats is None:
            return {'failure_rate': 0.0, 'num_failures': 0}
        
        # Detect OOD using Mahalanobis distance
        pred_flat = predictions.reshape(predictions.shape[0], -1)
        
        mahalanobis_dist = self._compute_mahalanobis_distance(
            pred_flat,
            train_stats['mean'],
            train_stats['cov']
        )
        
        # Threshold based on chi-squared distribution
        from scipy.stats import chi2
        threshold = chi2.ppf(0.95, df=pred_flat.shape[1])
        
        ood_mask = mahalanobis_dist > threshold
        
        return {
            'failure_rate': ood_mask.float().mean().item(),
            'num_failures': ood_mask.sum().item(),
            'avg_mahalanobis_dist': mahalanobis_dist.mean().item(),
        }
    
    def _compute_error_threshold(self, ground_truth):
        """
        Compute adaptive error threshold based on data scale.
        """
        return 0.1 * ground_truth.std().item()
    
    def _compute_mahalanobis_distance(self, x, mean, cov):
        """
        Compute Mahalanobis distance for OOD detection.
        """
        diff = x - mean
        inv_cov = torch.linalg.inv(cov + 1e-6 * torch.eye(cov.shape[0]))
        
        mahalanobis = torch.sqrt(
            torch.sum(diff @ inv_cov * diff, dim=1)
        )
        
        return mahalanobis
```

### 3. Baseline Models

```python
class BaselineModels:
    """
    Baseline models for comparison.
    """
    def __init__(self):
        self.baselines = {
            'shi_unconstrained': self._create_shi_unconstrained,
            'shi_offline': self._create_shi_offline,
            'shi_dp': self._create_shi_with_dp,
            'shi_compressed': self._create_shi_compressed,
            'iris_baseline': self._create_iris_baseline,
            'random_baseline': self._create_random_baseline,
        }
    
    def _create_shi_unconstrained(self):
        """
        Original SHI without constraints (upper bound).
        """
        return SHI(
            allow_online_rollout=True,
            allow_adaptive_masking=True,
            allow_model_updates=True
        )
    
    def _create_shi_offline(self):
        """
        SHI with offline inference constraint.
        
        Key changes:
        - No online rollout refinement
        - Fixed masking strategy
        - No model updates during deployment
        """
        return SHI(
            allow_online_rollout=False,
            allow_adaptive_masking=False,
            allow_model_updates=False,
            max_rollout_horizon=15
        )
    
    def _create_shi_with_dp(self):
        """
        SHI with differential privacy.
        
        Key changes:
        - DP-SGD during training
        - Gradient clipping
        - Noise injection
        """
        return SHIDP(
            epsilon=1.0,
            delta=1e-5,
            max_grad_norm=1.0
        )
    
    def _create_shi_compressed(self):
        """
        SHI with model compression.
        
        Key changes:
        - Pruned weights (50% sparsity)
        - Quantized to INT8
        - Reduced codebook size
        """
        return SHICompressed(
            pruning_ratio=0.5,
            quantization_bits=8,
            codebook_size=256  # Reduced from 512
        )
    
    def _create_iris_baseline(self):
        """
        IRIS baseline (no hierarchy, no masking).
        
        Reference from paper [heirarchical-transformer.pdf:3]
        """
        return IRIS(
            num_layers=6,
            d_model=512,
            num_heads=8
        )
    
    def _create_random_baseline(self):
        """
        Random predictions (lower bound).
        """
        return RandomPredictor()
```

### 4. Datasets

**Primary Datasets:**

```python
class VerificationDatasets:
    """
    Datasets for testing verification failure rates.
    """
    def __init__(self):
        self.datasets = {
            'atari_100k': self._create_atari_100k,
            'atari_adversarial': self._create_atari_adversarial,
            'crafter': self._create_crafter,
            'safety_gym': self._create_safety_gym,
            'distributional_shift': self._create_distributional_shift,
        }
    
    def _create_atari_100k(self):
        """
        Standard Atari 100k benchmark [heirarchical-transformer.pdf:3].
        
        26 games, 100k environment steps each.
        """
        return {
            'name': 'Atari 100k',
            'games': [
                'Pong', 'Breakout', 'Qbert', 'Seaquest', 'SpaceInvaders',
                'BeamRider', 'Enduro', 'MsPacman', 'Asterix', 'Freeway',
                # ... 16 more games
            ],
            'num_episodes': 100,
            'max_steps_per_episode': 1000,
            'evaluation_metric': 'human_normalized_score',
        }
    
    def _create_atari_adversarial(self):
        """
        Adversarial Atari dataset.
        
        Specifically designed to trigger verification failures:
        - Rare states
        - Adversarial perturbations
        - Edge cases
        """
        return {
            'name': 'Atari Adversarial',
            'base_games': ['Pong', 'Breakout', 'Seaquest'],
            'perturbations': [
                'rare_states',      # States with <1% frequency in training
                'adversarial_obs',  # Adversarially perturbed observations
                'edge_cases',       # Boundary conditions (e.g., max score)
            ],
            'num_examples_per_type': 1000,
        }
    
    def _create_crafter(self):
        """
        Crafter benchmark [heirarchical-transformer.pdf:3].
        
        Open-ended survival game with long-horizon planning.
        """
        return {
            'name': 'Crafter',
            'num_episodes': 100,
            'max_steps_per_episode': 10000,
            'evaluation_metric': 'achievement_score',
            'safety_constraints': [
                'avoid_death',
                'maintain_health',
                'avoid_monsters',
            ],
        }
    
    def _create_safety_gym(self):
        """
        Safety Gym benchmark.
        
        Continuous control with explicit safety constraints.
        """
        return {
            'name': 'Safety Gym',
            'tasks': [
                'PointGoal1',
                'CarGoal1',
                'DoggoGoal1',
            ],
            'safety_constraints': [
                'avoid_hazards',
                'stay_in_bounds',
                'limit_velocity',
            ],
            'num_episodes': 100,
        }
    
    def _create_distributional_shift(self):
        """
        Distributional shift dataset.
        
        Test generalization to shifted distributions.
        """
        return {
            'name': 'Distributional Shift',
            'base_dataset': 'Atari 100k',
            'shift_types': [
                'temporal_shift',      # Later game stages
                'difficulty_shift',    # Harder difficulty levels
                'visual_shift',        # Different color schemes
                'dynamics_shift',      # Modified game physics
            ],
            'num_examples_per_shift': 500,
        }
```

**Dataset Construction:**

```python
class AdversarialAtariDataset:
    """
    Construct adversarial Atari dataset to trigger verification failures.
    """
    def __init__(self, base_env, model):
        self.base_env = base_env
        self.model = model
        
    def generate_rare_states(self, num_examples=1000):
        """
        Generate rare states (low training frequency).
        
        Method: Monte Carlo Tree Search to find rare states.
        """
        rare_states = []
        
        # Estimate state density from training data
        state_density = self._estimate_state_density()
        
        # Search for low-density states
        for _ in range(num_examples):
            state = self._mcts_search_rare_state(state_density)
            rare_states.append(state)
        
        return rare_states
    
    def generate_adversarial_observations(self, num_examples=1000, epsilon=0.1):
        """
        Generate adversarial observations using FGSM.
        
        Maximize prediction error while staying within epsilon ball.
        """
        adversarial_obs = []
        
        # Collect clean observations
        clean_obs = self._collect_observations(num_examples)
        
        # Generate adversarial perturbations
        for obs in clean_obs:
            adv_obs = self._fgsm_attack(obs, epsilon)
            adversarial_obs.append(adv_obs)
        
        return adversarial_obs
    
    def generate_edge_cases(self, num_examples=1000):
        """
        Generate edge cases (boundary conditions).
        
        Examples:
        - Maximum score
        - Minimum lives
        - Extreme positions
        """
        edge_cases = []
        
        edge_conditions = [
            {'score': 'max', 'lives': 'min'},
            {'position': 'boundary'},
            {'velocity': 'max'},
        ]
        
        for condition in edge_conditions:
            cases = self._generate_condition_states(condition, num_examples // len(edge_conditions))
            edge_cases.extend(cases)
        
        return edge_cases
    
    def _fgsm_attack(self, obs, epsilon):
        """
        Fast Gradient Sign Method attack.
        """
        obs_tensor = torch.tensor(obs, requires_grad=True)
        
        # Forward pass
        prediction = self.model(obs_tensor)
        
        # Compute loss (maximize prediction error)
        loss = -prediction.sum()  # Negative to maximize
        
        # Backward pass
        loss.backward()
        
        # Generate perturbation
        perturbation = epsilon * obs_tensor.grad.sign()
        
        # Apply perturbation
        adv_obs = obs_tensor + perturbation
        
        # Clip to valid range
        adv_obs = torch.clamp(adv_obs, 0, 255)
        
        return adv_obs.detach().numpy()
    
    def _estimate_state_density(self):
        """
        Estimate state density using kernel density estimation.
        """
        # Collect training states
        training_states = self._collect_training_states()
        
        # Encode states using VQ-VAE
        encoded_states = self.model.vqvae.encode(training_states)
        
        # Fit KDE
        from sklearn.neighbors import KernelDensity
        
        kde = KernelDensity(bandwidth=0.5)
        kde.fit(encoded_states)
        
        return kde
    
    def _mcts_search_rare_state(self, state_density):
        """
        Use MCTS to search for rare states.
        """
        # Simplified MCTS implementation
        # Full implementation would require more sophisticated search
        
        current_state = self.base_env.reset()
        
        for _ in range(100):  # Max search depth
            # Evaluate state density
            density = state_density.score_samples(
                self.model.vqvae.encode(current_state).reshape(1, -1)
            )[0]
            
            # If rare enough, return
            if density < -10:  # Threshold for rarity
                return current_state
            
            # Otherwise, take random action and continue
            action = self.base_env.action_space.sample()
            current_state, _, done, _ = self.base_env.step(action)
            
            if done:
                current_state = self.base_env.reset()
        
        return current_state
```

### 5. Statistical Tests

```python
class VerificationFailureStatistics:
    """
    Statistical tests for verification failure rates.
    """
    def __init__(self):
        pass
    
    def test_failure_rate_difference(self, unconstrained_failures, constrained_failures):
        """
        Test if privacy constraint increases failure rate.
        
        H0: Failure rates are equal
        H1: Constrained model has higher failure rate
        """
        from scipy.stats import chi2_contingency, fisher_exact
        
        # Construct contingency table
        # Rows: [unconstrained, constrained]
        # Cols: [success, failure]
        
        contingency_table = np.array([
            [
                len(unconstrained_failures['successes']),
                len(unconstrained_failures['failures'])
            ],
            [
                len(constrained_failures['successes']),
                len(constrained_failures['failures'])
            ]
        ])
        
        # Chi-squared test
        chi2, p_value_chi2, dof, expected = chi2_contingency(contingency_table)
        
        # Fisher's exact test (more accurate for small samples)
        odds_ratio, p_value_fisher = fisher_exact(contingency_table, alternative='greater')
        
        # Effect size (relative risk)
        unconstrained_rate = contingency_table[0, 1] / contingency_table[0].sum()
        constrained_rate = contingency_table[1, 1] / contingency_table[1].sum()
        relative_risk = constrained_rate / (unconstrained_rate + 1e-10)
        
        # Risk difference
        risk_difference = constrained_rate - unconstrained_rate
        
        # 95% CI for risk difference (Wald method)
        n1, n2 = contingency_table.sum(axis=1)
        se_diff = np.sqrt(
            unconstrained_rate * (1 - unconstrained_rate) / n1 +
            constrained_rate * (1 - constrained_rate) / n2
        )
        ci_lower = risk_difference - 1.96 * se_diff
        ci_upper = risk_difference + 1.96 * se_diff
        
        return {
            'chi2_statistic': chi2,
            'chi2_p_value': p_value_chi2,
            'fisher_p_value': p_value_fisher,
            'odds_ratio': odds_ratio,
            'relative_risk': relative_risk,
            'risk_difference': risk_difference,
            'risk_difference_ci': (ci_lower, ci_upper),
            'unconstrained_failure_rate': unconstrained_rate,
            'constrained_failure_rate': constrained_rate,
            'interpretation': self._interpret_results(p_value_fisher, relative_risk)
        }
    
    def test_failure_severity(self, unconstrained_errors, constrained_errors):
        """
        Test if failures are more severe under constraints.
        
        H0: Error magnitudes are equal
        H1: Constrained model has larger errors
        """
        from scipy.stats import mannwhitneyu, ttest_ind
        
        # Mann-Whitney U test (non-parametric)
        u_stat, p_value_mw = mannwhitneyu(
            constrained_errors,
            unconstrained_errors,
            alternative='greater'
        )
        
        # t-test (parametric)
        t_stat, p_value_t = ttest_ind(
            constrained_errors,
            unconstrained_errors,
            alternative='greater'
        )
        
        # Effect size (Cohen's d)
        pooled_std = np.sqrt(
            (np.var(unconstrained_errors) + np.var(constrained_errors)) / 2
        )
        cohens_d = (np.mean(constrained_errors) - np.mean(unconstrained_errors)) / pooled_std
        
        return {
            'mann_whitney_u': u_stat,
            'mann_whitney_p': p_value_mw,
            't_statistic': t_stat,
            't_test_p': p_value_t,
            'cohens_d': cohens_d,
            'mean_unconstrained_error': np.mean(unconstrained_errors),
            'mean_constrained_error': np.mean(constrained_errors),
            'median_unconstrained_error': np.median(unconstrained_errors),
            'median_constrained_error': np.median(constrained_errors),
            'interpretation': self._interpret_severity(p_value_mw, cohens_d)
        }
    
    def test_failure_type_distribution(self, unconstrained_types, constrained_types):
        """
        Test if failure type distribution changes under constraints.
        
        H0: Failure type distributions are equal
        H1: Distributions differ
        """
        from scipy.stats import chi2_contingency
        
        # Get all failure types
        all_types = set(unconstrained_types.keys()) | set(constrained_types.keys())
        
        # Construct contingency table
        contingency_table = []
        for failure_type in all_types:
            contingency_table.append([
                unconstrained_types.get(failure_type, 0),
                constrained_types.get(failure_type, 0)
            ])
        
        contingency_table = np.array(contingency_table).T
        
        # Chi-squared test
        chi2, p_value, dof, expected = chi2_contingency(contingency_table)
        
        # Cramér's V (effect size for categorical data)
        n = contingency_table.sum()
        min_dim = min(contingency_table.shape) - 1
        cramers_v = np.sqrt(chi2 / (n * min_dim))
        
        return {
            'chi2_statistic': chi2,
            'p_value': p_value,
            'cramers_v': cramers_v,
            'contingency_table': contingency_table,
            'failure_types': list(all_types),
            'interpretation': self._interpret_distribution(p_value, cramers_v)
        }
    
    def test_temporal_failure_pattern(self, unconstrained_failures_by_time, constrained_failures_by_time):
        """
        Test if failure patterns change over rollout horizon.
        
        H0: Failure rates are constant over time
        H1: Failure rates increase over time (especially for constrained)
        """
        from scipy.stats import spearmanr
        
        # Compute failure rate at each timestep
        time_steps = sorted(unconstrained_failures_by_time.keys())
        
        unconstrained_rates = [
            unconstrained_failures_by_time[t]['failure_rate']
            for t in time_steps
        ]
        
        constrained_rates = [
            constrained_failures_by_time[t]['failure_rate']
            for t in time_steps
        ]
        
        # Test for trend (Spearman correlation with time)
        corr_unconstrained, p_unconstrained = spearmanr(time_steps, unconstrained_rates)
        corr_constrained, p_constrained = spearmanr(time_steps, constrained_rates)
        
        # Test if trends differ
        # Use Fisher's z-transformation
        z_unconstrained = np.arctanh(corr_unconstrained)
        z_constrained = np.arctanh(corr_constrained)
        
        n = len(time_steps)
        se_diff = np.sqrt(2 / (n - 3))
        z_diff = (z_constrained - z_unconstrained) / se_diff
        
        from scipy.stats import norm
        p_diff = 2 * (1 - norm.cdf(abs(z_diff)))
        
        return {
            'unconstrained_correlation': corr_unconstrained,
            'unconstrained_p': p_unconstrained,
            'constrained_correlation': corr_constrained,
            'constrained_p': p_constrained,
            'correlation_difference': corr_constrained - corr_unconstrained,
            'difference_p_value': p_diff,
            'interpretation': self._interpret_temporal(corr_constrained, corr_unconstrained, p_diff)
        }
    
    def compute_confidence_intervals(self, failure_rates, method='wilson'):
        """
        Compute confidence intervals for failure rates.
        
        Methods:
        - wilson: Wilson score interval (recommended)
        - clopper_pearson: Exact binomial CI
        - agresti_coull: Agresti-Coull interval
        """
        from statsmodels.stats.proportion import proportion_confint
        
        n_total = failure_rates['n_total']
        n_failures = failure_rates['n_failures']
        
        ci_lower, ci_upper = proportion_confint(
            n_failures,
            n_total,
            alpha=0.05,
            method=method
        )
        
        return {
            'point_estimate': n_failures / n_total,
            'ci_lower': ci_lower,
            'ci_upper': ci_upper,
            'method': method
        }
    
    def _interpret_results(self, p_value, relative_risk):
        """Interpret statistical test results."""
        if p_value < 0.001:
            significance = "highly significant"
        elif p_value < 0.01:
            significance = "very significant"
        elif p_value < 0.05:
            significance = "significant"
        else:
            significance = "not significant"
        
        if relative_risk > 2.0:
            magnitude = "large increase"
        elif relative_risk > 1.5:
            magnitude = "moderate increase"
        elif relative_risk > 1.1:
            magnitude = "small increase"
        else:
            magnitude = "negligible change"
        
        return f"{significance} ({magnitude} in failure rate, RR={relative_risk:.2f})"
    
    def _interpret_severity(self, p_value, cohens_d):
        """Interpret severity test results."""
        if p_value >= 0.05:
            return "No significant difference in error severity"
        
        if cohens_d > 0.8:
            magnitude = "large"
        elif cohens_d > 0.5:
            magnitude = "medium"
        elif cohens_d > 0.2:
            magnitude = "small"
        else:
            magnitude = "negligible"
        
        return f"Constrained model has {magnitude} increase in error severity (d={cohens_d:.2f})"
    
    def _interpret_distribution(self, p_value, cramers_v):
        """Interpret distribution test results."""
        if p_value >= 0.05:
            return "No significant change in failure type distribution"
        
        if cramers_v > 0.5:
            magnitude = "strong"
        elif cramers_v > 0.3:
            magnitude = "moderate"
        elif cramers_v > 0.1:
            magnitude = "weak"
        else:
            magnitude = "negligible"
        
        return f"{magnitude} association between constraint and failure type (V={cramers_v:.2f})"
    
    def _interpret_temporal(self, corr_constrained, corr_unconstrained, p_diff):
        """Interpret temporal pattern test results."""
        if p_diff >= 0.05:
            return "No significant difference in temporal failure patterns"
        
        if corr_constrained > corr_unconstrained:
            direction = "stronger"
        else:
            direction = "weaker"
        
        return f"Constrained model shows {direction} temporal degradation (ρ_diff={corr_constrained - corr_unconstrained:.2f})"
```

### 6. Experimental Protocol

```python
class VerificationExperiment:
    """
    Complete experimental protocol for testing privacy constraints.
    """
    def __init__(self, baselines, datasets, failure_detector, statistics):
        self.baselines = baselines
        self.datasets = datasets
        self.failure_detector = failure_detector
        self.statistics = statistics
        
    def run_experiment(self):
        """
        Execute complete experimental protocol.
        """
        print("=" * 80)
        print("VERIFICATION FAILURE RATE EXPERIMENT")
        print("=" * 80)
        
        results = {}
        
        # Phase 1: Train all baselines
        print("\n[Phase 1/4] Training baselines...")
        trained_models = self._train_baselines()
        
        # Phase 2: Evaluate on all datasets
        print("\n[Phase 2/4] Evaluating on datasets...")
        evaluation_results = self._evaluate_models(trained_models)
        
        # Phase 3: Detect failures
        print("\n[Phase 3/4] Detecting verification failures...")
        failure_results = self._detect_failures(evaluation_results)
        
        # Phase 4: Statistical analysis
        print("\n[Phase 4/4] Statistical analysis...")
        statistical_results = self._analyze_failures(failure_results)
        
        # Generate report
        self._generate_report(statistical_results)
        
        return statistical_results
    
    def _train_baselines(self):
        """
        Train all baseline models.
        """
        trained_models = {}
        
        for baseline_name, baseline_fn in self.baselines.items():
            print(f"  Training {baseline_name}...")
            
            model = baseline_fn()
            
            # Train on Atari 100k
            trainer = Trainer(model, dataset='atari_100k')
            trainer.train(num_steps=100_000)
            
            trained_models[baseline_name] = model
        
        return trained_models
    
    def _evaluate_models(self, trained_models):
        """
        Evaluate all models on all datasets.
        """
        evaluation_results = {}
        
        for dataset_name, dataset_fn in self.datasets.items():
            print(f"  Evaluating on {dataset_name}...")
            
            dataset = dataset_fn()
            evaluation_results[dataset_name] = {}
            
            for model_name, model in trained_models.items():
                print(f"    Model: {model_name}")
                
                predictions = []
                ground_truths = []
                metadata_list = []
                
                for example in dataset:
                    pred = model.predict(example['observation'])
                    predictions.append(pred)
                    ground_truths.append(example['ground_truth'])
                    metadata_list.append(example['metadata'])
                
                evaluation_results[dataset_name][model_name] = {
                    'predictions': predictions,
                    'ground_truths': ground_truths,
                    'metadata': metadata_list
                }
        
        return evaluation_results
    
    def _detect_failures(self, evaluation_results):
        """
        Detect verification failures in all evaluations.
        """
        failure_results = {}
        
        for dataset_name, dataset_results in evaluation_results.items():
            failure_results[dataset_name] = {}
            
            for model_name, model_results in dataset_results.items():
                failures = self.failure_detector.detect_failures(
                    predictions=model_results['predictions'],
                    ground_truth=model_results['ground_truths'],
                    metadata=model_results['metadata']
                )
                
                failure_results[dataset_name][model_name] = failures
        
        return failure_results
    
    def _analyze_failures(self, failure_results):
        """
        Statistical analysis of failure patterns.
        """
        statistical_results = {}
        
        # Compare unconstrained vs. offline
        print("  Comparing unconstrained vs. offline...")
        statistical_results['offline_vs_unconstrained'] = self._compare_models(
            failure_results,
            'shi_unconstrained',
            'shi_offline'
        )
        
        # Compare unconstrained vs. DP
        print("  Comparing unconstrained vs. differential privacy...")
        statistical_results['dp_vs_unconstrained'] = self._compare_models(
            failure_results,
            'shi_unconstrained',
            'shi_dp'
        )
        
        # Compare unconstrained vs. compressed
        print("  Comparing unconstrained vs. compressed...")
        statistical_results['compressed_vs_unconstrained'] = self._compare_models(
            failure_results,
            'shi_unconstrained',
            'shi_compressed'
        )
        
        # Analyze failure types
        print("  Analyzing failure type distributions...")
        statistical_results['failure_type_analysis'] = self._analyze_failure_types(
            failure_results
        )
        
        # Analyze temporal patterns
        print("  Analyzing temporal failure patterns...")
        statistical_results['temporal_analysis'] = self._analyze_temporal_patterns(
            failure_results
        )
        
        return statistical_results
    
    def _compare_models(self, failure_results, model1_name, model2_name):
        """
        Compare two models across all datasets.
        """
        comparison_results = {}
        
        for dataset_name in failure_results.keys():
            model1_failures = failure_results[dataset_name][model1_name]
            model2_failures = failure_results[dataset_name][model2_name]
            
            # Test failure rate difference
            rate_test = self.statistics.test_failure_rate_difference(
                model1_failures,
                model2_failures
            )
            
            # Test failure severity
            severity_test = self.statistics.test_failure_severity(
                model1_failures['errors'],
                model2_failures['errors']
            )
            
            # Test failure type distribution
            type_test = self.statistics.test_failure_type_distribution(
                model1_failures['types'],
                model2_failures['types']
            )
            
            comparison_results[dataset_name] = {
                'rate_test': rate_test,
                'severity_test': severity_test,
                'type_test': type_test
            }
        
        return comparison_results
    
    def _analyze_failure_types(self, failure_results):
        """
        Analyze distribution of failure types.
        """
        # Implementation details omitted for brevity
        pass
    
    def _analyze_temporal_patterns(self, failure_results):
        """
        Analyze how failures evolve over rollout horizon.
        """
        # Implementation details omitted for brevity
        pass
    
    def _generate_report(self, statistical_results):
        """
        Generate comprehensive report.
        """
        report = """
# Verification Failure Rate Analysis Report

## Executive Summary

This report analyzes how privacy/governance constraints affect verification-like
failure rates in the Sparse Hierarchical Imagination (SHI) Transformer.

## Key Findings

### 1. Offline Inference Constraint
"""
        
        offline_results = statistical_results['offline_vs_unconstrained']
        
        for dataset_name, results in offline_results.items():
            rate_test = results['rate_test']
            report += f"""
#### {dataset_name}
- **Failure Rate Increase:** {rate_test['risk_difference']:.2%} 
  [{rate_test['risk_difference_ci'][0]:.2%}, {rate_test['risk_difference_ci'][1]:.2%}]
- **Relative Risk:** {rate_test['relative_risk']:.2f}
- **Statistical Significance:** {rate_test['interpretation']}
- **Unconstrained Rate:** {rate_test['unconstrained_failure_rate']:.2%}
- **Offline Rate:** {rate_test['constrained_failure_rate']:.2%}

"""
        
        report += """
### 2. Differential Privacy Constraint
"""
        
        dp_results = statistical_results['dp_vs_unconstrained']
        
        for dataset_name, results in dp_results.items():
            rate_test = results['rate_test']
            severity_test = results['severity_test']
            
            report += f"""
#### {dataset_name}
- **Failure Rate Increase:** {rate_test['risk_difference']:.2%}
- **Error Severity Increase:** {severity_test['cohens_d']:.2f} (Cohen's d)
- **Interpretation:** {severity_test['interpretation']}

"""
        
        # Save report
        with open('verification_failure_report.md', 'w') as f:
            f.write(report)
        
        print("\nReport saved to: verification_failure_report.md")
```

### 7. Expected Outcomes & Interpretation

```python
class OutcomeScenarios:
    """
    Expected outcomes and interpretation guidelines.
    """
    def __init__(self):
        self.scenarios = {
            'scenario_1': self._scenario_minimal_impact,
            'scenario_2': self._scenario_moderate_impact,
            'scenario_3': self._scenario_severe_impact,
            'scenario_4': self._scenario_differential_impact,
        }
    
    def _scenario_minimal_impact(self):
        """
        Scenario 1: Privacy constraints have minimal impact.
        
        Findings:
        - Failure rate increase < 5%
        - No significant change in error severity
        - Failure type distribution unchanged
        
        Interpretation:
        - SHI is robust to offline inference constraint
        - Hierarchical masking provides sufficient flexibility
        - Privacy-preserving deployment is feasible
        
        Recommendation:
        - Deploy with offline constraint
        - No additional safeguards needed
        """
        return {
            'failure_rate_increase': 0.03,  # 3%
            'relative_risk': 1.05,
            'severity_cohens_d': 0.1,
            'interpretation': 'Minimal impact - safe to deploy with constraints',
            'recommendation': 'Proceed with offline deployment'
        }
    
    def _scenario_moderate_impact(self):
        """
        Scenario 2: Moderate impact on failure rates.
        
        Findings:
        - Failure rate increase 10-20%
        - Moderate increase in error severity (d=0.5)
        - Some shift in failure types (more rollout divergence)
        
        Interpretation:
        - Offline constraint reduces model flexibility
        - Adaptive masking was providing benefit
        - Trade-off between privacy and reliability
        
        Recommendation:
        - Deploy with caution
        - Implement additional monitoring
        - Consider hybrid approach (limited online refinement)
        """
        return {
            'failure_rate_increase': 0.15,  # 15%
            'relative_risk': 1.18,
            'severity_cohens_d': 0.5,
            'interpretation': 'Moderate impact - requires mitigation',
            'recommendation': 'Deploy with enhanced monitoring and fallback mechanisms'
        }
    
    def _scenario_severe_impact(self):
        """
        Scenario 3: Severe impact on failure rates.
        
        Findings:
        - Failure rate increase > 30%
        - Large increase in error severity (d>0.8)
        - Significant shift to catastrophic failures
        
        Interpretation:
        - Offline constraint fundamentally limits model capability
        - Online rollout refinement is critical for safety
        - Privacy-utility trade-off is unfavorable
        
        Recommendation:
        - Do not deploy with offline constraint
        - Explore alternative privacy mechanisms
        - Consider federated learning or secure enclaves
        """
        return {
            'failure_rate_increase': 0.35,  # 35%
            'relative_risk': 1.54,
            'severity_cohens_d': 0.9,
            'interpretation': 'Severe impact - deployment not recommended',
            'recommendation': 'Explore alternative privacy-preserving approaches'
        }
    
    def _scenario_differential_impact(self):
        """
        Scenario 4: Impact varies by context.
        
        Findings:
        - Minimal impact on common states
        - Severe impact on rare/adversarial states
        - Temporal degradation (failures increase with rollout horizon)
        
        Interpretation:
        - Offline constraint hurts generalization
        - Model relies on online adaptation for edge cases
        - Context-dependent deployment strategy needed
        
        Recommendation:
        - Deploy with offline constraint for common cases
        - Use online refinement for rare/critical cases
        - Implement risk-based switching mechanism
        """
        return {
            'failure_rate_common': 0.05,  # 5% increase on common states
            'failure_rate_rare': 0.40,    # 40% increase on rare states
            'temporal_correlation': 0.75,  # Strong temporal degradation
            'interpretation': 'Context-dependent impact - requires adaptive strategy',
            'recommendation': 'Implement risk-based hybrid deployment'
        }
```

### 8. Power Analysis

```python
class PowerAnalysis:
    """
    Determine required sample size for detecting failure rate differences.
    """
    def __init__(self):
        pass
    
    def compute_required_sample_size(self, 
                                     baseline_rate=0.10,
                                     effect_size=0.05,
                                     alpha=0.05,
                                     power=0.80):
        """
        Compute required sample size for detecting failure rate difference.
        
        Args:
            baseline_rate: Expected baseline failure rate (e.g., 10%)
            effect_size: Minimum detectable difference (e.g., 5% increase)
            alpha: Significance level (0.05)
            power: Desired statistical power (0.80)
        
        Returns:
            Required sample size per group
        """
        from statsmodels.stats.power import zt_ind_solve_power
        
        # Convert rates to effect size (Cohen's h)
        p1 = baseline_rate
        p2 = baseline_rate + effect_size
        
        cohens_h = 2 * (np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2)))
        
        # Solve for sample size
        n_per_group = zt_ind_solve_power(
            effect_size=cohens_h,
            alpha=alpha,
            power=power,
            alternative='two-sided'
        )
        
        return {
            'n_per_group': int(np.ceil(n_per_group)),
            'total_n': int(np.ceil(2 * n_per_group)),
            'baseline_rate': baseline_rate,
            'effect_size': effect_size,
            'cohens_h': cohens_h,
            'power': power,
            'alpha': alpha
        }
    
    def compute_power_curve(self, sample_sizes, baseline_rate=0.10, effect_size=0.05, alpha=0.05):
        """
        Compute power curve for different sample sizes.
        """
        from statsmodels.stats.power import zt_ind_solve_power
        
        p1 = baseline_rate
        p2 = baseline_rate + effect_size
        cohens_h = 2 * (np.arcsin(np.sqrt(p1)) - np.arcsin(np.sqrt(p2)))
        
        powers = []
        for n in sample_sizes:
            power = zt_ind_solve_power(
                effect_size=cohens_h,
                nobs1=n,
                alpha=alpha,
                alternative='two-sided'
            )
            powers.append(power)
        
        return {
            'sample_sizes': sample_sizes,
            'powers': powers,
            'effect_size': effect_size,
            'baseline_rate': baseline_rate
        }
    
    def plot_power_curve(self, power_curve_data):
        """
        Visualize power curve.
        """
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(10, 6))
        plt.plot(power_curve_data['sample_sizes'], power_curve_data['powers'], 'b-', linewidth=2)
        plt.axhline(0.80, color='r', linestyle='--', label='80% power')
        plt.xlabel('Sample Size per Group')
        plt.ylabel('Statistical Power')
        plt.title(f"Power Curve (Effect Size = {power_curve_data['effect_size']:.2%})")
        plt.grid(True, alpha=0.3)
        plt.legend()
        plt.tight_layout()
        
        return plt
```

### 9. Computational Budget

```python
class ComputationalBudget:
    """
    Estimate computational requirements for experiment.
    """
    def __init__(self):
        pass
    
    def estimate_budget(self):
        """
        Estimate total computational budget.
        """
        # Training
        training_budget = {
            'shi_unconstrained': 26 * 5 * 4,    # 26 games × 5 seeds × 4 GPU-hours
            'shi_offline': 26 * 5 * 4,
            'shi_dp': 26 * 5 * 6,               # DP training is slower
            'shi_compressed': 26 * 5 * 4,
            'iris_baseline': 26 * 5 * 4,
        }
        
        total_training = sum(training_budget.values())
        
        # Evaluation
        evaluation_budget = {
            'atari_100k': 5 * 26 * 100 * 0.01,  # 5 models × 26 games × 100 episodes × 0.01 GPU-hours
            'atari_adversarial': 5 * 3 * 1000 * 0.005,
            'crafter': 5 * 100 * 0.1,
            'safety_gym': 5 * 3 * 100 * 0.05,
            'distributional_shift': 5 * 4 * 500 * 0.005,
        }
        
        total_evaluation = sum(evaluation_budget.values())
        
        # Analysis
        analysis_budget = 50  # GPU-hours for statistical analysis
        
        # Total
        total_budget = total_training + total_evaluation + analysis_budget
        
        # Cost estimate (A100 @ $2.50/hour)
        total_cost = total_budget * 2.50
        
        return {
            'training_hours': total_training,
            'evaluation_hours': total_evaluation,
            'analysis_hours': analysis_budget,
            'total_hours': total_budget,
            'estimated_cost_usd': total_cost,
            'breakdown': {
                'training': training_budget,
                'evaluation': evaluation_budget
            }
        }
```

## Summary

This framework tests privacy/governance constraints on SHI by:

1. **Constraints:** Offline inference, differential privacy, compression, federated learning
2. **Failure Detection:** High-confidence errors, rollout divergence, safety violations, distribution shift
3. **Baselines:** Unconstrained SHI, offline SHI, DP-SHI, compressed SHI, IRIS
4. **Datasets:** Atari 100k, adversarial Atari, Crafter, Safety Gym, distributional shift
5. **Statistical Tests:** Chi-squared, Fisher's exact, Mann-Whitney U, Spearman correlation
6. **Metrics:** Failure rate, relative risk, error severity (Cohen's d), failure type distribution

**Expected Computational Budget:**
- Training: ~2,600 GPU-hours
- Evaluation: ~200 GPU-hours
- Total: ~2,850 GPU-hours (~$7,125 on A100s)

**Key Research Questions:**
1. Does offline inference increase verification failure rates?
2. Are failures more severe under privacy constraints?
3. Do failure types shift (e.g., more catastrophic failures)?
4. Does impact vary by context (common vs. rare states)?

## Sources

This framework is based on:
- [heirarchical-transformer.pdf] - "Sparse Hierarchical Imagination for Efficient Transformer World Models" - provides the hierarchical token organization [heirarchical-transformer.pdf:2], long-horizon imagination rollouts [heirarchical-transformer.pdf:2], evaluation on Atari 100k and Crafter [heirarchical-transformer.pdf:3], and SPARTAN causal graph component [heirarchical-transformer.pdf:2]

For privacy/governance and verification methodology, I recommend:
- **Differential Privacy:** Abadi et al. (2016) "Deep Learning with Differential Privacy" (CCS)
- **Verification in ML:** Katz et al. (2017) "Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks" (CAV)
- **Failure Detection:** Amodei et al. (2016) "Concrete Problems in AI Safety" (arXiv)
- **Statistical Testing:** Dror et al. (2018) "The Hitchhiker's Guide to Testing Statistical Significance in Natural Language Processing" (ACL)
- **Power Analysis:** Cohen (1988) "Statistical Power Analysis for the Behavioral Sciences"
- **Adversarial Robustness:** Goodfellow et al. (2015) "Explaining and Harnessing Adversarial Examples" (ICLR)