Short answer: As stated, “build AGI to solve world hunger” is not novel. The idea of using advanced AI for food security and famine early warning is decades old, with operational systems (FEWS NET) and a growing ML literature on predicting food insecurity from satellite, market, weather, and text data [4][1][5]. What could be novel is a sharply scoped, evidence-backed contribution that (a) closes the loop from prediction to decisions, (b) generalizes across countries with sparse labels, and (c) demonstrates measurable impact and safety under real constraints [2][5].

Where novelty can be
- End-to-end decision impact: Move beyond risk scoring to optimized, robust policies for targeting assistance and logistics (distribution, cash vs in‑kind) with off-policy evaluation and prospective pilots, not just predictive AUC [2].  
- Foundation model for low-resource generalization: A single multimodal model (satellite, prices, weather, conflict, news) that zero-shots to unseen countries and shocks with calibrated uncertainty, outperforming per-country models [1][5].  
- Human-AI early warning workflows: Demonstrate analyst-in-the-loop systems that improve lead time and reduce false alarms versus FEWS NET baselines while maintaining interpretability and accountability [2][4].  
- Causal robustness: Explicitly model interventions and confounding (e.g., rainfall, conflict, market closures) so recommendations remain valid under policy changes, not just correlations [5].  
- Cost-and-risk-aware optimization: Jointly optimize forecast quality and operational constraints (port capacity, road access, shelf life), reporting regret and cost-effectiveness vs status quo deployments [2].

Concrete, falsifiable experiments
- E1. Country-out generalization benchmark  
  Setup: Train on n−1 countries; test on the held-out country for 1–3 month food insecurity nowcasts (e.g., IPC phase or WFP insufficient food consumption) using multimodal inputs (Sentinel-2/VIIRS, CHIRPS rainfall, market prices, conflict, news).  
  Baselines: Per-country gradient boosting/CNN; recent satellite-pretrained models [1]; multimodal fusion [5].  
  Metrics: AUROC/F1 for hotspot detection, Brier score, lead-time vs FEWS NET alerts; calibration (ECE).  
  Falsifiable outcome: Zero-shot AUROC improves by ≥5 points over the best baseline in ≥70% of held-out countries at 1–2 month horizons [1][5].

- E2. Decision-centric off-policy evaluation  
  Setup: Learn a targeting policy that allocates limited aid (cash/food) by district under a budget. Evaluate with logged program data via doubly robust off-policy estimators; simulate counterfactuals with econometric demand and market models.  
  Metrics: Estimated increase in households meeting minimum dietary diversity per $1M, geographic coverage equity, worst-case regret under shocks.  
  Falsifiable outcome: Policy achieves ≥10% gains in outcomes per dollar over status quo heuristic targeting on historical logs; sensitivity analysis remains within ±3% under plausible confounding.

- E3. Lead-time gain over operational baselines  
  Setup: Compare your system to FEWS NET alerting on 5–10 historical crises. Inputs must be frozen to information available at the time.  
  Metrics: Early warning lead time (days), false-alarm/miss rates, analyst workload saved.  
  Falsifiable outcome: Median lead-time gain ≥14 days at matched false-alarm rate; if not achieved, claim of earlier warning is not supported [2][4].

- E4. Robustness and shift stress tests  
  Setup: Evaluate under conflict onset, extreme rainfall deficits, and sensor outages (simulate missing modalities).  
  Metrics: Performance drop vs in-distribution; conformal coverage under shift; ablation of modalities.  
  Falsifiable outcome: With any single modality removed, AUROC degrades <3 points and conformal intervals maintain nominal coverage; otherwise, system is brittle [5].

Suggested data and baselines
- Data: Public satellite imagery (Sentinel-2/VIIRS), rainfall (CHIRPS), market prices (FAO/WFP), conflict events (ACLED), and text/news. Prior work shows satellite pretraining helps food insecurity prediction [1] and that multimodal integration improves accuracy [5].  
- Baselines: FEWS NET/IPC analyst products for alert comparison [4]; recent satellite-pretrained classifiers [1]; multimodal fusion models [5]; earlier ML famine forecasting efforts [3].

Bottom line
- The vision is not novel; the contribution can be. Make it concrete: pick a decision, a geography set, and a lead-time target; prove generalization, decision impact, and robustness with transparent, falsifiable tests—ideally in collaboration with an operational partner [2][4][5].

Citations
[1] Spatiotemporal self-supervised pre-training on satellite imagery improves food insecurity prediction — https://www.cambridge.org/core/journals/environmental-data-science/article/spatiotemporal-selfsupervised-pretraining-on-satellite-imagery-improves-food-insecurity-prediction/47FDCFF96FF9A99D31548C1539D506A5  
[2] Saving Lives Sooner (FEWS NET white paper) — https://fews.net/sites/default/files/2025-08/White%20Paper%20-%20Innovation.pdf  
[3] Predicting Food Shortages (UCSB News) — https://news.ucsb.edu/2019/019558/predicting-food-shortages  
[4] Recognizing the Famine Early Warning Systems Network: Over 30 Years of Reducing Food Insecurity — https://journals.ametsoc.org/view/journals/bams/100/6/bams-d-17-0233.1.xml  
[5] Improving the accuracy of food security predictions by integrating multiple data sources — https://arxiv.org/html/2410.22342v1