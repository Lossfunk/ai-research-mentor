Short answer: Partly. GANs have been used in poetry, but almost entirely for generation (e.g., SeqGAN-style text GANs and multi-adversarial setups for poem creation) rather than analysis tasks like meter/scansion, rhyme/form classification, or authorship/style attribution [1][2][5]. State-of-the-art poetry analysis work typically uses specialized models or transformers, not GANs [3][4]. So “GANs for poetry analysis” is under-explored; it can be novel if you show that adversarial methods measurably improve analysis accuracy or robustness over strong non-GAN baselines.

What could be novel (and testable)
- GAN-based augmentation for analysis: Use a text GAN or adversarial paraphraser to generate counterfactual lines/verses that preserve semantics while varying meter or rhyme, then show that training on these improves scansion or rhyme-scheme classification OOD (e.g., across poets/eras) [5]. Conjecture.
- Cycle-consistent style transfer for counterfactual analysis: Train a cycle-style model to map between meters (e.g., iambic ↔ trochaic) and use it to probe what your classifier relies on; if augmentation with these counterfactuals improves generalization, that’s a concrete contribution. Conjecture.
- Adversarially trained discriminators as learned critics: Use the GAN discriminator as a feature extractor/auxiliary loss for meter/rhyme/form classification and show gains over transformer baselines on metrical prediction datasets [3][4]. Conjecture.

Three concrete, falsifiable experiments
- E1. Scansion accuracy with GAN augmentation
  - Task: Predict metrical pattern at the line level on a multilingual/English metrical dataset with established baselines [4].
  - Setup: Train a transformer classifier baseline vs the same model augmented with GAN-generated counterfactual lines that alter stress patterns but preserve content (human spot-check a sample for validity).
  - Metrics: F1/accuracy on in-domain and poet-held-out test sets.
  - Criterion: Augmented model improves OOD F1 by ≥3 points at equal precision; if not, no analysis benefit from GAN augmentation.

- E2. Rhyme scheme classification with adversarial features
  - Task: Classify rhyme scheme for quatrains/sonnets using rhyme labels or heuristics (Deep-speare and related work analyze rhyme and meter) [3].
  - Setup: Train (a) transformer baseline, (b) same model with an auxiliary GAN discriminator trained to distinguish “poetic vs perturbed” endings; feed discriminator features to the classifier.
  - Metrics: Accuracy/AUC and calibration; robustness to adversarial perturbations of line endings.
  - Criterion: Auxiliary discriminator yields ≥2-point accuracy gain and lower expected calibration error (ECE) by ≥20%; else auxiliary GAN not justified.

- E3. Cross-era/author robustness in form detection
  - Task: Detect sonnet form variants (Shakespearean vs Petrarchan) or meter class across eras.
  - Setup: Train on Shakespeare; test on later poets. Compare (a) baseline, (b) baseline + cycle-consistent meter-transfer augmentation (iambic↔other), (c) pure GAN-generated samples.
  - Metrics: OOD accuracy gap and worst-group accuracy.
  - Criterion: Cycle-consistent augmentation reduces OOD drop by ≥30% relative to baseline; if not, counterfactual GAN data isn’t helping.

Strong baselines and data
- Baselines: Deep-speare-style models for meter/rhyme and modern transformer classifiers for metrical pattern prediction [3][4].
- Datasets: Use metrical pattern corpora from prior work on multilingual meter prediction and rhyme/meter resources referenced in Deep-speare; supplement with curated sonnet corpora where form labels are unambiguous [3][4].
- Practical note: Training GANs on discrete text is nontrivial; methods like SeqGAN use policy gradients due to non-differentiable sampling. If generation quality is poor, focus on discriminator-as-feature or adversarial training rather than full text GANs [5].

How to claim novelty
- Clearly state the analysis task (scansion, rhyme/form, or attribution), define the metric, and compare against strong non-GAN baselines on held-out poets/eras.
- Show that adversarial components deliver consistent, statistically significant gains (with ablations isolating generator vs discriminator contributions).
- Provide failure analyses (e.g., where GAN-produced counterfactuals harm performance).

Takeaway
- GANs in poetry are not new for generation, but they are rarely used for analysis. You can make a novel contribution if you demonstrate that adversarial generation or discriminators measurably improve accuracy and robustness on well-defined analysis tasks, compared to transformer and rule-based baselines, with clean OOD tests [1][2][3][4][5].

Sources
[1] Generating Poetry from Images by Multi-Adversarial Training — https://arxiv.org/pdf/1804.08473
[2] Creative GANs for generating poems, lyrics, and metaphors — https://arxiv.org/abs/1909.09534
[3] Deep-speare: A joint neural model of poetic language, meter and rhyme — https://aclanthology.org/P18-1181/
[4] Transformers analyzing poetry: multilingual metrical pattern prediction — https://link.springer.com/content/pdf/10.1007/s00521-021-06692-2.pdf
[5] SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient — https://ojs.aaai.org/index.php/AAAI/article/view/10804