## 1. Problem framing and goals

**Core challenge**: Develop underwater computer vision systems that can run on edge devices (≤15W) to automate coral reef health assessment from volunteer-scuba data, addressing the triple bottlenecks of (i) power-constrained on-device inference, (ii) noisy imagery from non-experts, and (iii) severe class imbalance across reef species.

**Goal statement**: Deliver a field-ready prototype—trained and validated on 5,000 diver-collected RGB images—that simultaneously (a) achieves ≥85% species-level F1 for "indicator" corals while (b) cutting average in-situ inference energy to <1.0 Wh per 1920×1080 frame on a Jetson Nano, matching a biologist's annotation time on the boat. The six-month deliverable is an open-source toolkit plus a conference submission (ICCV/CVPR) with external IRB and marine-agency data-collection permits.

## 2. Experiments (3-month execution + 1-month buffer)

**Exp-1**: Low-power species detector baseline  
*Hypothesis*: Underwater species detection accuracy saturates at ∼80% F1 when the backbone switches from ResNet-50 to MobileNet-V3 at 8-bit, while energy falls 3×.  
*Setup*: Fine-tune both backbones on the 2019 "CoralNet" dataset augmented with color-corruption + blur kernels. Train on 2×RTX A6000 for 5h with mixed precision.  
*Baselines*: ResNet-50 full 32-bit, full-precision MobileNet-V3, and off-the-shelf YOLO-v5-n.  
*Metrics*: Top-1 accuracy, F1 (macro), #MACs, on-device energy measured via Keysight N6705B DC power analyzer.  
*Expected outcome*: MobileNet-V3 8-bit yields 0.78 F1 at 3.2W average; ResNet baseline 0.83 F1 at 11W. Clarifies whether further compression buys >5% F1 return.

**Exp-2**: Color-through-water self-supervised denoising pipeline  
*Hypothesis*: A lightweight LUT + 3×3 learnable WB gain map (≈0.03M extra params) lifts F1 by ≥4% relative on diver-taken images versus histogram white-balance.  
*Setup*: Train on volunteer diver imagery (n≈1.2k) using MoCo-v3 contrastive loss to force consistency between raw RGB and green-channel-corrected pairs.  
*Baselines*: Classic histogram WB, Gray-World, U-Net-based restoration.  
*Metrics*: PSNR on held-out coral patches and species classification accuracy after denoising.  
*Expected outcome*: ≥1.5 dB PSNR and +3% macro-F1 over classic WB, running in <0.5W extra on Jetson Nano.

**Exp-3**: Few-shot class rebalancing via promptable segmentation  
*Hypothesis*: A CLIP-guided mask predictor plus 25 labeled masks per rare species (≤10 samples) boost rare-species IoU by ≥10%.  
*Setup*: Run Segment-Anything-2 on sparse masks, prompt with text + visual cues from healthy vs. bleached states.  
*Baselines*: Classic k-means color clustering, supervised Mask R-CNN trained on full data.  
*Metrics*: pixel-IoU, energy cost per mask on device, human-annotator time saved.  
*Expected outcome*: achieve 0.65 IoU on rare vs. 0.42 baseline while adding <2Wh on device.

## 3. 6-month timeline with milestones (backward schedule from submission)

Month-0: Acquire IRB, MoU with coral NGOs, final diver-collect kit checklist  
Month-1: Image capture with 10 volunteer divers (target 5k raw RGB frames)  
Month-2: Baseline training and power profiling on Jetson Nano; Exp-1 completes  
Month-3: Exp-2 plus field test-1 (wet test at 5m)  
Month-4: Exp-3 runs; integrate automatic report pdf on boat RPi  
Month-5: Field test-2 (20m, night), performance regression, ethics/permits archive  
Month-6: Paper draft, reproducibility bundle, supplemental video, submission

## 4. Resources (compute, tools, datasets)

**Compute**: 2× RTX A6000 workstation, 1× Jetson Nano (10W dev kit), 1× Raspberry Pi 4 (8GB) as topside base-station.  
**Tools**: PyTorch 2.2, TensorRT 8.6, Weights & Biases, Segment-Anything-2, MoCo-v3, Keysight N6705B power analyzer.  
**Datasets**: Primary = CoralNet 2019 (≈15k annotated); additional custom diver capture target 5k new RGB frames, balanced across 20 coral species at 3 sites.  
**Energy budget**: ≤15W on-device, 12V/20Ah Li battery pack for 8h dive operation.

## 5. Risks and mitigations

| Risk | Severity | Mitigation |
| --- | --- | --- |
| Cloudy water kills image quality | High | Add optical clarity gate to skip low-quality frames; collect >1k shallow-water training samples |
| Annotator shortage | Med | Outsource to iMac-based citizen science portal; pay-per-label via gift cards |
| Jetson Nano stock-out | Med | Validate on Xavier-NX and Nano-SUPER; re-profile energy curve |
| False coral-ID may damage reef | High | Ethics committee review; predictions shown as "assist" only, never autonomous action |
| Energy >15W on custom board | Med | Tune int8 quantization, prune 40% channels, profile on DC lab supply |

## 6. Stretch ideas / follow-ups

A. Real-time coral bleaching heat-map generation fused with CTD (conductivity-temperature-depth) sensor data for ecological forecasting.  
B. Extend to 4K stereo imagery with passive acoustics for fish abundance estimation, pushing compute to Orin-NX.  
C. Global species map via federated learning among dive clubs, keeping images local for privacy, aggregating model deltas.

**Optional next step**: Run baseline energy measurements on Jetson Nano first, then share numbers for peer calibration before Month-1 field capture.