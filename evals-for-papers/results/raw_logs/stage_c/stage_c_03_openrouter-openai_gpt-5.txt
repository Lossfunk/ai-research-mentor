Short answer up front: No single AI system will “cure cancer tomorrow.” But you can, within days to weeks, deploy and test AI workflows that measurably improve early detection, speed time-to-treatment, and optimize therapy selection—areas where evidence already supports benefit in pathology and screening. Below is a 90‑day plan with concrete, falsifiable experiments, tight governance, and quick wins that scale.

Objectives (near term, 30–90 days)
- Reduce time-to-treatment by 20–30% in targeted pathways (e.g., colorectal, breast) via AI-enabled triage and decision support. Conjecture.
- Increase detection and guideline-concordant testing by deploying validated AI where evidence exists:
  - AI breast screening support has shown improved specificity/sensitivity in large evaluations [2].
  - Deep learning can predict microsatellite instability (MSI) directly from H&E slides, a marker guiding immunotherapy, enabling low-friction screening to prioritize confirmatory testing [1].
- Use FDA-cleared AI/ML devices where available, especially in radiology workflows, to speed adoption and compliance [3].

30/60/90-day plan
Days 0–14: Foundation and rapid retrospective evaluation
- Scope: Pick 2 high-volume, high-impact pathways (e.g., colorectal and breast). Define patient cohorts, endpoints, and decision points amenable to AI.
- Data and compliance: Secure IRB/QA pathway for retrospective evaluation; data use agreements; de-identification; model risk classification and monitoring plans.
- Tools to evaluate (offline first):
  - Pathology MSI-screening model on H&E WSIs to prioritize MSI PCR/NGS testing (supports immunotherapy decision-making) [1].
  - Mammography screening AI for triage/second read; integrate into reader study design [2].
  - Clinical trial matching assistant (LLM-based) to pre-screen eligibility; keep human-in-the-loop. Conjecture.
- Baselines: Current time-to-treatment; cancer detection rates; recall/false-positive rates; MSI test ordering rates; trial referral rates.

Days 15–45: Prospective pilots (stepped-wedge or A/B) with guardrails
- Stand up two pilots:
  1) Pathology MSI-screening: Silent mode for 2 weeks (no action, data only) → then surfaced suggestions to pathologists/oncologists with rapid confirmatory testing. [1]
  2) AI-assisted mammography: Reader study or stepped-wedge deployment across sites/days; measure specificity/sensitivity and recall rates against standard-of-care [2].
- Human oversight: Multi-disciplinary tumor board sign-off; escalation protocols; safety monitoring; daily drift and bias checks (age, sex, race/ethnicity, site).
- Early health economics: Track turnaround time, resource use (confirmatory tests, biopsies), and bottlenecks.

Days 46–90: Scale, measure, and harden
- Expand successful pilots to additional sites; integrate into EHR/ordering systems (e.g., automatic add-on MSI confirmatory testing triggers when AI risk is high).
- Launch trial-matching navigator (LLM-assisted) as a pilot to reduce time-to-referral; keep manual verification. Conjecture.
- Finalize reporting: clinical utility metrics, workflow impact, cost-effectiveness; decide on wider rollout.

Falsifiable experiments (at least three)
1) Pathology MSI-screening impact study
- Design: Stepped-wedge deployment across pathology benches for colorectal/gastric tumors over 8–12 weeks.
- Hypothesis: AI triage increases confirmed MSI-H detection by ≥20% and reduces time from biopsy to confirmatory result by ≥3 days, without increasing inappropriate immunotherapy starts. Falsify if either improvement is below thresholds or safety events occur. Supported by feasibility of MSI prediction from H&E [1].
- Metrics: Positive predictive value of AI-high flag for MSI-H; MSI testing rate; turnaround time; therapy initiation delays; demographic parity across subgroups.
- Sample size: Power for 10–15% absolute increase in MSI testing rate (baseline ~50–60%) within 500–1,000 cases. Conjecture.

2) AI-assisted mammography reader study
- Design: Multi-reader, multi-case trial with and without AI; or stepped-wedge in routine practice for 6–8 weeks.
- Hypothesis: AI assistance improves specificity by ≥5% at non-inferior sensitivity (−1% margin) and reduces recall rate by ≥10% relative to baseline. Falsify if any criterion fails. Grounded in large-scale evaluation evidence [2].
- Metrics: Sensitivity, specificity, recall rate, cancer detection rate, reading time per case; stratify by breast density and age.

3) Time-to-treatment reduction via AI triage
- Design: Before/after or controlled cohort in two pathways (breast, colorectal).
- Hypothesis: Median time from suspicious finding/biopsy to first treatment falls by ≥20% after AI triage + fast-track confirmatory testing, with no increase in adverse events. Falsify if reduction <10% or quality metrics worsen. Conjecture.
- Metrics: Time-to-diagnosis, time-to-MDT, time-to-treatment; proportion of stage migration at diagnosis; unplanned admissions.

4) LLM-assisted clinical trial matching
- Design: Prospective concordance study vs. nurse navigator gold standard on 150–300 patients.
- Hypothesis: LLM pre-screen achieves ≥90% precision and ≥80% recall on trial eligibility summaries and reduces navigator time per patient by ≥30%, with zero unreviewed patient-facing outputs. Falsify if thresholds not met. Conjecture.
- Safety: Human confirmation required; audit logs; HIPAA-compliant deployment.

5) Cost-utility analysis alongside pilots
- Design: Decision-analytic model fed by pilot data.
- Hypothesis: Net cost per additional appropriate therapy initiation (e.g., immunotherapy in MSI-H) is below a pre-specified threshold (e.g., <$2,000) given reduced delays and fewer redundant tests. Falsify if above threshold. Conjecture.

Key enablers and controls
- Use validated tools where evidence exists:
  - MSI-from-H&E as low-friction screen to trigger confirmatory testing [1].
  - AI for breast screening has shown performance gains in international evaluations [2].
  - Prefer FDA-cleared AI/ML devices for radiology and similar domains for faster governance and support [3].
- Governance and safety
  - IRB or quality-improvement oversight; pre-specified stopping rules.
  - Bias and drift monitoring; subgroup analyses; calibration checks.
  - Data privacy, access control, audit trails; no unsupervised patient-facing LLM outputs.
- Integration and ops
  - EHR order sets: automatic confirmatory test suggestions when AI flags high risk.
  - Tumor board briefs: structured summaries of pathology/radiology with citations for clinician verification. Conjecture.
  - Staff training, feedback loops, and post-deployment monitoring dashboards.

Deliverables and checkpoints
- Week 2: Retrospective performance reports (AUC, calibration), workflow maps, risk assessment.
- Week 6: Prospective pilot interim analysis; decision on scale-up.
- Week 12: Final utility and cost analyses; deployment plan for additional services/sites.

Risks and mitigations
- Model underperforms on local data: run local recalibration and silent-mode evaluation first; set conservative operating thresholds.
- Workflow friction negates gains: co-design with clinicians; automate low-burden steps; monitor turnaround times.
- Regulatory and legal: prefer cleared devices for patient-impacting tasks; confine research models to decision support with human sign-off.

Two literature anchors
- Deep learning can predict MSI directly from H&E histology, enabling targeted testing prioritization [1].
- AI-assisted mammography has shown improved screening performance in large evaluations [2].

Citations
[1] Kather et al. Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer — https://www.nature.com/articles/s41591-019-0462-y
[2] McKinney et al. International evaluation of an AI system for breast cancer screening — https://www.nature.com/articles/s41586-019-1799-6
[3] FDA. Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices — https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices

Key takeaway: You can’t cure cancer with AI tomorrow, but you can stand up tightly-governed pilots within weeks that increase appropriate testing, improve screening accuracy, and shorten time-to-treatment—areas already supported by evidence.