1. Problem framing and goals
- Objective: Develop graph neural network (GNN) models that improve sea-ice forecasting and analysis across three operationally relevant tasks: (a) spatiotemporal forecasting of sea-ice concentration (SIC) and ice edge, (b) sea-ice drift prediction using floe- or grid-based graphs, and (c) deformation/lead detection with physics-aware constraints. Recent work shows that graph modeling helps capture multi-scale interactions in sea ice fields [1] and that deep GNNs are viable for sub-seasonal Arctic sea-ice forecasting [2], motivating a targeted, rigorous plan.
- Why GNNs: Sea ice exhibits strong spatial coupling, anisotropic deformation, and flow-driven dynamics. Graphs naturally encode neighborhood relations across irregular coastlines and dynamic floe networks, and can be extended to multi-sensor fusion and physics-aware message passing [1][2].
- Data landscape and supervision: 
  - SIC for forecasting and edge verification from NOAA/NSIDC CDR [6], plus operational ice edge products for evaluation.
  - Drift “ground truth” from OSI-SAF Lagrangian products and documentation [5] and intercomparison/verification context via SIDFEx [7].
  - SAR (Sentinel-1) for floe structure and deformation; use SAR segmentation/tracking pipelines as baselines [3][4][8].
- Deliverables:
  - A reproducible GNN codebase with standardized graph construction, training, and evaluation protocols tailored to sea ice.
  - Benchmarked models on SIC forecasting, drift prediction, and deformation/lead detection under robust spatiotemporal splits.
  - Uncertainty-aware outputs suitable for decision support in operations, following emerging sea-ice UQ practice [10].

2. Experiments
Experiment 1: Multi-scale graph modeling for SIC forecasting and ice-edge detection
- Hypothesis: A spatiotemporal GNN (message passing on a grid/mesh with multi-scale edges) will outperform strong CNN/Transformer baselines for multi-day SIC and edge forecasting by better capturing heterogeneous advection and coastline effects [1][2].
- Setup:
  - Data: NOAA/NSIDC SIC CDR (daily, 1979–present) for pan-Arctic; train on 1992–2015, validate 2016–2018, test 2019–2023 with seasonally stratified splits [6]. Optional nowcasting augmentation with near-real-time OSI-SAF [5].
  - Graph: Nodes are grid cells (e.g., 25 km), edges include k-NN geodesic neighbors and multi-scale links (25–100–200 km) to capture teleconnections [1]. Temporal graph with edges across t→t+1..t+7.
  - Model: Spatiotemporal GNN or Graph Transformer with learned edge features (distance, bearing, historical drift), and exogenous forcing (wind, near-surface temperature) if available.
- Baselines:
  - U-Net and ConvLSTM baselines (SIC forecasting), ViT time-lagged baseline [4].
  - Persistence and climatology baselines; simple optical-flow advection of SIC.
- Evaluation metrics:
  - RMSE/MAE for SIC; ice-edge F1 and distance-to-edge error; Brier score and reliability for probabilistic edge forecasts.
- Expected outcomes:
  - Improved ice-edge F1 and SIC RMSE at 3–7 day horizons relative to U-Net/ConvLSTM, especially near marginal ice zones where nonlocal effects matter [1][2].
  - Ablations show gains from multi-scale edges and season-aware graph normalization.

Experiment 2: Drift prediction with graph-based floe dynamics
- Hypothesis: A floe-graph GNN that passes messages along floe–floe contacts and nearest neighbors will reduce endpoint drift error vs. optical-flow or correlation-based drift baselines when trained on SAR-derived floe graphs with OSI-SAF or tracked drift supervision [5][8].
- Setup:
  - Data: Sentinel-1 SAR pairs (e.g., 6–48 h separation) over Arctic; derive floe segments (CNN/Watershed/level-set baseline) [4], then track floes between images to form a graph; labels via OSI-SAF drift vectors and/or SAR-based tracking [5][8].
  - Graph: Nodes are floes with attributes (area, shape, backscatter stats), edges from Delaunay adjacency and proximity; add wind/ice motion context if available.
  - Model: Message-passing GNN predicting displacement vectors per floe; train with Huber loss on displacement.
- Baselines:
  - Cross-correlation drift (classical) [8], optical-flow, OSI-SAF drift where applicable [5].
- Evaluation metrics:
  - Vector endpoint error, angular error, and outlier fraction; track continuity metrics for sequences.
- Expected outcomes:
  - Lower endpoint error and fewer large outliers in dynamic/fragmented regimes vs. correlation/optical-flow baselines; improved consistency across SAR incidence angles due to learned features.

Experiment 3: Physics-aware GNN for deformation and lead opening
- Hypothesis: Incorporating simple mechanical priors (e.g., penalizing area-increase under compression, encouraging faults/anisotropy alignment) in the loss or architecture will improve detection and short-term forecasting of leads and shear bands in SAR [2][9].
- Setup:
  - Data: Sentinel-1 SAR time series; generate pseudo-labels of leads/deformation via intensity/texture cues and drift gradients; optional manual validation subsets. Use linked SIC and drift products to contextualize [5][6].
  - Graph: Grid or floe-based. Include directional edge features (wind direction, prior drift direction).
  - Model: GNN with physics-aware losses: (i) divergence penalty in consolidated pack, (ii) anisotropic smoothness along flow, (iii) topology-regularized lead persistence.
- Baselines:
  - CNN segmentation (SAR leads) [4]; classical strain-rate thresholds from drift fields.
- Evaluation metrics:
  - Lead IoU/F1, false discovery rate along coastlines, and change-detection metrics for opening/closing intervals.
- Expected outcomes:
  - Higher lead IoU and more stable change detection in storm events; ablations show physics-aware penalties reduce noisy false positives. We note that physics-informed GNNs are established in ice mechanics emulation (ice sheets) and motivate analogous priors for sea ice, though direct sea-ice physics-GNN studies remain sparse [9].

Experiment 4: Uncertainty-aware GNNs for operational decision support
- Hypothesis: Probabilistic GNNs (ensembles, MC dropout, heteroscedastic heads) calibrated on retrospective forecasts yield better risk communication (calibration and sharpness) than deterministic models, aligning with emerging uncertainty-aware sea-ice forecasting work [10].
- Setup:
  - Apply to Experiments 1–3; produce predictive means and variances; train with NLL + proper scoring rules; post-hoc calibration with isotonic regression.
- Baselines:
  - Deterministic GNNs and CNNs; naive ensembles.
- Evaluation metrics:
  - CRPS, Brier score, reliability diagrams, coverage of prediction intervals.
- Expected outcomes:
  - Better-calibrated probabilities and improved CRPS without sacrificing point accuracy at short horizons [10].

Notes on literature coverage: We found directly relevant GNN studies on multi-scale graph modeling for sea ice prediction [1] and a deep GNN for sub-seasonal sea-ice forecasting [2]. For floe segmentation/tracking and drift, robust non-GNN baselines exist [4][8] and standard verification products are available [5][7]. Physics-informed GNN emulation is established in ice mechanics (ice sheets) [9], but sea-ice–specific physics-GNN papers remain limited. We propose to gather stronger references by: (i) a systematic search combining “sea ice” + “graph neural network” + “drift”/“lead”/“physics-informed” on arXiv and AGU journals; (ii) harvesting citations from [1][2] to expand sea-ice–specific GNN literature; and (iii) screening OSI-SAF validation studies for metric standards.

3. Timeline for the next 6 months with milestones
Month 1:
- Data and infrastructure: Ingest NSIDC SIC CDR [6], OSI-SAF drift [5], and a curated Sentinel-1 SAR subset; standardize projections and grids; define spatial-temporal splits.
- Baselines: Implement persistence, climatology, and U-Net/ConvLSTM for SIC; cross-correlation drift from [8].
- Graph prototypes: Implement grid graph with multi-scale edges; floe graph extraction pipeline (simple watershed + tracking).

Month 2:
- Experiment 1 (SIC): Train first spatiotemporal GNN; tune graph scales; evaluate RMSE/edge F1.
- Experiment 2 (Drift): Train initial floe-graph GNN on SAR pairs; compare to correlation/optical flow.
- Metrics harness: Unified evaluation for RMSE/edge F1, drift endpoint error, lead IoU.

Month 3:
- Experiment 1 ablations: Graph construction (k-NN vs Delaunay vs coastline-aware), horizon sensitivity (1–7 days).
- Experiment 2 ablations: Edge definitions, temporal context windows, incidence-angle robustness.
- Draft short internal report on methods and initial results.

Month 4:
- Experiment 3 (Physics-aware): Implement divergence and anisotropy penalties; train on SAR sequences; evaluate lead detection and change metrics.
- Experiment 4 (UQ): Add probabilistic heads/ensembles for Experiments 1–3; calibrate; assess CRPS/Brier.
- External baselines: Compare to OSI-SAF drift, public SIC operational products.

Month 5:
- Integrations: Multi-task learning (SIC + edge + drift); add exogenous forcings if available (winds).
- Robustness: Out-of-year generalization, extreme events (storms), coastal masks; uncertainty stress tests.
- Draft paper: Methods, experiments, and ablations; figures and calibration plots.

Month 6:
- Reproducibility: Release code, configs, and data recipes; finalize experiments; run held-out SIDFEx-style case studies [7].
- Submission: Target a remote sensing or geoscience ML venue; prepare supplementary material, including error analysis and failure cases.

4. Resources (compute, tools, datasets)
- Compute: 2–4 GPUs (A100/RTX 6000 class) for GNN and CNN training; ~10–20 TB storage for SAR tiles and intermediate products; CPUs for SAR preprocessing.
- Tools:
  - PyTorch Geometric or DGL for GNNs; xarray/zarr for geospatial time series; rasterio/pyproj for reprojection; cuCIM/OpenCV for SAR tiling; hydra/wandb for experiment tracking.
- Datasets and products:
  - SIC: NOAA/NSIDC CDR v4 [6] and near-real-time products.
  - Drift and edge: OSI-SAF drift product descriptions and datasets [5]; SIDFEx for intercomparison/verification practices [7].
  - SAR: Sentinel-1 GRD scenes; segmentation/tracking baselines and open-source drift algorithm for Sentinel-1 [8]; SAR-based sea ice classification and segmentation references [3][4].
  - Optional forcings: ERA5 winds/temperature if permitted; coastal masks and bathymetry grids for graph features.

5. Risks and mitigations table
- Sparse GNN sea-ice literature — Mitigation: Anchor to [1][2] for graph modeling and supplement with strong non-GNN baselines [4][8]; design thorough ablations and public benchmarks to ensure rigor.
- Label noise/uncertainty in drift and leads — Mitigation: Use multiple “truth” sources (OSI-SAF, SAR tracking) and robust losses; evaluate with SIDFEx-style case studies [5][7].
- SAR domain shifts (season/incidence angle) — Mitigation: Incidence-angle features, per-season normalization, domain augmentation; evaluate by season and sensor mode.
- Graph construction sensitivity — Mitigation: Systematic ablations (k-NN/Delaunay/multi-scale), coastline-aware edges; report performance variance and confidence intervals.
- Overfitting to regions/years — Mitigation: Strict space–time splits; hold-out years and regions; report generalization gaps explicitly.
- Computational bottlenecks for SAR preprocessing — Mitigation: Tiling and caching; prioritize representative regions; scale up progressively.
- Physics priors mismatch — Mitigation: Tune penalties with validation; fallback to purely data-driven variants; include sensitivity analysis.
- Uncertainty miscalibration — Mitigation: Use proper scoring rules, post-hoc calibration, and reliability diagrams; stress test during extremes [10].

6. Stretch ideas or follow-up directions
- Hybrid ML–physics: Couple GNN outputs with a lightweight sea-ice dynamics emulator for constraint-aware rollout; leverage progress in GNN emulators for ice mechanics (transferrable architectural ideas) [9].
- Graph construction from deformation networks: Build nodes on strain-rate ridges or lead skeletons for event-centric forecasting; compare to uniform grids.
- Multi-sensor fusion: Integrate passive microwave, SAR, and ICESat-2 freeboard via heterogeneous graphs.
- Long-horizon sub-seasonal forecasting: Extend [2] to 1–8 week horizons with regime-aware training and seasonal stratification.
- Active learning: Targeted annotation of difficult SAR scenes (storms, marginal ice zones) guided by epistemic uncertainty [10].

Optional next step
- Stand up Experiment 1 end-to-end on a 25 km pan-Arctic grid (1992–2020 train, 2021–2023 test) with a multi-scale Graph Transformer and compare to U-Net/ConvLSTM, reporting SIC RMSE and ice-edge F1; then roll in probabilistic heads and calibration.

Citations
[1] Arctic Sea Ice Prediction Based on Multi-Scale Graph Modeling With ... — https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024JD042136
[2] Deep Graph Neural Networks for Spatiotemporal Forecasting of Sub-seasonal Arctic Sea Ice (preprint) — https://d197for5662m48.cloudfront.net/documents/publicationstatus/182375/preprint_pdf/26152ac7cda0bbf3585f10d45e5ba412.pdf
[3] IceGCN: An Interactive Sea Ice Classification Pipeline for SAR (MDPI Remote Sensing) — https://www.mdpi.com/2072-4292/16/13/2301
[4] Sea Ice Segmentation From SAR Data by Convolutional Neural Networks (arXiv) — https://arxiv.org/abs/2306.07649
[5] OSI-SAF Medium Resolution Sea Ice Drift product (OSI-407-a) — https://osisaf-hl.met.no/osi-407-a-desc
[6] Sea Ice Concentration: NOAA/NSIDC Climate Data Record — https://climatedataguide.ucar.edu/climate-data/sea-ice-concentration-noaansidc-climate-data-record
[7] The Sea Ice Drift Forecast Experiment (SIDFEx) — https://sidfex.polarprediction.net/
[8] Open-source sea ice drift algorithm for Sentinel-1 SAR imagery (The Cryosphere, 2017) — https://tc.copernicus.org/articles/11/1835/2017/tc-11-1835-2017.pdf
[9] Graph Neural Networks for Emulation of Finite-Element Ice (ice sheets; arXiv) — https://arxiv.org/abs/2406.18423
[10] Data-Driven Uncertainty-Aware Forecasting of Sea Ice Conditions in the Arctic (arXiv) — https://arxiv.org/html/2410.19782v1