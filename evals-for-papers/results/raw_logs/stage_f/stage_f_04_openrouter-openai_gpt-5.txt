Below is a venue-by-venue map of formatting/anonymization and artifact expectations, followed by an adapted submission plan for “Do Multiple Instance Learning Models Transfer?” I reference the official pages so you can double-check details that change year to year.

Venue-specific expectations

NeurIPS
- Formatting/pages: Use the current NeurIPS template and limits in the Call for Papers; references typically unlimited but main-text page limits are strict and enforced at desk-check [1]. Include the NeurIPS Paper Checklist in the submission package [2].
- Anonymization: Double-blind; follow the author FAQ for what counts as identifying information [4].
- Code/data: Strongly encouraged. Address the Reproducibility Checklist items in text/appendix; Datasets & Benchmarks track has additional requirements on licenses/provenance [2][3]. Ethics guidelines apply and papers can be routed to an ethics review when appropriate [19][20].

ICML
- Formatting/pages: Follow the ICML 2025 formatting instructions and template; strict page/format checks at submission (example and style guide provided) [5][6]. Prior-year author instructions give useful context but rely on the current year for hard limits [7].
- Anonymization: Double-blind per the author instructions; ensure supplementary is anonymized similarly [5][7].
- Code/data: Code release and a thorough reproducibility section are strongly encouraged and often expected for empirical work; align with the widely used reproducibility checklist pattern [5][7].

ICLR
- Formatting/pages: Use the ICLR 2025 Author Guide and template; OpenReview submission with specific formatting requirements outlined in the guide [8][9].
- Anonymization: Double-blind via OpenReview; follow the Author Guide for anonymization and citation of preprints [8][10].
- Code/data: Code is encouraged; reviewers and area chairs commonly expect runnable artifacts or, at minimum, clear instructions to reproduce results [8].

MLSys
- Formatting/pages: See the MLSys 2025 CFP for template and length rules; MLSys enforces systems-oriented empirical evidence and often coordinates artifact expectations with the CFP timeline [11].
- Anonymization: Double-blind (per CFP). Ensure systems diagrams and institution-specific cluster names are scrubbed [11].
- Code/data: Artifact expectations are encouraged in MLSys culture; confirm the current year’s Artifact Evaluation or badging details in the CFP/AE pages before finalizing the package [11].

ACL via ARR (if NLP-centric)
- Formatting/pages: See ACL 2025 main CFP (page limits by category). ARR uses ACL styles and submission rules; defer to the current call for exact limits [12][14].
- Anonymization: Double-blind through ARR; follow ARR’s instructions for self-citation and anonymized links [14].
- Code/data: Responsible NLP Research Checklist is required as an appendix in many ACL venues; ethics review possible where risks apply [12][13].

TMLR
- Formatting/pages: Guidance emphasizes clarity and completeness; use the TMLR author guide (OpenReview process). No tight page caps like conferences, but concise presentation is expected [15][16].
- Anonymization: Double-blind during review on OpenReview; follow TMLR’s instructions for anonymous artifacts [15][16].
- Code/data: Strongly encouraged to release code/data or provide reproduction instructions; transparency and reproducibility are central to reviews [15][16].

JMLR
- Formatting/pages: Journal format with JMLR style; no fixed page limit but high expectations for completeness and rigor [17][18].
- Anonymization: Single-blind/open—authors are named; not suitable if you need a double-blind process [17].
- Code/data: Encouraged to release code/data and adhere to reproducibility norms of the journal [17][18].

Adapted submission plan for “Do Multiple Instance Learning Models Transfer?”

Pick the primary target now
- If you want open, iterative community feedback: ICLR (OpenReview) or TMLR first, then take a revised version to ICML/NeurIPS [8][15][16].
- If you want a single-shot conference: ICML/NeurIPS. Ensure formatting strictness and checklist compliance early to pass desk review [1][2][5][6].

Week-by-week deliverables (6–8 weeks)

Week 0 (now): Decision + scaffolding
- Choose primary venue and lock template (NeurIPS vs ICML vs ICLR). Create a private branch that compiles under that venue’s LaTeX style [1][5][8].
- Set up an anonymous artifacts plan: private Git repo mirrored to an anonymous GitHub or OpenReview attachment; scrub commit authors; include a one-command run script; draft a license/README with dataset licenses summarized [8][15][16].

Week 1–2: Core results + compliance
- Finish core MIL transfer experiments (source→target pairs, seeds ≥3) and populate a Reproducibility section (splits, seeds, HP ranges, compute, hardware) keyed to the venue’s checklist [2][5][8].
- Build the dataset license/provenance table (appendix) and model/dataset release notes (what is released at submission vs. upon acceptance) [2][3][12][13].

Week 3: Supplement + artifacts
- Prepare anonymized supplemental PDF with extended tables, abl/robustness, and the full license table; ensure consistent anonymization across PDF and supplemental [4][5][8][12][14].
- Package artifacts: scripts/configs/environment.yml; deterministic seeds; compressed logs. For ICLR/TMLR, test OpenReview artifact upload limits and plan an external mirror if needed [8][15][16].

Week 4: Writing freeze + internal desk-check
- Conform to template margins, references style, and page limits; remove any forbidden content (author names, acknowledgments, institutional URLs) until camera-ready [1][5][8][12].
- Run a “desk-check” pass: compile with clean logs; verify figures fit template; no overfull boxes; references are complete.

Week 5: Dry run submission
- Upload to the venue system (OpenReview for ICLR/TMLR; CMT for ICML/NeurIPS) and verify PDFs render correctly. Test anonymous artifact links in a fresh browser session [8][15][16].
- Add the venue-specific checklist: NeurIPS Paper Checklist; Responsible NLP Checklist if targeting ACL via ARR; or an explicit reproducibility section for ICML/ICLR [2][13][5][8].

Week 6: Buffer and polish
- Address any last issues surfaced in internal reviews. If MLSys is a candidate, confirm any Artifact Evaluation sign-up or checklist timing from the CFP [11].

Risks to manage per venue (and mitigations)

- Desk rejection for formatting violations (page limits, fonts, margins)
  - Mitigation: Lock the correct LaTeX template on day 0; run an automated pdf/x compliance check; keep references unlimited only if venue allows; avoid moving content into references to bypass limits [1][5][8].

- De-anonymization via artifacts or self-citations
  - Mitigation: Use anonymous artifact mirrors (no author names in commits or metadata); cite your prior work neutrally in third person; delay code DOI creation until camera-ready if it would unblind [8][14][15].

- Incomplete reproducibility and licensing details
  - Mitigation: Include the NeurIPS/ICML-style reproducibility content and the dataset license table in appendix; for ACL, add the Responsible NLP Checklist appendix explicitly [2][5][13].

- Artifact availability mismatch with claims
  - Mitigation: If any data cannot be redistributed, provide scripts to fetch from original URLs and document licenses; for trained weights, provide training recipes if licenses restrict release [3][12][17].

Checklist you can copy into your project tracker

Formatting and anonymization
- Paper compiles in selected venue template; main text within page limits; references/supplement per rules [1][5][8][12].
- All PDFs and supplements anonymized; figures scrubbed of institutional watermarks/filenames; acknowledgments removed until camera-ready [4][5][8][12][14].

Artifacts and reproducibility
- Anonymous code repo or OpenReview attachment with run script; environment and exact seeds documented [8][15][16].
- Reproducibility section includes hardware, hours, precision, batch, seeds; hyperparameter ranges and selection rules; fixed random seed listings [2][5][8].
- Dataset license/provenance appendix complete; attributions and allowed uses noted; non-redistributable data replaced by scripts [2][3][12][13][17].

Ethics/safety
- Ethics statement includes data provenance, any human-subjects information, and risk/mitigation discussion; checklists (NeurIPS Paper Checklist; Responsible NLP for ACL) included as required [2][12][13][19].

Venue-specific add-ons
- ICLR/TMLR: OpenReview-ready submission; anonymous links confirmed; preprint policy compliance checked [8][15][16].
- NeurIPS/ICML: Internal pass on the venue’s FAQ/instructions; ensure checklist inclusion and strict formatting [1][2][5][6][7].
- MLSys: Confirm any Artifact Evaluation or badging windows; prepare a minimal artifact bundle even if AE is optional [11].

Key takeaways
- Decide your primary venue now and adopt its template/checklists immediately to avoid late desk-check surprises [1][5][8].
- Treat artifacts and anonymization as first-class deliverables; test anonymous links and reproduction on a clean machine [8][15][16].
- Put all licensing and reproducibility specifics in an appendix and reference them in main text; this aligns with reviewer expectations across venues [2][3][5][12][13].

Sources
[1] NeurIPS 2025 Call for Papers — https://neurips.cc/Conferences/2025/CallForPapers
[2] NeurIPS Paper Checklist — https://neurips.cc/public/guides/PaperChecklist
[3] NeurIPS 2025 Datasets and Benchmarks FAQ — https://neurips.cc/Conferences/2025/DatasetsBenchmarks-FAQ
[4] NeurIPS 2025 FAQ for Authors — https://neurips.cc/Conferences/2025/PaperInformation/NeurIPS-FAQ
[5] ICML 2025 Submission and Formatting Instructions — https://arxiv.org/html/2410.16665v2
[6] ICML 2025 example paper (style) — https://media.icml.cc/Conferences/ICML2025/Styles/example_paper.pdf
[7] ICML Author Instructions (2024) — https://icml.cc/Conferences/2024/AuthorInstructions
[8] ICLR 2025 Author Guide — https://iclr.cc/Conferences/2025/AuthorGuide
[9] ICLR 2025 Formatting Instructions — https://arxiv.org/html/2501.14577v1
[10] ICLR 2025 on OpenReview — https://openreview.net/group?id=ICLR.cc%2F2025%2FConference
[11] MLSys 2025 Call for Papers — https://mlsys.org/Conferences/2025/CallForPapers
[12] ACL 2025 Main Conference CFP — https://2025.aclweb.org/calls/main_conference_papers/
[13] Responsible NLP Research Checklist — https://openreview.net/attachment?id=yGhYSEj8ln0&name=responsible_NLP_research
[14] ACL Rolling Review (ARR) — http://aclrollingreview.org
[15] TMLR Author Guidelines — https://jmlr.csail.mit.edu/tmlr/author-guide.html
[16] TMLR FAQ — https://jmlr.org/tmlr/faq.html
[17] JMLR Author Guidelines — https://jmlr.org/author-info.html
[18] JMLR Formatting Requirements — https://www.jmlr.org/format/format.html
[19] NeurIPS Ethics Guidelines — https://neurips.cc/Conferences/2023/EthicsGuidelines
[20] NeurIPS Ethics Guidelines for Reviewers — https://neurips.cc/Conferences/2023/EthicsGuidelinesForReviewers